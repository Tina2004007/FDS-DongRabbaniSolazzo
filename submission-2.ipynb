{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":107555,"databundleVersionId":13033998,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!wget \"https://github.com/freemedom/temp_dataset/releases/download/v2.0/pokemon_stats_20.json\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-14T23:48:55.350182Z","iopub.execute_input":"2025-11-14T23:48:55.350429Z","iopub.status.idle":"2025-11-14T23:48:55.886519Z","shell.execute_reply.started":"2025-11-14T23:48:55.350407Z","shell.execute_reply":"2025-11-14T23:48:55.885600Z"}},"outputs":[{"name":"stdout","text":"--2025-11-14 23:48:55--  https://github.com/freemedom/temp_dataset/releases/download/v2.0/pokemon_stats_20.json\nResolving github.com (github.com)... 140.82.121.3\nConnecting to github.com (github.com)|140.82.121.3|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://release-assets.githubusercontent.com/github-production-release-asset/1090602936/12253f88-9861-431c-ab07-1156f2e17388?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-11-15T00%3A25%3A20Z&rscd=attachment%3B+filename%3Dpokemon_stats_20.json&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-11-14T23%3A25%3A15Z&ske=2025-11-15T00%3A25%3A20Z&sks=b&skv=2018-11-09&sig=3s7gyDn36Yre7ESZAtSF3v%2FClTnA2YTIWbxVwl7EvsQ%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2MzE2NDQzNSwibmJmIjoxNzYzMTY0MTM1LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.DejDlzE3XeARRayymUztCNqgKF6l4g3HFLqKNHhog8E&response-content-disposition=attachment%3B%20filename%3Dpokemon_stats_20.json&response-content-type=application%2Foctet-stream [following]\n--2025-11-14 23:48:55--  https://release-assets.githubusercontent.com/github-production-release-asset/1090602936/12253f88-9861-431c-ab07-1156f2e17388?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-11-15T00%3A25%3A20Z&rscd=attachment%3B+filename%3Dpokemon_stats_20.json&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-11-14T23%3A25%3A15Z&ske=2025-11-15T00%3A25%3A20Z&sks=b&skv=2018-11-09&sig=3s7gyDn36Yre7ESZAtSF3v%2FClTnA2YTIWbxVwl7EvsQ%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2MzE2NDQzNSwibmJmIjoxNzYzMTY0MTM1LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.DejDlzE3XeARRayymUztCNqgKF6l4g3HFLqKNHhog8E&response-content-disposition=attachment%3B%20filename%3Dpokemon_stats_20.json&response-content-type=application%2Foctet-stream\nResolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\nConnecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 4730 (4.6K) [application/octet-stream]\nSaving to: ‘pokemon_stats_20.json’\n\npokemon_stats_20.js 100%[===================>]   4.62K  --.-KB/s    in 0s      \n\n2025-11-14 23:48:55 (53.9 MB/s) - ‘pokemon_stats_20.json’ saved [4730/4730]\n\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport json\nfrom datetime import datetime\nfrom sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier, GradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif, RFE, RFECV\nfrom sklearn.linear_model import LogisticRegression\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom catboost import CatBoostClassifier\nimport warnings\nimport os\nimport sys\nimport optuna\nfrom optuna.pruners import MedianPruner\n\ndef extract_final_pokemon_status(timeline):\n    p1_alive_pokemon_names = set()\n    p1_fnt_pokemon_names = set()\n    p2_alive_pokemon_names = set()\n    p1_last_status = {}\n    p2_last_status = {}\n    for turn in timeline:\n        p1_pokemon_state = turn.get('p1_pokemon_state', {})\n        p1_pokemon_name = p1_pokemon_state.get('name', '')\n        if p1_pokemon_name:\n            p1_last_status[p1_pokemon_name] = p1_pokemon_state.get('status', 'nostatus')\n\n        p2_pokemon_state = turn.get('p2_pokemon_state', {})\n        p2_pokemon_name = p2_pokemon_state.get('name', '')\n        if p2_pokemon_name:\n            p2_last_status[p2_pokemon_name] = p2_pokemon_state.get('status', 'nostatus')\n\n    for pokemon_name, status in p1_last_status.items():\n        if status == 'fnt':\n            p1_fnt_pokemon_names.add(pokemon_name)\n        else:\n            p1_alive_pokemon_names.add(pokemon_name)\n\n    for pokemon_name, status in p2_last_status.items():\n        if status != 'fnt':\n            p2_alive_pokemon_names.add(pokemon_name)\n\n    return p1_alive_pokemon_names, p1_fnt_pokemon_names, p2_alive_pokemon_names\n\ndef extract_moves(data: dict):\n\n    p1_pokemon_moves = {}\n    p2_pokemon_moves = {}\n\n    for turn in data.get(\"battle_timeline\", []):\n\n        p1_name = turn.get(\"p1_pokemon_state\", {}).get(\"name\", \"\")\n        p2_name = turn.get(\"p2_pokemon_state\", {}).get(\"name\", \"\")\n\n        p1_move = turn.get(\"p1_move_details\")\n        if p1_move is not None and (p1_name not in p1_pokemon_moves or p1_move not in p1_pokemon_moves[p1_name]):\n\n            p1_pokemon_moves.setdefault(p1_name, []).append(p1_move)\n        \n        p2_move = turn.get(\"p2_move_details\")\n        if p2_move is not None and (p2_name not in p2_pokemon_moves or p2_move not in p2_pokemon_moves[p2_name]):\n            p2_pokemon_moves.setdefault(p2_name, []).append(p2_move)\n\n        p1_status = turn.get(\"p1_pokemon_state\", {}).get(\"status\", \"\")\n        if p1_status == \"fnt\":\n            p1_pokemon_moves.pop(p1_name, None)\n        \n        p2_status = turn.get(\"p2_pokemon_state\", {}).get(\"status\", \"\")\n        if p2_status == \"fnt\":\n            p2_pokemon_moves.pop(p2_name, None)\n\n    return p1_pokemon_moves, p2_pokemon_moves\n\ndef type_multiplier(p1_moves: dict, p2_moves: dict):\n\n    type_pokemon1 = {}\n    type_pokemon2 = {}\n\n    for pokemon, moves in p1_moves.items():\n        type_pokemon1[pokemon] = []\n        for move in moves:\n\n            if move and move.get(\"type\") and move.get(\"base_power\") and move.get(\"category\") != \"STATUS\":\n\n                type_pokemon1[pokemon].append({\n                    \"type\": move[\"type\"].capitalize(),\n                    \"power\": move[\"base_power\"] * move.get(\"accuracy\", 1.0)\n                })\n\n    for pokemon, moves in p2_moves.items():\n        type_pokemon2[pokemon] = []\n        for move in moves:\n            if move and move.get(\"type\") and move.get(\"base_power\") and move.get(\"category\") != \"STATUS\":\n                type_pokemon2[pokemon].append({\n                    \"type\": move[\"type\"].capitalize(),\n                    \"power\": move[\"base_power\"] * move.get(\"accuracy\", 1.0)\n                })\n\n    diz_multiplier_my_pokemon = {}\n    diz_multiplier_other_pokemon = {}\n\n    for pokemon1, moves1 in type_pokemon1.items():\n        total_effectiveness = []\n\n        for pokemon2, moves2 in type_pokemon2.items():\n            multiplier = 1.0\n\n            for move in moves1:\n                t_att = move[\"type\"]\n                base_power = move[\"power\"]\n\n                if t_att not in TABLE_TYPE:\n                    continue\n                super_eff, meno_eff, no_eff = TABLE_TYPE[t_att]\n\n                for t_def in P_DEF_TYPE.get(pokemon2.lower(), []):\n\n                    if t_def in no_eff:\n                        multiplier *= 0.0\n                    elif t_def in super_eff:\n                        multiplier *= 2.0\n                    elif t_def in meno_eff:\n                        multiplier *= 0.5\n\n                multiplier *= (base_power / 100.0)\n\n            total_effectiveness.append(multiplier)\n\n        if total_effectiveness:\n            diz_multiplier_my_pokemon[pokemon1] = np.mean(total_effectiveness)\n        else:\n            diz_multiplier_my_pokemon[pokemon1] = 0.0\n\n    for pokemon2, moves2 in type_pokemon2.items():\n        total_effectiveness = []\n\n        for pokemon1, moves1 in type_pokemon1.items():\n            multiplier = 1.0\n\n            for move in moves2:\n                t_att = move[\"type\"]\n                base_power = move[\"power\"]\n                if t_att not in TABLE_TYPE:\n                    continue\n                super_eff, meno_eff, no_eff = TABLE_TYPE[t_att]\n\n                for t_def in P_DEF_TYPE.get(pokemon1.lower(), []):\n\n                    if t_def in no_eff:\n                        multiplier *= 0.0\n                    elif t_def in super_eff:\n                        multiplier *= 2.0\n                    elif t_def in meno_eff:\n                        multiplier *= 0.5\n\n                multiplier *= (base_power / 100.0)\n\n            total_effectiveness.append(multiplier)\n\n        if total_effectiveness:\n            diz_multiplier_other_pokemon[pokemon2] = np.mean(total_effectiveness)\n        else:\n            diz_multiplier_other_pokemon[pokemon2] = 0.0\n\n    if diz_multiplier_my_pokemon:\n        p1_team_avg = np.mean(list(diz_multiplier_my_pokemon.values()))\n    else:\n        p1_team_avg = 0.0\n\n    if diz_multiplier_other_pokemon:\n        p2_team_avg = np.mean(list(diz_multiplier_other_pokemon.values()))\n    else:\n        p2_team_avg = 0.0\n\n    return p1_team_avg, p2_team_avg\n\ndef count_priority_moves(pokemon_moves: dict) -> int:\n\n    return sum(move.get(\"priority\", 0) for moves in pokemon_moves.values() for move in moves)\n\nTABLE_TYPE = {\n    \"Normal\": ([], [\"Rock\", \"Steel\"], [\"Ghost\"]),\n    \"Fire\": ([\"Grass\", \"Ice\", \"Bug\", \"Steel\"],\n             [\"Fire\", \"Water\", \"Rock\", \"Dragon\"], []),\n    \"Water\": ([\"Fire\", \"Ground\", \"Rock\"],\n              [\"Water\", \"Grass\", \"Dragon\"], []),\n    \"Electric\": ([\"Water\", \"Flying\"],\n                 [\"Electric\", \"Grass\", \"Dragon\"], [\"Ground\"]),\n    \"Grass\": ([\"Water\", \"Ground\", \"Rock\"],\n              [\"Fire\", \"Grass\", \"Poison\", \"Flying\", \"Bug\", \"Dragon\", \"Steel\"], []),\n    \"Ice\": ([\"Grass\", \"Ground\", \"Flying\", \"Dragon\"],\n            [\"Fire\", \"Water\", \"Ice\", \"Steel\"], []),\n    \"Fighting\": ([\"Normal\", \"Ice\", \"Rock\", \"Dark\", \"Steel\"],\n                 [\"Poison\", \"Flying\", \"Psychic\", \"Bug\", \"Fairy\"], []),\n    \"Poison\": ([\"Grass\", \"Fairy\"],\n               [\"Poison\", \"Ground\", \"Rock\", \"Ghost\"], []),\n    \"Ground\": ([\"Fire\", \"Electric\", \"Poison\", \"Rock\", \"Steel\"],\n               [\"Grass\", \"Bug\"], [\"Flying\"]),\n    \"Flying\": ([\"Grass\", \"Fighting\", \"Bug\"],\n               [\"Electric\", \"Rock\", \"Steel\"], []),\n    \"Psychic\": ([\"Fighting\", \"Poison\"],\n                [\"Psychic\", \"Steel\"], [\"Dark\"]),\n    \"Bug\": ([\"Grass\", \"Psychic\", \"Dark\"],\n            [\"Fire\", \"Fighting\", \"Poison\", \"Flying\", \"Ghost\", \"Steel\", \"Fairy\"], []),\n    \"Rock\": ([\"Fire\", \"Ice\", \"Flying\", \"Bug\"],\n             [\"Fighting\", \"Ground\", \"Steel\"], []),\n    \"Ghost\": ([\"Psychic\", \"Ghost\"],\n              [\"Dark\"], [\"Normal\"]),\n    \"Dragon\": ([\"Dragon\"],\n               [\"Steel\"], [\"Fairy\"]),\n    \"Dark\": ([\"Psychic\", \"Ghost\"],\n             [\"Fighting\", \"Dark\", \"Fairy\"], []),\n    \"Steel\": ([\"Ice\", \"Rock\", \"Fairy\"],\n              [\"Fire\", \"Water\", \"Electric\", \"Steel\"], []),\n    \"Fairy\": ([\"Fighting\", \"Dragon\", \"Dark\"],\n              [\"Fire\", \"Poison\", \"Steel\"], [])\n}\n\nP_DEF_TYPE = {\n    \"starmie\": [\"psychic\", \"water\"],\n    \"exeggutor\": [\"grass\", \"psychic\"],\n    \"chansey\": [\"normal\"],\n    \"snorlax\": [\"normal\"],\n    \"tauros\": [\"normal\"],\n    \"alakazam\": [\"psychic\"],\n    \"jynx\": [\"ice\", \"psychic\"],\n    \"slowbro\": [\"psychic\", \"water\"],\n    \"gengar\": [\"ghost\", \"poison\"],\n    \"rhydon\": [\"ground\", \"rock\"],\n    \"zapdos\": [\"electric\", \"flying\"],\n    \"cloyster\": [\"ice\", \"water\"],\n    \"golem\": [\"ground\", \"rock\"],\n    \"jolteon\": [\"electric\"],\n    \"articuno\": [\"flying\", \"ice\"],\n    \"persian\": [\"normal\"],\n    \"lapras\": [\"ice\", \"water\"],\n    \"dragonite\": [\"dragon\", \"flying\"],\n    \"victreebel\": [\"grass\", \"poison\"],\n    \"charizard\": [\"fire\", \"flying\"]\n}\n\n_log_file_handle = None\n_original_print = print\n\ndef setup_logging(log_dir='print_log'):\n    global _log_file_handle\n    \n    if not os.path.exists(log_dir):\n        os.makedirs(log_dir)\n    \n    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n    log_file_path = os.path.join(log_dir, f'print_log_{timestamp}.log')\n    \n    _log_file_handle = open(log_file_path, 'w', encoding='utf-8')\n    \n    return log_file_path\n\ndef log_print(*args, **kwargs):\n    global _log_file_handle, _original_print\n    \n    file_param = kwargs.get('file', None)\n    \n    _original_print(*args, **kwargs)\n    \n    if _log_file_handle is not None and file_param is None:\n        try:\n\n            sep = kwargs.get('sep', ' ')\n            end = kwargs.get('end', '\\n')\n            \n            message = sep.join(str(arg) for arg in args) + end\n            \n            _log_file_handle.write(message)\n            _log_file_handle.flush()\n        except Exception as e:\n\n            _original_print(f\"Warning: Failed to write to log file: {e}\", file=sys.stderr)\n\ndef close_logging():\n    global _log_file_handle\n    if _log_file_handle is not None:\n        _log_file_handle.close()\n        _log_file_handle = None\n\nclass PokemonBattlePredictorEnhanced:\n    # Class constants\n    WEIGHT_HP = 1.0\n    WEIGHT_ATTACK = 1.5\n    WEIGHT_DEFENSE = 1.0\n    WEIGHT_SPEED = 1.75\n\n    SPECIAL_POKEMON_MODIFIERS = {\n        \"chansey\": 1.2, \"alakazam\": 1.25, \"snorlax\": 1.15, \"dragonite\": 1.2,\n        \"zapdos\": 1.1, \"starmie\": 1.05, \"exeggutor\": 1.05, \"gengar\": 1.1,\n        \"rhydon\": 1.05, \"cloyster\": 1.05, \"golem\": 1.05, \"jolteon\": 1.05,\n        \"articuno\": 1.05, \"persian\": 1.0, \"lapras\": 1.05, \"charizard\": 1.0,\n        \"victreebel\": 1.0, \"jynx\": 1.0, \"slowbro\": 1.05, \"tauros\": 1.05\n    }\n\n    def __init__(self):\n        self.train_data = None\n        self.test_data = None\n        self.features = None\n        self.target = None\n        self.models = {}\n        self.feature_importance = {}\n        self.scaler = StandardScaler()\n        self.feature_selector = None\n        self.X_val = None\n        self.y_val = None\n        self.best_model = None\n        self.best_model_name = None\n\n        self.features_to_remove = []\n\n        self.validation_split = 0.1\n\n        self.use_optuna_tuning = False\n        self.optuna_n_trials = 50\n        self.optuna_timeout = 3600\n        self.optuna_cv_folds = 3\n        self.optuna_pruner_warmup = 5\n        self.optuna_pruner_interval = 1\n\n        self.optuna_best_params = {}\n        self.optuna_studies = {}\n\n    def load_pokemon_database(self):\n        \"\"\"Load Pokemon attributes database\"\"\"\n        pokemon_db = {}\n        try:\n            if os.path.exists('pokemon_stats_20.json'):\n                with open('pokemon_stats_20.json', 'r', encoding='utf-8') as f:\n                    pokemon_list = json.load(f)\n                    for pokemon in pokemon_list:\n                        pokemon_name = pokemon.get('name', '').lower()\n                        if pokemon_name:\n                            pokemon_db[pokemon_name] = pokemon\n                print(f\"✓ Loaded {len(pokemon_db)}  Pokemon attribute data\")\n        except Exception as e:\n            print(f\"⚠️ Failed to load Pokemon attribute database: {e}\")\n            pokemon_db = {}\n        return pokemon_db\n\n    def sanitize_move_name(self, move_name):\n        sanitized = move_name.replace(' ', '_').replace('-', '_').replace(\"'\", '').replace('.', '')\n        sanitized = ''.join(c if c.isalnum() or c == '_' else '_' for c in sanitized)\n        return sanitized.lower()\n\n    def calculate_pokemon_strength(self, pokemon_data):\n        if not pokemon_data:\n            return 0.0\n\n        base_hp = pokemon_data.get('base_hp', 0)\n        base_atk = pokemon_data.get('base_atk', 0)\n        base_def = pokemon_data.get('base_def', 0)\n        base_spa = pokemon_data.get('base_spa', 0)\n        base_spd = pokemon_data.get('base_spd', 0)\n        base_spe = pokemon_data.get('base_spe', 0)\n\n        hp_score = base_hp * self.WEIGHT_HP\n        atk_score = base_atk * self.WEIGHT_ATTACK\n        def_score = base_def * self.WEIGHT_DEFENSE\n        spa_score = base_spa * self.WEIGHT_ATTACK\n        spd_score = base_spd * self.WEIGHT_DEFENSE\n        spe_score = base_spe * self.WEIGHT_SPEED\n\n        strength = hp_score + atk_score + def_score + spa_score + spd_score + spe_score\n\n        pokemon_name = pokemon_data.get('name', '').lower()\n        if pokemon_name in self.SPECIAL_POKEMON_MODIFIERS:\n            strength *= self.SPECIAL_POKEMON_MODIFIERS[pokemon_name]\n\n        return strength\n\n    def extract_hp_features(self, timeline, total_turns):\n        features = {}\n        p1_hp_losses = []\n        p2_hp_losses = []\n        p1_prev_hp = None\n        p2_prev_hp = None\n\n        for turn in timeline:\n            p1_hp = turn.get('p1_pokemon_state', {}).get('hp_pct', 0)\n            p2_hp = turn.get('p2_pokemon_state', {}).get('hp_pct', 0)\n\n            if p1_prev_hp is not None:\n                p1_hp_loss = p1_prev_hp - p1_hp\n                p1_hp_losses.append(p1_hp_loss)\n            if p2_prev_hp is not None:\n                p2_hp_loss = p2_prev_hp - p2_hp\n                p2_hp_losses.append(p2_hp_loss)\n\n            p1_prev_hp = p1_hp\n            p2_prev_hp = p2_hp\n\n        if p1_hp_losses:\n            features['p1_avg_hp_loss'] = np.mean(p1_hp_losses)\n            features['p1_max_hp_loss'] = max(p1_hp_losses)\n        else:\n            features['p1_avg_hp_loss'] = 0\n            features['p1_max_hp_loss'] = 0\n\n        if p2_hp_losses:\n            features['p2_avg_hp_loss'] = np.mean(p2_hp_losses)\n            features['p2_max_hp_loss'] = max(p2_hp_losses)\n        else:\n            features['p2_avg_hp_loss'] = 0\n            features['p2_max_hp_loss'] = 0\n\n        return features\n\n    def extract_move_features(self, timeline):\n        features = {}\n        p1_move_powers = []\n        p2_move_powers = []\n        p1_move_accuracies = []\n        p2_move_accuracies = []\n        p1_switch_count = 0\n        p2_switch_count = 0\n\n        for turn in timeline:\n            p1_move = turn.get('p1_move_details')\n            p2_move = turn.get('p2_move_details')\n\n            if p1_move:\n                power = p1_move.get('base_power', 0)\n                accuracy = p1_move.get('accuracy', 1.0)\n                if power > 0:\n                    p1_move_powers.append(power)\n                p1_move_accuracies.append(accuracy)\n            else:\n                p1_switch_count += 1\n\n            if p2_move:\n                power = p2_move.get('base_power', 0)\n                accuracy = p2_move.get('accuracy', 1.0)\n                if power > 0:\n                    p2_move_powers.append(power)\n                p2_move_accuracies.append(accuracy)\n            else:\n                p2_switch_count += 1\n\n        if p1_move_accuracies:\n            features['p1_avg_accuracy'] = np.mean(p1_move_accuracies)\n        else:\n            features['p1_avg_accuracy'] = 1.0\n\n        if p2_move_accuracies:\n            features['p2_avg_accuracy'] = np.mean(p2_move_accuracies)\n        else:\n            features['p2_avg_accuracy'] = 1.0\n\n        features['p1_switch_count'] = p1_switch_count\n        features['p2_switch_count'] = p2_switch_count\n\n        return features\n\n    def extract_status_features(self, timeline):\n        features = {}\n        p1_pokemon_status_dict = {}\n        p2_pokemon_status_dict = {}\n        p1_counter_invalid = 0\n        p2_counter_invalid = 0\n        p1_pokemon_appeared_30turns = set()\n        p2_pokemon_appeared_30turns = set()\n\n        for i, turn in enumerate(timeline):\n            p1_move = turn.get('p1_move_details')\n            p2_move = turn.get('p2_move_details')\n\n            if p1_move and p1_move.get('name', '').lower() == 'counter':\n                if not p2_move:\n                    p1_counter_invalid += 1\n                elif p2_move.get('category', 'STATUS') != 'PHYSICAL':\n                    p1_counter_invalid += 1\n\n            if p2_move and p2_move.get('name', '').lower() == 'counter':\n                if not p1_move:\n                    p2_counter_invalid += 1\n                elif p1_move.get('category', 'STATUS') != 'PHYSICAL':\n                    p2_counter_invalid += 1\n\n            p1_pokemon_name = turn.get('p1_pokemon_state', {}).get('name', '')\n            p1_status = turn.get('p1_pokemon_state', {}).get('status', 'nostatus')\n            if p1_pokemon_name:\n                p1_pokemon_status_dict[p1_pokemon_name] = p1_status\n                if i < 30:\n                    p1_pokemon_appeared_30turns.add(p1_pokemon_name)\n\n            p2_pokemon_name = turn.get('p2_pokemon_state', {}).get('name', '')\n            p2_status = turn.get('p2_pokemon_state', {}).get('status', 'nostatus')\n            if p2_pokemon_name:\n                p2_pokemon_status_dict[p2_pokemon_name] = p2_status\n                if i < 30:\n                    p2_pokemon_appeared_30turns.add(p2_pokemon_name)\n\n        p1_abnormal_status_count = 0\n        for pokemon_name in p1_pokemon_appeared_30turns:\n            status = p1_pokemon_status_dict.get(pokemon_name, 'nostatus')\n            if status != 'nostatus' and status != 'fnt':\n                p1_abnormal_status_count += 1\n\n        p2_abnormal_status_count = 0\n        for pokemon_name in p2_pokemon_appeared_30turns:\n            status = p2_pokemon_status_dict.get(pokemon_name, 'nostatus')\n            if status != 'nostatus' and status != 'fnt':\n                p2_abnormal_status_count += 1\n\n        p1_fnt_count = 0\n        for pokemon_name, status in p1_pokemon_status_dict.items():\n            if status == 'fnt':\n                p1_fnt_count += 1\n\n        p2_fnt_count = 0\n        for pokemon_name, status in p2_pokemon_status_dict.items():\n            if status == 'fnt':\n                p2_fnt_count += 1\n\n        features['p1_abnormal_status_count'] = p1_abnormal_status_count\n        features['p2_abnormal_status_count'] = p2_abnormal_status_count\n        features['abnormal_status_count_ratio'] = p1_abnormal_status_count / (p2_abnormal_status_count + 1.0)\n        features['p1_counter_invalid'] = p1_counter_invalid\n        features['p2_counter_invalid'] = p2_counter_invalid\n        features['fnt_count_ratio'] = p1_fnt_count / (p2_fnt_count + 1.0)\n        features['fnt_count_diff'] = p1_fnt_count - p2_fnt_count\n        features['p1_unique_pokemon_count_30turns'] = len(p1_pokemon_appeared_30turns)\n        features['p2_unique_pokemon_count_30turns'] = len(p2_pokemon_appeared_30turns)\n\n        return features\n\n    def calculate_strength_features(self, timeline, pokemon_db):\n        features = {}\n        p1_pokemon_hp_dict = {}\n        p2_pokemon_hp_dict = {}\n\n        for i, turn in enumerate(timeline):\n            if i < 30:\n                p1_pokemon_name = turn.get('p1_pokemon_state', {}).get('name', '')\n                p2_pokemon_name = turn.get('p2_pokemon_state', {}).get('name', '')\n                p1_hp = turn.get('p1_pokemon_state', {}).get('hp_pct', 0)\n                p2_hp = turn.get('p2_pokemon_state', {}).get('hp_pct', 0)\n\n                if p1_pokemon_name:\n                    if p1_pokemon_name not in p1_pokemon_hp_dict:\n                        p1_pokemon_hp_dict[p1_pokemon_name] = []\n                    p1_pokemon_hp_dict[p1_pokemon_name].append(p1_hp)\n\n                if p2_pokemon_name:\n                    if p2_pokemon_name not in p2_pokemon_hp_dict:\n                        p2_pokemon_hp_dict[p2_pokemon_name] = []\n                    p2_pokemon_hp_dict[p2_pokemon_name].append(p2_hp)\n\n        p1_weighted_strength_sum = 0.0\n        p1_strength_list = []\n        for pokemon_name, hp_list in p1_pokemon_hp_dict.items():\n            if hp_list:\n                last_hp = hp_list[-1]\n                if last_hp > 0:\n                    pokemon_name_lower = pokemon_name.lower()\n                    if pokemon_name_lower in pokemon_db:\n                        pokemon_data = pokemon_db[pokemon_name_lower]\n                        strength = self.calculate_pokemon_strength(pokemon_data)\n                        p1_weighted_strength_sum += last_hp * strength\n                        p1_strength_list.append(strength)\n\n        p1_appeared_count = len(p1_pokemon_hp_dict)\n        p1_missing_count = 6 - p1_appeared_count\n        if p1_missing_count > 0 and len(p1_strength_list) > 0:\n            p1_avg_strength = np.mean(p1_strength_list)\n            p1_weighted_strength_sum += p1_missing_count * 1.0 * p1_avg_strength\n\n        p2_weighted_strength_sum = 0.0\n        p2_strength_list = []\n        for pokemon_name, hp_list in p2_pokemon_hp_dict.items():\n            if hp_list:\n                last_hp = hp_list[-1]\n                if last_hp > 0:\n                    pokemon_name_lower = pokemon_name.lower()\n                    if pokemon_name_lower in pokemon_db:\n                        pokemon_data = pokemon_db[pokemon_name_lower]\n                        strength = self.calculate_pokemon_strength(pokemon_data)\n                        p2_weighted_strength_sum += last_hp * strength\n                        p2_strength_list.append(strength)\n\n        p2_appeared_count = len(p2_pokemon_hp_dict)\n        p2_missing_count = 6 - p2_appeared_count\n        if p2_missing_count > 0 and len(p2_strength_list) > 0:\n            p2_avg_strength = np.mean(p2_strength_list)\n            p2_weighted_strength_sum += p2_missing_count * 1.0 * p2_avg_strength\n\n        features['p1_weighted_strength_sum'] = p1_weighted_strength_sum\n        features['p2_weighted_strength_sum'] = p2_weighted_strength_sum\n\n        if p2_weighted_strength_sum > 0:\n            features['weighted_strength_ratio_30turns'] = p1_weighted_strength_sum / p2_weighted_strength_sum\n        else:\n            features['weighted_strength_ratio_30turns'] = 0.0\n\n        return features\n\n    def load_data(self, train_path, test_path):\n        print(\"Loading data...\")\n\n        train_records = []\n        with open(train_path, 'r', encoding='utf-8') as f:\n            for line in f:\n                train_records.append(json.loads(line.strip()))\n\n        test_records = []\n        with open(test_path, 'r', encoding='utf-8') as f:\n            for line in f:\n                test_records.append(json.loads(line.strip()))\n\n        self.train_data = pd.DataFrame(train_records)\n        self.test_data = pd.DataFrame(test_records)\n\n        print(f\"Training data loaded: {len(self.train_data)}  records\")\n        print(f\"Test data loaded: {len(self.test_data)}  records\")\n\n        return self.train_data, self.test_data\n\n    def get_complete_type_effectiveness(self):\n        effectiveness = {\n            'normal': {'rock': 0.5, 'ghost': 0.0, 'steel': 0.5},\n            'fire': {'fire': 0.5, 'water': 0.5, 'grass': 2.0, 'ice': 2.0, 'bug': 2.0, 'rock': 0.5, 'dragon': 0.5, 'steel': 2.0},\n            'water': {'fire': 2.0, 'water': 0.5, 'grass': 0.5, 'ground': 2.0, 'rock': 2.0, 'dragon': 0.5},\n            'electric': {'water': 2.0, 'electric': 0.5, 'grass': 0.5, 'ground': 0.0, 'flying': 2.0, 'dragon': 0.5},\n            'grass': {'fire': 0.5, 'water': 2.0, 'grass': 0.5, 'poison': 0.5, 'ground': 2.0, 'flying': 0.5, 'bug': 0.5, 'rock': 2.0, 'dragon': 0.5, 'steel': 0.5},\n            'ice': {'fire': 0.5, 'water': 0.5, 'grass': 2.0, 'ice': 0.5, 'ground': 2.0, 'flying': 2.0, 'dragon': 2.0, 'steel': 0.5},\n            'fighting': {'normal': 2.0, 'ice': 2.0, 'poison': 0.5, 'flying': 0.5, 'psychic': 0.5, 'bug': 0.5, 'rock': 2.0, 'ghost': 0.0, 'dark': 2.0, 'steel': 2.0, 'fairy': 0.5},\n            'poison': {'grass': 2.0, 'poison': 0.5, 'ground': 0.5, 'rock': 0.5, 'ghost': 0.5, 'steel': 0.0, 'fairy': 2.0},\n            'ground': {'fire': 2.0, 'electric': 2.0, 'grass': 0.5, 'poison': 2.0, 'flying': 0.0, 'bug': 0.5, 'rock': 2.0, 'steel': 2.0},\n            'flying': {'electric': 0.5, 'grass': 2.0, 'fighting': 2.0, 'bug': 2.0, 'rock': 0.5, 'steel': 0.5},\n            'psychic': {'fighting': 2.0, 'poison': 2.0, 'psychic': 0.5, 'dark': 0.0, 'steel': 0.5},\n            'bug': {'fire': 0.5, 'grass': 2.0, 'fighting': 0.5, 'poison': 0.5, 'flying': 0.5, 'psychic': 2.0, 'ghost': 0.5, 'dark': 2.0, 'steel': 0.5, 'fairy': 0.5},\n            'rock': {'fire': 2.0, 'ice': 2.0, 'fighting': 0.5, 'ground': 0.5, 'flying': 2.0, 'bug': 2.0, 'steel': 0.5},\n            'ghost': {'normal': 0.0, 'psychic': 2.0, 'ghost': 2.0, 'dark': 0.5},\n            'dragon': {'dragon': 2.0, 'steel': 0.5, 'fairy': 0.0},\n            'dark': {'fighting': 0.5, 'psychic': 2.0, 'ghost': 2.0, 'dark': 0.5, 'fairy': 0.5},\n            'steel': {'fire': 0.5, 'water': 0.5, 'electric': 0.5, 'ice': 2.0, 'rock': 2.0, 'steel': 0.5, 'fairy': 2.0},\n            'fairy': {'fire': 0.5, 'fighting': 2.0, 'poison': 0.5, 'dragon': 2.0, 'dark': 2.0, 'steel': 0.5}\n        }\n        return effectiveness\n\n    def calculate_team_type_advantage(self, p1_team, p2_lead):\n\n        effectiveness = self.get_complete_type_effectiveness()\n\n        advantages = []\n\n        p2_types = p2_lead.get('types', []) if p2_lead else []\n\n        for pokemon in p1_team:\n            if not pokemon:\n                continue\n\n            p1_types = pokemon.get('types', [])\n\n            adv = 1.0\n\n            for p1_type in p1_types:\n                if p1_type.lower() in effectiveness:\n\n                    for p2_type in p2_types:\n\n                        if p2_type.lower() in effectiveness[p1_type.lower()]:\n                            adv *= effectiveness[p1_type.lower()][p2_type.lower()]\n\n            advantages.append(adv)\n\n        if not advantages:\n            return {'type_adv_mean': 1.0, 'type_adv_max': 1.0, 'type_adv_min': 1.0}\n\n        return {\n            'type_adv_mean': np.mean(advantages),\n            'type_adv_max': max(advantages),\n            'type_adv_min': min(advantages),\n            'type_adv_std': np.std(advantages) if len(advantages) > 1 else 0\n        }\n\n    def calculate_alive_teams_type_advantage(self, p1_alive_team, p2_alive_team):\n        if not p1_alive_team or not p2_alive_team:\n\n            return {\n                'type_adv_mean': 1.0,\n                'type_adv_max': 1.0,\n                'type_adv_min': 1.0,\n                'type_adv_std': 0.0\n            }\n        \n        all_advantages = []\n        for p2_pokemon in p2_alive_team:\n\n            type_adv = self.calculate_team_type_advantage(p1_alive_team, p2_pokemon)\n\n            all_advantages.append(type_adv.get('type_adv_mean', 1.0))\n        \n        if all_advantages:\n            return {\n                'type_adv_mean': np.mean(all_advantages),\n                'type_adv_max': np.max(all_advantages),\n                'type_adv_min': np.min(all_advantages),\n                'type_adv_std': np.std(all_advantages) if len(all_advantages) > 1 else 0.0\n            }\n        else:\n\n            return {\n                'type_adv_mean': 1.0,\n                'type_adv_max': 1.0,\n                'type_adv_min': 1.0,\n                'type_adv_std': 0.0\n            }\n\n    def calculate_team_diversity(self, team):\n        if not team:\n            return {'type_diversity': 0, 'stat_diversity': 0}\n\n        all_types = []\n        for pokemon in team:\n            if pokemon and 'types' in pokemon:\n                all_types.extend(pokemon['types'])\n\n        type_diversity = len(set(all_types)) / max(len(all_types), 1)\n\n        stats_matrix = []\n        for pokemon in team:\n            if pokemon:\n                stats = [\n                    pokemon.get('base_hp', 0),\n                    pokemon.get('base_atk', 0),\n                    pokemon.get('base_def', 0),\n                    pokemon.get('base_spa', 0),\n                    pokemon.get('base_spd', 0),\n                    pokemon.get('base_spe', 0)\n                ]\n                stats_matrix.append(stats)\n\n        stat_diversity = 0\n        if stats_matrix:\n            stats_matrix = np.array(stats_matrix)\n\n            for i in range(6):\n                col = stats_matrix[:, i]\n                if np.mean(col) > 0:\n\n                    stat_diversity += np.std(col) / np.mean(col)\n\n            stat_diversity /= 6\n\n        return {'type_diversity': type_diversity, 'stat_diversity': stat_diversity}\n\n    def extract_static_features(self):\n        print(\"\\n=== Extracting Static Features (Enhanced) ===\")\n\n        pokemon_db = self.load_pokemon_database()\n\n        def extract_pokemon_stats(pokemon):\n            if not pokemon:\n                return [0] * 6\n\n            return [\n                pokemon.get('base_hp', 0),\n                pokemon.get('base_atk', 0),\n                pokemon.get('base_def', 0),\n                pokemon.get('base_spa', 0),\n                pokemon.get('base_spd', 0),\n                pokemon.get('base_spe', 0)\n            ]\n\n        def calculate_team_stats(alive_pokemon_names=None):\n            if not alive_pokemon_names:\n                return {'sum': [0]*6, 'mean': [0]*6, 'max': [0]*6, 'min': [0]*6, 'std': [0]*6}\n\n            stats_matrix = []\n            for pokemon_name in alive_pokemon_names:\n\n                pokemon_name_lower = pokemon_name.lower()\n                if pokemon_name_lower in pokemon_db:\n                    pokemon = pokemon_db[pokemon_name_lower]\n                    stats = extract_pokemon_stats(pokemon)\n                    stats_matrix.append(stats)\n\n            if not stats_matrix:\n                return {'sum': [0]*6, 'mean': [0]*6, 'max': [0]*6, 'min': [0]*6, 'std': [0]*6}\n\n            stats_matrix = np.array(stats_matrix)\n\n            return {\n                'sum': np.sum(stats_matrix, axis=0).tolist(),\n                'mean': np.mean(stats_matrix, axis=0).tolist(),\n                'max': np.max(stats_matrix, axis=0).tolist(),\n                'min': np.min(stats_matrix, axis=0).tolist(),\n                'std': np.std(stats_matrix, axis=0).tolist()\n            }\n\n        def extract_single_static_features(row):\n            features = {}\n\n            p1_team = row.get('p1_team_details', [])\n            \n            timeline = row.get('battle_timeline', [])\n            (\n                p1_alive_pokemon_names,\n                p1_fnt_pokemon_names,\n                p2_alive_pokemon_names,\n            ) = extract_final_pokemon_status(timeline)\n            \n            p1_team_names = {pokemon.get('name', '') for pokemon in p1_team \n                           if pokemon and pokemon.get('name', '') not in p1_fnt_pokemon_names}\n            p1_alive_pokemon_names = p1_team_names | p1_alive_pokemon_names\n\n            p1_team_stats = calculate_team_stats(alive_pokemon_names=p1_alive_pokemon_names)\n\n            p2_team_stats = calculate_team_stats(alive_pokemon_names=p2_alive_pokemon_names)\n\n            for i, stat_name in enumerate(['hp', 'atk', 'def', 'spa', 'spd', 'spe']):\n                features[f'{stat_name}_advantage'] = p1_team_stats['mean'][i] - p2_team_stats['mean'][i]\n                features[f'{stat_name}_ratio'] = p1_team_stats['mean'][i] / (p2_team_stats['mean'][i] + 1)\n\n            p1_alive_team = []\n            for pokemon_name in p1_alive_pokemon_names:\n                pokemon_name_lower = pokemon_name.lower()\n                if pokemon_name_lower in pokemon_db:\n                    p1_alive_team.append(pokemon_db[pokemon_name_lower])\n            \n            p2_alive_team = []\n            for pokemon_name in p2_alive_pokemon_names:\n                pokemon_name_lower = pokemon_name.lower()\n                if pokemon_name_lower in pokemon_db:\n                    p2_alive_team.append(pokemon_db[pokemon_name_lower])\n            \n            type_adv = self.calculate_alive_teams_type_advantage(p1_alive_team, p2_alive_team)\n            \n            features['type_adv_mean'] = type_adv['type_adv_mean']\n            \n            features['type_adv_max'] = type_adv['type_adv_max']\n            \n            features['type_adv_min'] = type_adv['type_adv_min']\n            \n            features['type_adv_std'] = type_adv['type_adv_std']\n\n            p1_team_for_diversity = []\n            for pokemon_name in p1_alive_pokemon_names:\n                pokemon_name_lower = pokemon_name.lower()\n                if pokemon_name_lower in pokemon_db:\n                    p1_team_for_diversity.append(pokemon_db[pokemon_name_lower])\n            p1_diversity = self.calculate_team_diversity(p1_team_for_diversity)\n            features.update(p1_diversity)\n            \n            p2_team_for_diversity = []\n            for pokemon_name in p2_alive_pokemon_names:\n                pokemon_name_lower = pokemon_name.lower()\n                if pokemon_name_lower in pokemon_db:\n                    p2_team_for_diversity.append(pokemon_db[pokemon_name_lower])\n            p2_diversity = self.calculate_team_diversity(p2_team_for_diversity)\n            features.update({f'p2_{k}': v for k, v in p2_diversity.items()})\n            \n            p1_type_div = p1_diversity.get('type_diversity', 0)\n            p2_type_div = p2_diversity.get('type_diversity', 0)\n            p1_stat_div = p1_diversity.get('stat_diversity', 0)\n            p2_stat_div = p2_diversity.get('stat_diversity', 0)\n            \n            features['type_diversity_ratio'] = p1_type_div / (p2_type_div + 1e-6)\n            features['stat_diversity_ratio'] = p1_stat_div / (p2_stat_div + 1e-6)\n\n            p1_physical_atk = p1_team_stats['mean'][1]\n            p1_special_atk = p1_team_stats['mean'][3]\n            p1_physical_def = p1_team_stats['mean'][2]\n            p1_special_def = p1_team_stats['mean'][4]\n\n            features['physical_special_atk_ratio'] = p1_physical_atk / (p1_special_atk + 1)\n            features['physical_special_def_ratio'] = p1_physical_def / (p1_special_def + 1)\n            features['offense_defense_ratio'] = (p1_physical_atk + p1_special_atk) / (p1_physical_def + p1_special_def + 1)\n            \n            p2_physical_atk = p2_team_stats['mean'][1]\n            p2_special_atk = p2_team_stats['mean'][3]\n            p2_physical_def = p2_team_stats['mean'][2]\n            p2_special_def = p2_team_stats['mean'][4]\n\n            features['p2_physical_special_atk_ratio'] = p2_physical_atk / (p2_special_atk + 1)\n            features['p2_physical_special_def_ratio'] = p2_physical_def / (p2_special_def + 1)\n            features['p2_offense_defense_ratio'] = (p2_physical_atk + p2_special_atk) / (p2_physical_def + p2_special_def + 1)\n            \n            features['physical_special_atk_ratio_p1_p2'] = features['physical_special_atk_ratio'] / (features['p2_physical_special_atk_ratio'] + 1e-6)\n            features['physical_special_def_ratio_p1_p2'] = features['physical_special_def_ratio'] / (features['p2_physical_special_def_ratio'] + 1e-6)\n            features['offense_defense_ratio_p1_p2'] = features['offense_defense_ratio'] / (features['p2_offense_defense_ratio'] + 1e-6)\n\n            p1_total_stats_mean = sum(p1_team_stats['mean'])\n            p2_total_stats_mean = sum(p2_team_stats['mean'])\n            features['p1_total_stats_mean'] = p1_total_stats_mean\n            features['p2_total_stats_mean'] = p2_total_stats_mean\n            features['total_stats_advantage'] = p1_total_stats_mean - p2_total_stats_mean\n\n            return features\n\n        train_features = [extract_single_static_features(row) for _, row in self.train_data.iterrows()]\n\n        test_features = [extract_single_static_features(row) for _, row in self.test_data.iterrows()]\n\n        self.train_static_features = pd.DataFrame(train_features)\n        self.test_static_features = pd.DataFrame(test_features)\n\n        print(f\"Static feature extraction completed: {self.train_static_features.shape[1]}  features contributing most to this prediction\")\n        return self.train_static_features, self.test_static_features\n\n    def extract_dynamic_features(self):\n        print(\"\\n=== Extracting Dynamic Features (Enhanced) ===\")\n\n        pokemon_db = self.load_pokemon_database()\n\n        train_battle_features = []\n        for idx, row in self.train_data.iterrows():\n            timeline = row.get('battle_timeline', [])\n            battle_features = self.analyze_battle_timeline(row, timeline, pokemon_db, None)\n            train_battle_features.append(battle_features)\n\n        test_battle_features = []\n        for idx, row in self.test_data.iterrows():\n            timeline = row.get('battle_timeline', [])\n            battle_features = self.analyze_battle_timeline(row, timeline, pokemon_db, None)\n            test_battle_features.append(battle_features)\n\n        self.train_dynamic_features = pd.DataFrame(train_battle_features)\n        self.test_dynamic_features = pd.DataFrame(test_battle_features)\n\n        print(f\"Dynamic feature extraction completed: {self.train_dynamic_features.shape[1]}  features contributing most to this prediction\")\n        return self.train_dynamic_features, self.test_dynamic_features\n\n    def analyze_battle_timeline(self, row, timeline, pokemon_db=None, turn30_winrates=None):\n        if not timeline:\n            return {}\n\n        if pokemon_db is None:\n            pokemon_db = {}\n\n        if turn30_winrates is None:\n            turn30_winrates = {}\n\n        total_turns = len(timeline)\n\n        hp_features = self.extract_hp_features(timeline, total_turns)\n        move_features = self.extract_move_features(timeline)\n        status_features = self.extract_status_features(timeline)\n        strength_features = self.calculate_strength_features(timeline, pokemon_db)\n\n        features = {}\n        features.update(hp_features)\n        features.update(move_features)\n        features.update(status_features)\n        features.update(strength_features)\n\n        # \n        battle_data = {'battle_timeline': timeline}\n        p1_moves, p2_moves = extract_moves(battle_data)\n\n        p1_team_avg, p2_team_avg = type_multiplier(p1_moves, p2_moves)\n        features['p1_avg'] = p1_team_avg\n        features['p2_avg'] = p2_team_avg\n\n        features['p1_num_priority_moves'] = count_priority_moves(p1_moves)\n        features['p2_num_priority_moves'] = count_priority_moves(p2_moves)\n\n        return features\n\n    def create_interaction_features(self, df):\n        df_copy = df.copy()\n\n        if 'p1_avg_move_power' in df_copy.columns and 'p1_avg_accuracy' in df_copy.columns:\n            df_copy['p1_effective_power'] = df_copy['p1_avg_move_power'] * df_copy['p1_avg_accuracy']\n\n        if 'p2_avg_move_power' in df_copy.columns and 'p2_avg_accuracy' in df_copy.columns:\n            df_copy['p2_effective_power'] = df_copy['p2_avg_move_power'] * df_copy['p2_avg_accuracy']\n\n        if 'type_adv_mean' in df_copy.columns and 'total_stats_advantage' in df_copy.columns:\n            df_copy['type_stats_interaction'] = df_copy['type_adv_mean'] * df_copy['total_stats_advantage']\n\n        return df_copy\n\n    def combine_features(self):\n        print(\"\\n=== Combining Features and Creating Interactions ===\")\n\n        self.train_combined = pd.concat([\n            self.train_static_features.reset_index(drop=True),\n            self.train_dynamic_features.reset_index(drop=True)\n        ], axis=1)\n\n        self.test_combined = pd.concat([\n            self.test_static_features.reset_index(drop=True),\n            self.test_dynamic_features.reset_index(drop=True)\n        ], axis=1)\n\n        self.train_combined = self.create_interaction_features(self.train_combined)\n        self.test_combined = self.create_interaction_features(self.test_combined)\n\n        if self.features_to_remove:\n            print(f\"\\n=== Removing Configured Features ({len(self.features_to_remove)}) ===\")\n            features_to_remove_actual = []\n            for feature in self.features_to_remove:\n                if feature in self.train_combined.columns:\n                    features_to_remove_actual.append(feature)\n                else:\n                    print(f\"  Warning: Feature '{feature}'  does not exist, skipping removal\")\n            \n            if features_to_remove_actual:\n                self.train_combined = self.train_combined.drop(columns=features_to_remove_actual)\n                self.test_combined = self.test_combined.drop(columns=features_to_remove_actual)\n                print(f\"  ✓ Removed {len(features_to_remove_actual)}  features contributing most to this prediction: {features_to_remove_actual}\")\n            else:\n                print(\"  ⚠️ No features found to remove\")\n\n        self.train_combined = self.train_combined.fillna(0)\n        self.test_combined = self.test_combined.fillna(0)\n\n        train_cols = set(self.train_combined.columns)\n        test_cols = set(self.test_combined.columns)\n\n        missing_in_test = train_cols - test_cols\n        missing_in_train = test_cols - train_cols\n\n        for col in missing_in_test:\n            self.test_combined[col] = 0\n        for col in missing_in_train:\n            self.train_combined[col] = 0\n\n        self.test_combined = self.test_combined[self.train_combined.columns]\n\n        print(f\"Feature combination completed:\")\n        print(f\"Training feature shape: {self.train_combined.shape}\")\n        print(f\"Test feature shape: {self.test_combined.shape}\")\n\n        return self.train_combined, self.test_combined\n\n    def select_features_rfecv(self, X_train, y_train, estimator=None, cv=5, scoring='accuracy', min_features_to_select=10, n_jobs=-1):\n        print(f\"\\n=== RFECV Feature Selection ===\")\n        print(f\"Initial number of features: {X_train.shape[1]}\")\n        print(f\"Cross-validation folds: {cv}\")\n        print(f\"Minimum features to select: {min_features_to_select}\")\n        print(\"Calculating optimal number of features (this may take a few minutes)...\")\n\n        if estimator is None:\n            estimator = xgb.XGBClassifier(\n                n_estimators=100,\n                max_depth=6,\n                learning_rate=0.1,\n                subsample=0.8,\n                colsample_bytree=0.8,\n                min_child_weight=1,\n                gamma=0,\n                reg_alpha=0.01,\n                reg_lambda=0.01,\n                random_state=42,\n                eval_metric='logloss',\n                n_jobs=n_jobs\n            )\n        \n        rfecv = RFECV(\n            estimator=estimator,\n            step=1,\n            cv=cv,\n            scoring=scoring,\n            min_features_to_select=min_features_to_select,\n            n_jobs=n_jobs\n        )\n        \n        rfecv.fit(X_train, y_train)\n        \n        self.feature_selector = rfecv\n        \n        selected_mask = rfecv.support_\n        selected_features = X_train.columns[selected_mask].tolist()\n        optimal_n_features = rfecv.n_features_\n        \n        X_train_selected = rfecv.transform(X_train)\n        \n        if isinstance(X_train, pd.DataFrame):\n            X_train_selected = pd.DataFrame(\n                X_train_selected,\n                columns=selected_features,\n                index=X_train.index\n            )\n        \n        all_features = X_train.columns.tolist()\n        removed_features = [feat for feat in all_features if feat not in selected_features]\n        \n        print(f\"✓ RFECV Feature Selection completed\")\n        print(f\"  Optimal number of features: {optimal_n_features}\")\n        print(f\"  Number of selected features: {len(selected_features)}\")\n        print(f\"  Features reduced: {X_train.shape[1] - optimal_n_features}  ({(1 - optimal_n_features/X_train.shape[1])*100:.1f}%)\")\n\n        if removed_features:\n            print(f\"\\nRemoved features ({len(removed_features)} ):\")\n\n            removed_features_sorted = sorted(removed_features)\n\n            for i in range(0, len(removed_features_sorted), 5):\n                features_line = removed_features_sorted[i:i+5]\n                print(f\"  {', '.join(features_line)}\")\n        else:\n            print(f\"\\nNo features were removed\")\n\n        print(f\"\\nCross-validation score vs number of features:\")\n        print(f\"  Highest score: {rfecv.cv_results_['mean_test_score'].max():.4f}\")\n        print(f\"  Score at optimal number of features: {rfecv.cv_results_['mean_test_score'][rfecv.n_features_ - min_features_to_select]:.4f}\")\n        \n        return X_train_selected, selected_features, optimal_n_features\n\n    def save_misclassified_samples(self, y_true_indices, y_pred, y_true, model_name='best_model'):\n        print(f\"\\n=== Saving{model_name} misclassified samples ===\")\n\n        misclassified_mask = y_pred != y_true.values\n        misclassified_indices = y_true_indices[misclassified_mask]\n        \n        if len(misclassified_indices) == 0:\n            print(\"No misclassified samples!\")\n            return None, None\n        \n        print(f\"Found {len(misclassified_indices)} misclassified samples\")\n        \n        y_pred_wrong = y_pred[misclassified_mask]\n        y_true_wrong = y_true.values[misclassified_mask]\n        \n        misclassified_samples = []\n        for i, idx in enumerate(misclassified_indices):\n            sample = self.train_data.iloc[idx].to_dict()\n            \n            sample['prediction_info'] = {\n                'predicted': int(y_pred_wrong[i]),\n                'actual': int(y_true_wrong[i]),\n                'model': model_name,\n                'original_index': int(idx)\n            }\n            \n            misclassified_samples.append(sample)\n        \n        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n        output_file = f'misclassified/misclassified_samples_{model_name}_{timestamp}.json'\n        \n        with open(output_file, 'w', encoding='utf-8') as f:\n            json.dump(misclassified_samples, f, indent=2, ensure_ascii=False)\n        \n        print(f\"Misclassified samples saved to: {output_file}\")\n        \n        stats = {\n            'total_samples': len(y_true),\n            'misclassified_count': len(misclassified_indices),\n            'accuracy': 1 - (len(misclassified_indices) / len(y_true)),\n            'error_rate': len(misclassified_indices) / len(y_true),\n            'false_positive': int(((y_pred == 1) & (y_true == 0)).sum()),\n            'false_negative': int(((y_pred == 0) & (y_true == 1)).sum()),\n            'timestamp': timestamp,\n            'model_name': model_name\n        }\n        \n        stats_file = f'misclassified/misclassified_stats_{model_name}_{timestamp}.json'\n        with open(stats_file, 'w', encoding='utf-8') as f:\n            json.dump(stats, f, indent=2)\n        \n        print(f\"Statistics saved to: {stats_file}\")\n        print(f\"Accuracy: {stats['accuracy']:.4f}\")\n        print(f\"Error rate: {stats['error_rate']:.4f}\")\n        print(f\"False positive (predicted win but actually lost): {stats['false_positive']}\")\n        print(f\"False negative (predicted loss but actually won): {stats['false_negative']}\")\n        \n        return misclassified_samples, stats\n\n    def optimize_xgboost_hyperparams(self, X_train, y_train):\n        print(f\"\\n=== XGBoost Hyperparameter Optimization ===\")\n        print(f\"Number of trials: {self.optuna_n_trials}\")\n        print(f\"Cross-validation folds: {self.optuna_cv_folds}\")\n        print(f\"Timeout: {self.optuna_timeout} seconds\")\n\n        def objective(trial):\n\n            params = {\n\n                'n_estimators': trial.suggest_int('n_estimators', 200, 1000, step=100),\n                \n                'max_depth': trial.suggest_int('max_depth', 4, 12),\n                \n                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n                \n                'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n                \n                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n                \n                'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n                \n                'gamma': trial.suggest_float('gamma', 0, 0.5),\n                \n                'reg_alpha': trial.suggest_float('reg_alpha', 0.001, 1.0, log=True),\n                \n                'reg_lambda': trial.suggest_float('reg_lambda', 0.001, 1.0, log=True),\n                \n                'random_state': 42,\n                'eval_metric': 'logloss',\n                'n_jobs': -1\n            }\n\n            model = xgb.XGBClassifier(**params)\n\n            cv = StratifiedKFold(n_splits=self.optuna_cv_folds, shuffle=True, random_state=42)\n            scores = []\n\n            for fold_idx, (train_idx, val_idx) in enumerate(cv.split(X_train, y_train)):\n\n                X_fold_train = X_train.iloc[train_idx] if hasattr(X_train, 'iloc') else X_train[train_idx]\n                y_fold_train = y_train.iloc[train_idx] if hasattr(y_train, 'iloc') else y_train[train_idx]\n                X_fold_val = X_train.iloc[val_idx] if hasattr(X_train, 'iloc') else X_train[val_idx]\n                y_fold_val = y_train.iloc[val_idx] if hasattr(y_train, 'iloc') else y_train[val_idx]\n\n                model.fit(X_fold_train, y_fold_train)\n\n                y_pred = model.predict(X_fold_val)\n                fold_accuracy = accuracy_score(y_fold_val, y_pred)\n                scores.append(fold_accuracy)\n\n                trial.report(fold_accuracy, fold_idx)\n\n                if trial.should_prune():\n                    raise optuna.TrialPruned()\n\n            return np.mean(scores)\n\n        pruner = MedianPruner(\n            n_startup_trials=self.optuna_pruner_warmup,\n            n_warmup_steps=self.optuna_pruner_interval\n        )\n\n        optuna.logging.set_verbosity(optuna.logging.WARNING)\n        \n        study = optuna.create_study(\n            direction='maximize',\n            pruner=pruner,\n            study_name='xgboost_optimization'\n        )\n\n        study.optimize(\n            objective,\n            n_trials=self.optuna_n_trials,\n            timeout=self.optuna_timeout,\n            show_progress_bar=True\n        )\n\n        self.optuna_studies['XGBoost'] = study\n        self.optuna_best_params['XGBoost'] = study.best_params\n\n        print(f\"\\n✓ XGBoost optimization completed\")\n        print(f\"  Best accuracy: {study.best_value:.4f}\")\n        print(f\"  Best parameters:\")\n        for key, value in study.best_params.items():\n            print(f\"    {key}: {value}\")\n        print(f\"  Completed trials: {len(study.trials)}\")\n\n        print(f\"  Pruned trials: {len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED])}\")\n\n        return study.best_params\n\n    def optimize_lightgbm_hyperparams(self, X_train, y_train):\n        print(f\"\\n=== LightGBM Hyperparameter Optimization ===\")\n        print(f\"Number of trials: {self.optuna_n_trials}\")\n        print(f\"Cross-validation folds: {self.optuna_cv_folds}\")\n        print(f\"Timeout: {self.optuna_timeout} seconds\")\n\n        def objective(trial):\n\n            params = {\n\n                'n_estimators': trial.suggest_int('n_estimators', 200, 1000, step=100),\n                \n                'max_depth': trial.suggest_int('max_depth', 4, 12),\n                \n                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n                \n                'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n                \n                'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n                \n                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n                \n                'min_child_samples': trial.suggest_int('min_child_samples', 5, 50),\n                \n                'reg_alpha': trial.suggest_float('reg_alpha', 0.001, 1.0, log=True),\n                \n                'reg_lambda': trial.suggest_float('reg_lambda', 0.001, 1.0, log=True),\n                \n                'random_state': 42,\n                'verbose': -1,\n                'n_jobs': -1\n            }\n\n            model = lgb.LGBMClassifier(**params)\n\n            cv = StratifiedKFold(n_splits=self.optuna_cv_folds, shuffle=True, random_state=42)\n            scores = []\n\n            for fold_idx, (train_idx, val_idx) in enumerate(cv.split(X_train, y_train)):\n                X_fold_train = X_train.iloc[train_idx] if hasattr(X_train, 'iloc') else X_train[train_idx]\n                y_fold_train = y_train.iloc[train_idx] if hasattr(y_train, 'iloc') else y_train[train_idx]\n                X_fold_val = X_train.iloc[val_idx] if hasattr(X_train, 'iloc') else X_train[val_idx]\n                y_fold_val = y_train.iloc[val_idx] if hasattr(y_train, 'iloc') else y_train[val_idx]\n\n                model.fit(X_fold_train, y_fold_train)\n\n                y_pred = model.predict(X_fold_val)\n                fold_accuracy = accuracy_score(y_fold_val, y_pred)\n                scores.append(fold_accuracy)\n\n                trial.report(fold_accuracy, fold_idx)\n\n                if trial.should_prune():\n                    raise optuna.TrialPruned()\n\n            return np.mean(scores)\n\n        pruner = MedianPruner(\n            n_startup_trials=self.optuna_pruner_warmup,\n            n_warmup_steps=self.optuna_pruner_interval\n        )\n\n        optuna.logging.set_verbosity(optuna.logging.WARNING)\n        study = optuna.create_study(\n            direction='maximize',\n            pruner=pruner,\n            study_name='lightgbm_optimization'\n        )\n\n        study.optimize(\n            objective,\n            n_trials=self.optuna_n_trials,\n            timeout=self.optuna_timeout,\n            show_progress_bar=True\n        )\n\n        self.optuna_studies['LightGBM'] = study\n        self.optuna_best_params['LightGBM'] = study.best_params\n\n        print(f\"\\n✓ LightGBM optimization completed\")\n        print(f\"  Best accuracy: {study.best_value:.4f}\")\n        print(f\"  Best parameters:\")\n        for key, value in study.best_params.items():\n            print(f\"    {key}: {value}\")\n        print(f\"  Completed trials: {len(study.trials)}\")\n        print(f\"  Pruned trials: {len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED])}\")\n\n        return study.best_params\n\n    def optimize_catboost_hyperparams(self, X_train, y_train):\n        print(f\"\\n=== CatBoost Hyperparameter Optimization ===\")\n        print(f\"Number of trials: {self.optuna_n_trials}\")\n        print(f\"Cross-validation folds: {self.optuna_cv_folds}\")\n        print(f\"Timeout: {self.optuna_timeout} seconds\")\n\n        def objective(trial):\n\n            params = {\n\n                'iterations': trial.suggest_int('iterations', 200, 1000, step=100),\n                \n                'depth': trial.suggest_int('depth', 4, 10),\n                \n                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n                \n                'l2_leaf_reg': trial.suggest_int('l2_leaf_reg', 1, 10),\n                \n                'random_seed': 42,\n                'verbose': False,\n                'thread_count': -1\n            }\n\n            model = CatBoostClassifier(**params)\n\n            cv = StratifiedKFold(n_splits=self.optuna_cv_folds, shuffle=True, random_state=42)\n            scores = []\n\n            for fold_idx, (train_idx, val_idx) in enumerate(cv.split(X_train, y_train)):\n                X_fold_train = X_train.iloc[train_idx] if hasattr(X_train, 'iloc') else X_train[train_idx]\n                y_fold_train = y_train.iloc[train_idx] if hasattr(y_train, 'iloc') else y_train[train_idx]\n                X_fold_val = X_train.iloc[val_idx] if hasattr(X_train, 'iloc') else X_train[val_idx]\n                y_fold_val = y_train.iloc[val_idx] if hasattr(y_train, 'iloc') else y_train[val_idx]\n\n                model.fit(X_fold_train, y_fold_train)\n\n                y_pred = model.predict(X_fold_val)\n                fold_accuracy = accuracy_score(y_fold_val, y_pred)\n                scores.append(fold_accuracy)\n\n                trial.report(fold_accuracy, fold_idx)\n\n                if trial.should_prune():\n                    raise optuna.TrialPruned()\n\n            return np.mean(scores)\n\n        pruner = MedianPruner(\n            n_startup_trials=self.optuna_pruner_warmup,\n            n_warmup_steps=self.optuna_pruner_interval\n        )\n\n        optuna.logging.set_verbosity(optuna.logging.WARNING)\n        study = optuna.create_study(\n            direction='maximize',\n            pruner=pruner,\n            study_name='catboost_optimization'\n        )\n\n        study.optimize(\n            objective,\n            n_trials=self.optuna_n_trials,\n            timeout=self.optuna_timeout,\n            show_progress_bar=True\n        )\n\n        self.optuna_studies['CatBoost'] = study\n        self.optuna_best_params['CatBoost'] = study.best_params\n\n        print(f\"\\n✓ CatBoost optimization completed\")\n        print(f\"  Best accuracy: {study.best_value:.4f}\")\n        print(f\"  Best parameters:\")\n        for key, value in study.best_params.items():\n            print(f\"    {key}: {value}\")\n        print(f\"  Completed trials: {len(study.trials)}\")\n        print(f\"  Pruned trials: {len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED])}\")\n\n        return study.best_params\n\n    def save_optuna_results(self, output_dir='optuna_results'):\n\n        if not self.optuna_studies:\n            print(\"⚠️ No Optuna optimization results to save\")\n            return\n\n        if not os.path.exists(output_dir):\n            os.makedirs(output_dir)\n\n        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n\n        print(f\"\\n=== Saving Optuna Optimization Results ===\")\n        print(f\"Output directory: {output_dir}\")\n\n        for model_name, study in self.optuna_studies.items():\n\n            best_params_file = os.path.join(output_dir, f'{model_name}_best_params_{timestamp}.json')\n            with open(best_params_file, 'w', encoding='utf-8') as f:\n                json.dump({\n                    'model': model_name,\n                    'best_value': study.best_value,\n                    'best_params': study.best_params,\n                    'n_trials': len(study.trials),\n                    'n_pruned': len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]),\n                    'timestamp': timestamp\n                }, f, indent=2, ensure_ascii=False)\n            print(f\"✓ {model_name} Best parameters saved: {best_params_file}\")\n\n            trials_df = study.trials_dataframe()\n            history_file = os.path.join(output_dir, f'{model_name}_optimization_history_{timestamp}.csv')\n            trials_df.to_csv(history_file, index=False)\n            print(f\"✓ {model_name} Optimization history saved: {history_file}\")\n\n            print(f\"\\n{model_name} Optimization statistics:\")\n            print(f\"  Total trials: {len(study.trials)}\")\n\n            print(f\"  Completed trials: {len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])}\")\n\n            print(f\"  Pruned trials: {len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED])}\")\n\n            print(f\"  Failed trials: {len([t for t in study.trials if t.state == optuna.trial.TrialState.FAIL])}\")\n            print(f\"  Best accuracy: {study.best_value:.4f}\")\n            print(f\"  Best parameters: {study.best_params}\")\n\n        print(f\"\\n✓ All Optuna results saved to {output_dir}\")\n\n    def train_models(self):\n        print(\"\\n=== Model Training (Stacking Ensemble) ===\")\n\n        X = self.train_combined\n        y = self.train_data['player_won']\n\n        xgb_cv_params = dict(\n            n_estimators=800,\n            max_depth=8,\n            learning_rate=0.03,\n            subsample=0.85,\n            colsample_bytree=0.85,\n            min_child_weight=2,\n            gamma=0.05,\n            reg_alpha=0.1,\n            reg_lambda=0.1,\n            random_state=42,\n            eval_metric='logloss',\n            n_jobs=-1\n        )\n        print(\"\\nPerforming XGBoost 4-fold cross-validation evaluation (all labeled samples)...\")\n        xgb_cv_model = xgb.XGBClassifier(**xgb_cv_params)\n        xgb_cv_splitter = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n        xgb_cv_scores = cross_val_score(\n            xgb_cv_model,\n            X,\n            y,\n            cv=xgb_cv_splitter,\n            scoring='accuracy',\n            n_jobs=-1\n        )\n        print(f\"XGBoost 4-fold cross-validation accuracy: {xgb_cv_scores.mean():.4f} ± {xgb_cv_scores.std():.4f}\")\n\n        X_train, X_val, y_train, y_val = train_test_split(\n            X, y, test_size=self.validation_split, random_state=42, stratify=y\n        )\n\n        self.X_val = X_val\n        self.y_val = y_val\n\n        val_indices = y_val.index.to_numpy()\n\n        use_rfecv = True\n        if use_rfecv:\n            X_train_selected, selected_features, optimal_n = self.select_features_rfecv(\n                X_train, y_train,\n                estimator=None,\n                cv=4,\n                scoring='accuracy',\n                min_features_to_select=20,\n                n_jobs=-1\n            )\n            X_val_selected = self.feature_selector.transform(X_val)\n\n            X_train = X_train_selected\n            X_val = X_val_selected\n            print(f\"\\nTraining models with RFECV-selected features\")\n            print(f\"Training feature shape: {X_train.shape}, Validation feature shape: {X_val.shape}\")\n\n        xgb_best_params = None\n        lgb_best_params = None\n        cat_best_params = None\n\n        if self.use_optuna_tuning:\n            print(f\"\\n{'='*80}\")\n            print(\"=== Starting Optuna Hyperparameter Optimization ===\")\n            print(f\"{'='*80}\")\n            print(f\"Optimization configuration:\")\n            print(f\"  - Number of trials per model: {self.optuna_n_trials}\")\n            print(f\"  - Cross-validation folds: {self.optuna_cv_folds}\")\n            print(f\"  - Timeout per model: {self.optuna_timeout} seconds\")\n            print(f\"  - Pruner warmup steps: {self.optuna_pruner_warmup}\")\n\n            xgb_best_params = self.optimize_xgboost_hyperparams(X_train, y_train)\n\n            lgb_best_params = self.optimize_lightgbm_hyperparams(X_train, y_train)\n\n            cat_best_params = self.optimize_catboost_hyperparams(X_train, y_train)\n\n            self.save_optuna_results(output_dir='optuna_results')\n\n            print(f\"\\n{'='*80}\")\n            print(\"=== Optuna Hyperparameter Optimization Completed ===\")\n            print(f\"{'='*80}\")\n        else:\n            print(\"\\n⚠️ Optuna hyperparameter optimization disabled, using default parameters\")\n\n        X_train_final = X_train.copy()\n        y_train_final = y_train.copy()\n\n        print(f\"\\n=== Formal Model Training ===\")\n        print(f\"Training data size: {len(X_train_final)}  samples\")\n\n        if self.use_optuna_tuning and xgb_best_params:\n\n            print(\"\\n✓ Using Optuna-optimized XGBoost parameters\")\n            xgb_params = {\n                **xgb_best_params,\n                'random_state': 42,\n                'eval_metric': 'logloss',\n                'n_jobs': -1\n            }\n        else:\n\n            xgb_params = xgb_cv_params\n\n        if self.use_optuna_tuning and lgb_best_params:\n\n            print(\"✓ Using Optuna-optimized LightGBM parameters\")\n            lgb_params = {\n                **lgb_best_params,\n                'random_state': 42,\n                'verbose': -1,\n                'n_jobs': -1\n            }\n        else:\n\n            lgb_params = {\n                'n_estimators': 800,\n                'max_depth': 10,\n                'learning_rate': 0.03,\n                'subsample': 0.85,\n                'colsample_bytree': 0.85,\n                'min_child_samples': 15,\n                'reg_alpha': 0.1,\n                'reg_lambda': 0.1,\n                'num_leaves': 50,\n                'random_state': 42,\n                'verbose': -1,\n                'n_jobs': -1\n            }\n\n        if self.use_optuna_tuning and cat_best_params:\n\n            print(\"✓ Using Optuna-optimized CatBoost parameters\")\n            cat_params = {\n                **cat_best_params,\n                'random_seed': 42,\n                'verbose': False,\n                'thread_count': -1\n            }\n        else:\n\n            cat_params = {\n                'iterations': 800,\n                'depth': 9,\n                'learning_rate': 0.03,\n                'l2_leaf_reg': 2,\n                'random_seed': 42,\n                'verbose': False,\n                'thread_count': -1\n            }\n\n        base_models = {\n            'XGBoost': xgb.XGBClassifier(**xgb_params),\n            'LightGBM': lgb.LGBMClassifier(**lgb_params),\n            'CatBoost': CatBoostClassifier(**cat_params)\n        }\n\n        for name, model in base_models.items():\n            print(f\"Training {name}...\")\n            model.fit(X_train_final, y_train_final)\n\n            y_pred = model.predict(X_val)\n            accuracy = accuracy_score(y_val, y_pred)\n\n            print(f\"{name} Validation accuracy: {accuracy:.4f}\")\n\n            self.models[name] = model\n\n            if hasattr(model, 'feature_importances_'):\n                self.feature_importance[name] = model.feature_importances_\n\n        print(\"\\nTraining Stacking ensemble model...\")\n\n        stacking_estimators = [\n            ('XGBoost', base_models['XGBoost']),\n            ('LightGBM', base_models['LightGBM']),\n            ('CatBoost', base_models['CatBoost'])\n        ]\n\n        stacking_model = StackingClassifier(\n            estimators=stacking_estimators,\n            final_estimator=LogisticRegression(C=1.0, max_iter=500, random_state=42),\n            cv=2,\n            n_jobs=1\n        )\n\n        try:\n            stacking_model.fit(X_train_final, y_train_final)\n            y_pred_stacking = stacking_model.predict(X_val)\n            stacking_accuracy = accuracy_score(y_val, y_pred_stacking)\n            print(f\"Stacking ensemble model validation accuracy: {stacking_accuracy:.4f}\")\n            self.models['Stacking'] = stacking_model\n        except Exception as e:\n            print(f\"Stacking training failed: {e}\")\n            print(\"Skipping Stacking model, using best base model as fallback\")\n\n        if 'Stacking' in self.models:\n            self.best_model_name = 'Stacking'\n            self.best_model = self.models['Stacking']\n            best_predictions = self.models['Stacking'].predict(X_val)\n        else:\n            # Stacking，\n            best_accuracy = 0\n            best_model_name = 'XGBoost'  # \n\n            for name in ['XGBoost', 'LightGBM', 'CatBoost']:\n                if name in self.models:\n                    model = self.models[name]\n                    y_pred = model.predict(X_val)\n                    accuracy = accuracy_score(y_val, y_pred)\n                    if accuracy > best_accuracy:\n                        best_accuracy = accuracy\n                        best_model_name = name\n\n            self.best_model_name = best_model_name\n            self.best_model = self.models[best_model_name]\n            best_predictions = self.models[best_model_name].predict(X_val)\n\n        return self.models\n\n    def make_predictions(self):\n        print(\"\\n=== Generating Predictions ===\")\n\n        test_features = self.test_combined\n        if hasattr(self, 'feature_selector') and self.feature_selector is not None:\n            print(\"Applying feature selection to test data...\")\n            test_features_array = self.feature_selector.transform(self.test_combined)\n\n            if isinstance(self.test_combined, pd.DataFrame):\n                selected_features = self.test_combined.columns[self.feature_selector.support_].tolist()\n                test_features = pd.DataFrame(\n                    test_features_array,\n                    columns=selected_features,\n                    index=self.test_combined.index\n                )\n            else:\n                test_features = test_features_array\n            print(f\"Test feature shape: {test_features.shape}\")\n\n        predictions = {}\n\n        for name, model in self.models.items():\n            pred = model.predict(test_features)\n            predictions[name] = pred\n            print(f\"{name} Prediction completed\")\n\n        if 'Stacking' in predictions:\n            best_predictions = predictions['Stacking']\n            print(\"Using Stacking model to generate final predictions\")\n        else:\n            # Stacking，self.best_model_name\n            best_predictions = predictions[self.best_model_name]\n            print(f\"Using {self.best_model_name} model to generate final predictions\")\n\n        submission = pd.DataFrame({\n            'battle_id': self.test_data['battle_id'],\n            'player_won': best_predictions.astype(int)\n        })\n\n        submission.to_csv('submission_enhanced_v4.csv', index=False)\n        print(\"Submission file generated: submission_enhanced_v4.csv\")\n\n        return submission, predictions\n\n    def get_sample_features(self, original_index):\n        if self.train_combined is None:\n            print(\"Error: Please run feature extraction first (extract_static_features, extract_dynamic_features, combine_features)\")\n            return None\n\n        if original_index >= len(self.train_combined):\n            print(f\"Error: Index out of range (Maximum: {len(self.train_combined)-1})\")\n            return None\n\n        return self.train_combined.iloc[original_index].to_dict()\n\n    def explain_single_prediction(self, sample_index, model_name='XGBoost', top_k=20, use_shap=True):\n        print(\"\\n\" + \"=\"*80)\n        print(f\"Explaining sample #{sample_index} prediction results\")\n        print(\"=\"*80)\n        \n        if self.train_combined is None:\n            print(\"Error: Please run feature extraction first\")\n            return None\n        \n        if model_name not in self.models:\n            print(f\"Error: Model '{model_name}'  does not exist\")\n            print(f\"Available models: {list(self.models.keys())}\")\n            return None\n        \n        model = self.models[model_name]\n        \n        if sample_index >= len(self.train_combined):\n            print(f\"Error: Index out of range (Maximum: {len(self.train_combined)-1})\")\n            return None\n        \n        sample_features = self.train_combined.iloc[sample_index:sample_index+1]\n        feature_names = self.train_combined.columns.tolist()\n        \n        prediction = model.predict(sample_features)[0]\n        prediction_proba = model.predict_proba(sample_features)[0]\n        \n        print(f\"\\n📊 Prediction Results:\")\n        print(f\"   Predicted class: {prediction} ({'P1 wins' if prediction == 1 else 'P2 wins'})\")\n        print(f\"   Prediction probability: P1 wins={prediction_proba[1]:.4f}, P2 wins={prediction_proba[0]:.4f}\")\n        print(f\"   Confidence: {max(prediction_proba):.4f}\")\n\n        if use_shap:\n            try:\n                import shap\n                print(f\"\\n🔍 Using SHAP values to explain prediction (showing top {top_k} features)...\")\n                \n                explainer = shap.TreeExplainer(model)\n                \n                if self.X_val is not None and len(self.X_val) > 100:\n\n                    background_data = self.X_val.iloc[:100]\n                    shap_values = explainer.shap_values(sample_features, background_data)\n                else:\n\n                    shap_values = explainer.shap_values(sample_features)\n                \n                if isinstance(shap_values, list):\n                    shap_values = shap_values[1] if len(shap_values) > 1 else shap_values[0]\n                \n                if len(shap_values.shape) > 1:\n                    sample_shap = shap_values[0]\n                else:\n                    sample_shap = shap_values\n                \n                feature_contributions = pd.DataFrame({\n                    'feature': feature_names,\n                    'shap_value': sample_shap,\n                    'feature_value': sample_features.iloc[0].values,\n                    'abs_shap': np.abs(sample_shap)\n                })\n                \n                feature_contributions = feature_contributions.sort_values('abs_shap', ascending=False)\n                \n                print(f\"\\n📈 Top {top_k} features contributing most to this prediction:\")\n                print(\"-\" * 80)\n                print(f\"{'Rank':<6} {'Feature Name':<40} {'Feature Value':<15} {'SHAP Value':<12} {'Direction':<10}\")\n                print(\"-\" * 80)\n                \n                for i, (idx, row) in enumerate(feature_contributions.head(top_k).iterrows(), 1):\n                    direction = \"↑ Supports P1\" if row['shap_value'] > 0 else \"↓ Supports P2\"\n                    print(f\"{i:<6} {row['feature']:<40} {row['feature_value']:<15.4f} {row['shap_value']:<12.6f} {direction:<10}\")\n                \n                positive_contrib = feature_contributions[feature_contributions['shap_value'] > 0]['shap_value'].sum()\n                negative_contrib = feature_contributions[feature_contributions['shap_value'] < 0]['shap_value'].sum()\n                \n                print(f\"\\n💡 Contribution Summary:\")\n                print(f\"   Total contribution supporting P1 win: {positive_contrib:.4f}\")\n                print(f\"   Total contribution supporting P2 win: {abs(negative_contrib):.4f}\")\n                print(f\"   Net contribution: {positive_contrib + negative_contrib:.4f}\")\n                \n                return {\n                    'sample_index': sample_index,\n                    'prediction': int(prediction),\n                    'prediction_proba': prediction_proba,\n                    'feature_contributions': feature_contributions,\n                    'method': 'SHAP'\n                }\n                \n            except ImportError:\n                print(\"⚠️ SHAP library not installed, using feature importance method...\")\n                use_shap = False\n            except Exception as e:\n                print(f\"⚠️ SHAP calculation failed: {e}\")\n                print(\"Using feature importance method...\")\n                use_shap = False\n        \n        return None\n\n    def analyze_results(self):\n        print(\"\\n=== Results Analysis ===\")\n\n        if self.feature_importance:\n            print(\"\\nFeature Importance Analysis:\")\n            for model_name, importance in self.feature_importance.items():\n                print(f\"\\n{model_name} Top 15 important features:\")\n                feature_names = self.train_combined.columns\n                importance_df = pd.DataFrame({\n                    'feature': feature_names,\n                    'importance': importance\n                }).sort_values('importance', ascending=False)\n                print(importance_df.head(15))\n\n        return self.feature_importance\n\ndef main():\n\n    log_file_path = setup_logging(log_dir='print_log')\n    print(f\"Logging system started, output will be saved to: {log_file_path}\")\n    \n    try:\n        print(\"Pokemon Battles Prediction 2025 - Enhanced Version\")\n        print(\"=\" * 60)\n\n        predictor = PokemonBattlePredictorEnhanced()\n\n        if os.path.exists('input/train.jsonl') and os.path.exists('input/test.jsonl'):\n            train_data, test_data = predictor.load_data('input/train.jsonl', 'input/test.jsonl')\n        else:\n            train_data, test_data = predictor.load_data('../input/fds-pokemon-battles-prediction-2025/train.jsonl', '../input/fds-pokemon-battles-prediction-2025/test.jsonl')\n\n        predictor.extract_static_features()\n        predictor.extract_dynamic_features()\n        predictor.combine_features()\n\n        predictor.train_models()\n\n        submission, predictions = predictor.make_predictions()\n\n        # predictor.analyze_results()\n        \n        print(\"\\n\" + \"=\"*60)\n\n        print(\"\\nTask completed!\")\n        print(\"Please check submission_enhanced_v4.csv file\")\n        print(\"Feature analysis report generated\")\n        print(\"\\n💡 Tip: To explain a single sample's prediction, you can use:\")\n        print(\"   predictor.explain_single_prediction(sample_index=6678, model_name='XGBoost', top_k=20)\")\n\n    except FileNotFoundError as e:\n        print(f\"Error: Data file not found - {e}\")\n        print(\"Please ensure train.jsonl and test.jsonl files exist in the input/ directory\")\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        import traceback\n        print(traceback.format_exc())\n    finally:\n\n        close_logging()\n        print(f\"\\nLog file saved: {log_file_path}\")\n\n# [\\u4e00-\\u9fa5]\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-11-14T23:52:53.893808Z","iopub.execute_input":"2025-11-14T23:52:53.894106Z","iopub.status.idle":"2025-11-14T23:57:45.578565Z","shell.execute_reply.started":"2025-11-14T23:52:53.894085Z","shell.execute_reply":"2025-11-14T23:57:45.577595Z"}},"outputs":[{"name":"stdout","text":"Logging system started, output will be saved to: print_log/print_log_20251114_235303.log\nPokemon Battles Prediction 2025 - Enhanced Version\n============================================================\nLoading data...\nTraining data loaded: 10000  records\nTest data loaded: 5000  records\n\n=== Extracting Static Features (Enhanced) ===\n✓ Loaded 20  Pokemon attribute data\nStatic feature extraction completed: 34  features contributing most to this prediction\n\n=== Extracting Dynamic Features (Enhanced) ===\n✓ Loaded 20  Pokemon attribute data\nDynamic feature extraction completed: 24  features contributing most to this prediction\n\n=== Combining Features and Creating Interactions ===\nFeature combination completed:\nTraining feature shape: (10000, 59)\nTest feature shape: (5000, 59)\n\n=== Model Training (Stacking Ensemble) ===\n\nPerforming XGBoost 4-fold cross-validation evaluation (all labeled samples)...\nXGBoost 4-fold cross-validation accuracy: 0.8436 ± 0.0039\n\n=== RFECV Feature Selection ===\nInitial number of features: 59\nCross-validation folds: 4\nMinimum features to select: 20\nCalculating optimal number of features (this may take a few minutes)...\n✓ RFECV Feature Selection completed\n  Optimal number of features: 54\n  Number of selected features: 54\n  Features reduced: 5  (8.5%)\n\nRemoved features (5 ):\n  p1_avg_accuracy, p1_max_hp_loss, p2_counter_invalid, p2_physical_special_def_ratio, type_adv_std\n\nCross-validation score vs number of features:\n  Highest score: 0.8438\n  Score at optimal number of features: 0.8438\n\nTraining models with RFECV-selected features\nTraining feature shape: (9000, 54), Validation feature shape: (1000, 54)\n\n⚠️ Optuna hyperparameter optimization disabled, using default parameters\n\n=== Formal Model Training ===\nTraining data size: 9000  samples\nTraining XGBoost...\nXGBoost Validation accuracy: 0.8540\nTraining LightGBM...\nLightGBM Validation accuracy: 0.8570\nTraining CatBoost...\nCatBoost Validation accuracy: 0.8600\n\nTraining Stacking ensemble model...\nStacking ensemble model validation accuracy: 0.8610\n\n=== Generating Predictions ===\nApplying feature selection to test data...\nTest feature shape: (5000, 54)\nXGBoost Prediction completed\nLightGBM Prediction completed\nCatBoost Prediction completed\nStacking Prediction completed\nUsing Stacking model to generate final predictions\nSubmission file generated: submission_enhanced_v4.csv\n\n============================================================\n\nTask completed!\nPlease check submission_enhanced_v4.csv file\nFeature analysis report generated\n\n💡 Tip: To explain a single sample's prediction, you can use:\n   predictor.explain_single_prediction(sample_index=6678, model_name='XGBoost', top_k=20)\n\nLog file saved: print_log/print_log_20251114_235303.log\n","output_type":"stream"}],"execution_count":6}]}
