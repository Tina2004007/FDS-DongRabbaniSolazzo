{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa727d75",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-14T18:38:44.342586Z",
     "iopub.status.busy": "2025-11-14T18:38:44.342245Z",
     "iopub.status.idle": "2025-11-14T18:40:49.999421Z",
     "shell.execute_reply": "2025-11-14T18:40:49.998166Z"
    },
    "papermill": {
     "duration": 125.671884,
     "end_time": "2025-11-14T18:40:50.001094",
     "exception": false,
     "start_time": "2025-11-14T18:38:44.329210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging system started, output will be saved to: print_log/print_log_20251114_183854.log\n",
      "Pokemon Battles Prediction 2025 - Enhanced Version\n",
      "============================================================\n",
      "Loading data...\n",
      "Training data loaded: 10000  records\n",
      "Test data loaded: 5000  records\n",
      "\n",
      "=== Extracting static features (Enhanced) ===\n",
      "Static features extraction completed: 60  features\n",
      "\n",
      "=== Extracting dynamic features (Enhanced) ===\n",
      "\n",
      "Collecting all move list...\n",
      "âœ“ Found 40  unique moves\n",
      "Dynamic features extraction completed: 81  features\n",
      "\n",
      "=== Combining features and creating interactions ===\n",
      "\n",
      "=== Removing configured features (8) ===\n",
      "  âœ“ Removed 8  features: ['p1_unique_pokemon_count_30turns', 'p2_unique_pokemon_count_30turns', 'p1_switch_count', 'p2_switch_count', 'p1_hp_min', 'p2_hp_min', 'p2_move_null_switch', 'p1_move_null_switch']\n",
      "Feature combination completed:\n",
      "Training feature shape: (10000, 137)\n",
      "Test feature shape: (5000, 137)\n",
      "\n",
      "=== Model Training (Stacking Ensemble) ===\n",
      "Training XGBoost...\n",
      "XGBoost Validation accuracy: 0.8580\n",
      "Training LightGBM...\n",
      "LightGBM Validation accuracy: 0.8610\n",
      "Training CatBoost...\n",
      "CatBoost Validation accuracy: 0.8550\n",
      "\n",
      "Training Stacking ensemble model...\n",
      "Stacking ensemble model validation accuracy: 0.8570\n",
      "\n",
      "=== Generating predictions ===\n",
      "XGBoost Prediction completed\n",
      "LightGBM Prediction completed\n",
      "CatBoost Prediction completed\n",
      "Stacking Prediction completed\n",
      "Using Stacking model for final predictions\n",
      "Submission file generated: submission_enhanced_v2.csv\n",
      "\n",
      "============================================================\n",
      "Starting feature removal impact test...\n",
      "============================================================\n",
      "\n",
      "================================================================================\n",
      "Explaining sample #7433 prediction\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š Prediction results:\n",
      "   Predicted class: 1 (P1 wins)\n",
      "   Prediction probability: P1 wins=0.9582, P2 wins=0.0418\n",
      "   Confidence: 0.9582\n",
      "\n",
      "ðŸ” Using SHAP values to explain prediction (showing top 20 features)...\n",
      "\n",
      "ðŸ“ˆ Top 20 features contributing to this prediction:\n",
      "--------------------------------------------------------------------------------\n",
      "Rank   Feature                                  Value           SHAP Value   Direction \n",
      "--------------------------------------------------------------------------------\n",
      "1      total_pokemon_hp_pct_ratio_30turns       1.0309          2.029645     â†‘ Supports P1\n",
      "2      abnormal_status_count_ratio              0.2500          0.845142     â†‘ Supports P1\n",
      "3      p2_effect_turns                          9.0000          -0.342093    â†“ Supports P2\n",
      "4      p2_move_null_status                      5.0000          0.294539     â†‘ Supports P1\n",
      "5      p1_max_move_power                        120.0000        -0.241997    â†“ Supports P2\n",
      "6      p2_mid_hp_avg                            0.9240          0.180682     â†‘ Supports P1\n",
      "7      p2_physical_move_ratio                   0.6111          0.165529     â†‘ Supports P1\n",
      "8      p2_mid_hp_min                            0.5700          -0.165190    â†“ Supports P2\n",
      "9      p2_avg_move_power                        102.7273        -0.162892    â†“ Supports P2\n",
      "10     p2_special_move_ratio                    0.0000          0.151988     â†‘ Supports P1\n",
      "11     p2_hp_avg                                0.8020          0.149748     â†‘ Supports P1\n",
      "12     p2_avg_accuracy                          0.9139          -0.141494    â†“ Supports P2\n",
      "13     p2_avg_hp_loss                           0.0324          -0.135996    â†“ Supports P2\n",
      "14     p2_early_hp_min                          0.3300          0.132167     â†‘ Supports P1\n",
      "15     p2_max_move_power                        150.0000        0.118938     â†‘ Supports P1\n",
      "16     p2_early_switch_ratio                    0.4167          0.109597     â†‘ Supports P1\n",
      "17     p1_status_move_ratio                     0.2692          0.090345     â†‘ Supports P1\n",
      "18     p1_team_hp_sum                           265.0000        -0.090157    â†“ Supports P2\n",
      "19     hp_advantage_avg                         -0.0817         0.089500     â†‘ Supports P1\n",
      "20     p2_late_hp_avg                           0.6440          0.082737     â†‘ Supports P1\n",
      "\n",
      "ðŸ’¡ Contribution summary:\n",
      "   Total contribution supporting P1 win: 5.5638\n",
      "   Total contribution supporting P2 win: 2.4524\n",
      "   Net contribution: 3.1114\n",
      "\n",
      "Task completed!\n",
      "Please check submission_enhanced_v2.csv  file\n",
      "Feature analysis report generated\n",
      "\n",
      "ðŸ’¡ Tip: To explain a single sample prediction, you can use:\n",
      "   predictor.explain_single_prediction(sample_index=6678, model_name='XGBoost', top_k=20)\n",
      "\n",
      "Log file saved: print_log/print_log_20251114_183854.log\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif, RFE, RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.inspection import permutation_importance\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "_log_file_handle = None\n",
    "_original_print = print\n",
    "\n",
    "def setup_logging(log_dir='print_log'):\n",
    "    global _log_file_handle\n",
    "    \n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "    \n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    log_file_path = os.path.join(log_dir, f'print_log_{timestamp}.log')\n",
    "    \n",
    "    _log_file_handle = open(log_file_path, 'w', encoding='utf-8')\n",
    "    \n",
    "    return log_file_path\n",
    "\n",
    "def log_print(*args, **kwargs):\n",
    "    global _log_file_handle, _original_print\n",
    "    \n",
    "    file_param = kwargs.get('file', None)\n",
    "    \n",
    "    _original_print(*args, **kwargs)\n",
    "    \n",
    "    if _log_file_handle is not None and file_param is None:\n",
    "        try:\n",
    "            sep = kwargs.get('sep', ' ')\n",
    "            end = kwargs.get('end', '\\n')\n",
    "            \n",
    "            message = sep.join(str(arg) for arg in args) + end\n",
    "            \n",
    "            _log_file_handle.write(message)\n",
    "            _log_file_handle.flush()\n",
    "        except Exception as e:\n",
    "            _original_print(f\"Warning: Failed to write to log file: {e}\", file=sys.stderr)\n",
    "\n",
    "def close_logging():\n",
    "    global _log_file_handle\n",
    "    if _log_file_handle is not None:\n",
    "        _log_file_handle.close()\n",
    "        _log_file_handle = None\n",
    "\n",
    "print = log_print\n",
    "\n",
    "class PokemonBattlePredictorEnhanced:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.train_data = None\n",
    "        self.test_data = None\n",
    "        self.features = None\n",
    "        self.target = None\n",
    "        self.models = {}\n",
    "        self.feature_importance = {}\n",
    "        self.scaler = StandardScaler()\n",
    "        self.feature_selector = None\n",
    "        self.X_val = None\n",
    "        self.y_val = None\n",
    "        self.best_model = None\n",
    "        self.best_model_name = None\n",
    "        self.all_moves_list = None\n",
    "        \n",
    "        self.features_to_remove = ['p1_unique_pokemon_count_30turns','p2_unique_pokemon_count_30turns','p1_switch_count','p2_switch_count','p1_hp_min','p2_hp_min', 'p2_move_null_switch','p1_move_null_switch']\n",
    "\n",
    "    def get_all_moves_list(self, max_samples=10000):\n",
    "        if self.all_moves_list is not None:\n",
    "            return self.all_moves_list\n",
    "        \n",
    "        print(\"\\nCollecting all move list...\")\n",
    "        all_moves = set()\n",
    "        \n",
    "        sample_size = min(max_samples, len(self.train_data))\n",
    "        for idx in range(sample_size):\n",
    "            row = self.train_data.iloc[idx]\n",
    "            timeline = row.get('battle_timeline', [])\n",
    "            \n",
    "            for turn in timeline:\n",
    "                p1_move = turn.get('p1_move_details')\n",
    "                p2_move = turn.get('p2_move_details')\n",
    "                \n",
    "                if p1_move and p1_move.get('name'):\n",
    "                    all_moves.add(p1_move.get('name'))\n",
    "                \n",
    "                if p2_move and p2_move.get('name'):\n",
    "                    all_moves.add(p2_move.get('name'))\n",
    "        \n",
    "        self.all_moves_list = sorted(list(all_moves))\n",
    "        print(f\"âœ“ Found {len(self.all_moves_list)}  unique moves\")\n",
    "        \n",
    "        return self.all_moves_list\n",
    "\n",
    "    def load_data(self, train_path, test_path):\n",
    "        print(\"Loading data...\")\n",
    "\n",
    "        train_records = []\n",
    "        with open(train_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                train_records.append(json.loads(line.strip()))\n",
    "\n",
    "        test_records = []\n",
    "        with open(test_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                test_records.append(json.loads(line.strip()))\n",
    "\n",
    "        self.train_data = pd.DataFrame(train_records)\n",
    "        self.test_data = pd.DataFrame(test_records)\n",
    "\n",
    "        print(f\"Training data loaded: {len(self.train_data)}  records\")\n",
    "        print(f\"Test data loaded: {len(self.test_data)}  records\")\n",
    "\n",
    "        return self.train_data, self.test_data\n",
    "\n",
    "    def get_complete_type_effectiveness(self):\n",
    "        effectiveness = {\n",
    "            'normal': {'rock': 0.5, 'ghost': 0.0, 'steel': 0.5},\n",
    "            'fire': {'fire': 0.5, 'water': 0.5, 'grass': 2.0, 'ice': 2.0, 'bug': 2.0, 'rock': 0.5, 'dragon': 0.5, 'steel': 2.0},\n",
    "            'water': {'fire': 2.0, 'water': 0.5, 'grass': 0.5, 'ground': 2.0, 'rock': 2.0, 'dragon': 0.5},\n",
    "            'electric': {'water': 2.0, 'electric': 0.5, 'grass': 0.5, 'ground': 0.0, 'flying': 2.0, 'dragon': 0.5},\n",
    "            'grass': {'fire': 0.5, 'water': 2.0, 'grass': 0.5, 'poison': 0.5, 'ground': 2.0, 'flying': 0.5, 'bug': 0.5, 'rock': 2.0, 'dragon': 0.5, 'steel': 0.5},\n",
    "            'ice': {'fire': 0.5, 'water': 0.5, 'grass': 2.0, 'ice': 0.5, 'ground': 2.0, 'flying': 2.0, 'dragon': 2.0, 'steel': 0.5},\n",
    "            'fighting': {'normal': 2.0, 'ice': 2.0, 'poison': 0.5, 'flying': 0.5, 'psychic': 0.5, 'bug': 0.5, 'rock': 2.0, 'ghost': 0.0, 'dark': 2.0, 'steel': 2.0, 'fairy': 0.5},\n",
    "            'poison': {'grass': 2.0, 'poison': 0.5, 'ground': 0.5, 'rock': 0.5, 'ghost': 0.5, 'steel': 0.0, 'fairy': 2.0},\n",
    "            'ground': {'fire': 2.0, 'electric': 2.0, 'grass': 0.5, 'poison': 2.0, 'flying': 0.0, 'bug': 0.5, 'rock': 2.0, 'steel': 2.0},\n",
    "            'flying': {'electric': 0.5, 'grass': 2.0, 'fighting': 2.0, 'bug': 2.0, 'rock': 0.5, 'steel': 0.5},\n",
    "            'psychic': {'fighting': 2.0, 'poison': 2.0, 'psychic': 0.5, 'dark': 0.0, 'steel': 0.5},\n",
    "            'bug': {'fire': 0.5, 'grass': 2.0, 'fighting': 0.5, 'poison': 0.5, 'flying': 0.5, 'psychic': 2.0, 'ghost': 0.5, 'dark': 2.0, 'steel': 0.5, 'fairy': 0.5},\n",
    "            'rock': {'fire': 2.0, 'ice': 2.0, 'fighting': 0.5, 'ground': 0.5, 'flying': 2.0, 'bug': 2.0, 'steel': 0.5},\n",
    "            'ghost': {'normal': 0.0, 'psychic': 2.0, 'ghost': 2.0, 'dark': 0.5},\n",
    "            'dragon': {'dragon': 2.0, 'steel': 0.5, 'fairy': 0.0},\n",
    "            'dark': {'fighting': 0.5, 'psychic': 2.0, 'ghost': 2.0, 'dark': 0.5, 'fairy': 0.5},\n",
    "            'steel': {'fire': 0.5, 'water': 0.5, 'electric': 0.5, 'ice': 2.0, 'rock': 2.0, 'steel': 0.5, 'fairy': 2.0},\n",
    "            'fairy': {'fire': 0.5, 'fighting': 2.0, 'poison': 0.5, 'dragon': 2.0, 'dark': 2.0, 'steel': 0.5}\n",
    "        }\n",
    "        return effectiveness\n",
    "\n",
    "    def calculate_team_type_advantage(self, p1_team, p2_lead):\n",
    "        effectiveness = self.get_complete_type_effectiveness()\n",
    "\n",
    "        advantages = []\n",
    "        p2_types = p2_lead.get('types', []) if p2_lead else []\n",
    "\n",
    "        for pokemon in p1_team:\n",
    "            if not pokemon:\n",
    "                continue\n",
    "            p1_types = pokemon.get('types', [])\n",
    "\n",
    "            adv = 1.0\n",
    "            for p1_type in p1_types:\n",
    "                if p1_type.lower() in effectiveness:\n",
    "                    for p2_type in p2_types:\n",
    "                        if p2_type.lower() in effectiveness[p1_type.lower()]:\n",
    "                            adv *= effectiveness[p1_type.lower()][p2_type.lower()]\n",
    "            advantages.append(adv)\n",
    "\n",
    "        if not advantages:\n",
    "            return {'type_adv_mean': 1.0, 'type_adv_max': 1.0, 'type_adv_min': 1.0}\n",
    "\n",
    "        return {\n",
    "            'type_adv_mean': np.mean(advantages),\n",
    "            'type_adv_max': max(advantages),\n",
    "            'type_adv_min': min(advantages),\n",
    "            'type_adv_std': np.std(advantages) if len(advantages) > 1 else 0\n",
    "        }\n",
    "\n",
    "    def calculate_team_diversity(self, team):\n",
    "        if not team:\n",
    "            return {'type_diversity': 0, 'stat_diversity': 0}\n",
    "\n",
    "        all_types = []\n",
    "        for pokemon in team:\n",
    "            if pokemon and 'types' in pokemon:\n",
    "                all_types.extend(pokemon['types'])\n",
    "        type_diversity = len(set(all_types)) / max(len(all_types), 1)\n",
    "\n",
    "        stats_matrix = []\n",
    "        for pokemon in team:\n",
    "            if pokemon:\n",
    "                stats = [\n",
    "                    pokemon.get('base_hp', 0),\n",
    "                    pokemon.get('base_atk', 0),\n",
    "                    pokemon.get('base_def', 0),\n",
    "                    pokemon.get('base_spa', 0),\n",
    "                    pokemon.get('base_spd', 0),\n",
    "                    pokemon.get('base_spe', 0)\n",
    "                ]\n",
    "                stats_matrix.append(stats)\n",
    "\n",
    "        stat_diversity = 0\n",
    "        if stats_matrix:\n",
    "            stats_matrix = np.array(stats_matrix)\n",
    "            for i in range(6):\n",
    "                col = stats_matrix[:, i]\n",
    "                if np.mean(col) > 0:\n",
    "                    stat_diversity += np.std(col) / np.mean(col)\n",
    "            stat_diversity /= 6\n",
    "\n",
    "        return {'type_diversity': type_diversity, 'stat_diversity': stat_diversity}\n",
    "\n",
    "    def extract_static_features(self):\n",
    "        print(\"\\n=== Extracting static features (Enhanced) ===\")\n",
    "\n",
    "        def extract_pokemon_stats(pokemon):\n",
    "            if not pokemon:\n",
    "                return [0] * 6\n",
    "\n",
    "            return [\n",
    "                pokemon.get('base_hp', 0),\n",
    "                pokemon.get('base_atk', 0),\n",
    "                pokemon.get('base_def', 0),\n",
    "                pokemon.get('base_spa', 0),\n",
    "                pokemon.get('base_spd', 0),\n",
    "                pokemon.get('base_spe', 0)\n",
    "            ]\n",
    "\n",
    "        def calculate_team_stats(team, fnt_pokemon_names=None):\n",
    "            if not team:\n",
    "                return {'sum': [0]*6, 'mean': [0]*6, 'max': [0]*6, 'min': [0]*6, 'std': [0]*6}\n",
    "\n",
    "            stats_matrix = []\n",
    "            for pokemon in team:\n",
    "                if fnt_pokemon_names is not None:\n",
    "                    pokemon_name = pokemon.get('name', '') if pokemon else ''\n",
    "                    if pokemon_name in fnt_pokemon_names:\n",
    "                        continue\n",
    "                \n",
    "                stats = extract_pokemon_stats(pokemon)\n",
    "                stats_matrix.append(stats)\n",
    "\n",
    "            if not stats_matrix:\n",
    "                return {'sum': [0]*6, 'mean': [0]*6, 'max': [0]*6, 'min': [0]*6, 'std': [0]*6}\n",
    "\n",
    "            stats_matrix = np.array(stats_matrix)\n",
    "\n",
    "            return {\n",
    "                'sum': np.sum(stats_matrix, axis=0).tolist(),\n",
    "                'mean': np.mean(stats_matrix, axis=0).tolist(),\n",
    "                'max': np.max(stats_matrix, axis=0).tolist(),\n",
    "                'min': np.min(stats_matrix, axis=0).tolist(),\n",
    "                'std': np.std(stats_matrix, axis=0).tolist()\n",
    "            }\n",
    "\n",
    "        train_features = []\n",
    "        for idx, row in self.train_data.iterrows():\n",
    "            features = {}\n",
    "\n",
    "            p1_fnt_pokemon_names = set()\n",
    "            timeline = row.get('battle_timeline', [])\n",
    "            for turn in timeline:\n",
    "                p1_status = turn.get('p1_pokemon_state', {}).get('status', 'nostatus')\n",
    "                if p1_status == 'fnt':\n",
    "                    p1_pokemon_name = turn.get('p1_pokemon_state', {}).get('name', '')\n",
    "                    if p1_pokemon_name:\n",
    "                        p1_fnt_pokemon_names.add(p1_pokemon_name)\n",
    "\n",
    "            p1_team = row.get('p1_team_details', [])\n",
    "            p1_team_stats = calculate_team_stats(p1_team, fnt_pokemon_names=p1_fnt_pokemon_names)\n",
    "\n",
    "            p2_lead = row.get('p2_lead_details', {})\n",
    "            p2_stats = extract_pokemon_stats(p2_lead)\n",
    "\n",
    "            for agg_type in ['sum', 'mean', 'max', 'min', 'std']:\n",
    "                for i, stat_name in enumerate(['hp', 'atk', 'def', 'spa', 'spd', 'spe']):\n",
    "                    features[f'p1_team_{stat_name}_{agg_type}'] = p1_team_stats[agg_type][i]\n",
    "\n",
    "            for i, stat_name in enumerate(['hp', 'atk', 'def', 'spa', 'spd', 'spe']):\n",
    "                features[f'p2_lead_{stat_name}'] = p2_stats[i]\n",
    "\n",
    "            for i, stat_name in enumerate(['hp', 'atk', 'def', 'spa', 'spd', 'spe']):\n",
    "                features[f'{stat_name}_advantage'] = p1_team_stats['mean'][i] - p2_stats[i]\n",
    "                features[f'{stat_name}_ratio'] = p1_team_stats['mean'][i] / (p2_stats[i] + 1)\n",
    "\n",
    "            type_adv = self.calculate_team_type_advantage(p1_team, p2_lead)\n",
    "            features.update(type_adv)\n",
    "\n",
    "            diversity = self.calculate_team_diversity(p1_team)\n",
    "            features.update(diversity)\n",
    "\n",
    "            physical_atk = p1_team_stats['mean'][1]\n",
    "            special_atk = p1_team_stats['mean'][3]\n",
    "            physical_def = p1_team_stats['mean'][2]\n",
    "            special_def = p1_team_stats['mean'][4]\n",
    "\n",
    "            features['physical_special_atk_ratio'] = physical_atk / (special_atk + 1)\n",
    "            features['physical_special_def_ratio'] = physical_def / (special_def + 1)\n",
    "            features['offense_defense_ratio'] = (physical_atk + special_atk) / (physical_def + special_def + 1)\n",
    "\n",
    "            features['p1_total_stats'] = sum(p1_team_stats['sum'])\n",
    "            features['p2_total_stats'] = sum(p2_stats)\n",
    "            features['total_stats_advantage'] = features['p1_total_stats'] - features['p2_total_stats']\n",
    "\n",
    "            train_features.append(features)\n",
    "\n",
    "        test_features = []\n",
    "        for idx, row in self.test_data.iterrows():\n",
    "            features = {}\n",
    "\n",
    "            p1_fnt_pokemon_names = set()\n",
    "            timeline = row.get('battle_timeline', [])\n",
    "            for turn in timeline:\n",
    "                p1_status = turn.get('p1_pokemon_state', {}).get('status', 'nostatus')\n",
    "                if p1_status == 'fnt':\n",
    "                    p1_pokemon_name = turn.get('p1_pokemon_state', {}).get('name', '')\n",
    "                    if p1_pokemon_name:\n",
    "                        p1_fnt_pokemon_names.add(p1_pokemon_name)\n",
    "\n",
    "            p1_team = row.get('p1_team_details', [])\n",
    "            p1_team_stats = calculate_team_stats(p1_team, fnt_pokemon_names=p1_fnt_pokemon_names)\n",
    "\n",
    "            p2_lead = row.get('p2_lead_details', {})\n",
    "            p2_stats = extract_pokemon_stats(p2_lead)\n",
    "\n",
    "            for agg_type in ['sum', 'mean', 'max', 'min', 'std']:\n",
    "                for i, stat_name in enumerate(['hp', 'atk', 'def', 'spa', 'spd', 'spe']):\n",
    "                    features[f'p1_team_{stat_name}_{agg_type}'] = p1_team_stats[agg_type][i]\n",
    "\n",
    "            for i, stat_name in enumerate(['hp', 'atk', 'def', 'spa', 'spd', 'spe']):\n",
    "                features[f'p2_lead_{stat_name}'] = p2_stats[i]\n",
    "\n",
    "            for i, stat_name in enumerate(['hp', 'atk', 'def', 'spa', 'spd', 'spe']):\n",
    "                features[f'{stat_name}_advantage'] = p1_team_stats['mean'][i] - p2_stats[i]\n",
    "                features[f'{stat_name}_ratio'] = p1_team_stats['mean'][i] / (p2_stats[i] + 1)\n",
    "\n",
    "            type_adv = self.calculate_team_type_advantage(p1_team, p2_lead)\n",
    "            features.update(type_adv)\n",
    "\n",
    "            diversity = self.calculate_team_diversity(p1_team)\n",
    "            features.update(diversity)\n",
    "\n",
    "            physical_atk = p1_team_stats['mean'][1]\n",
    "            special_atk = p1_team_stats['mean'][3]\n",
    "            physical_def = p1_team_stats['mean'][2]\n",
    "            special_def = p1_team_stats['mean'][4]\n",
    "\n",
    "            features['physical_special_atk_ratio'] = physical_atk / (special_atk + 1)\n",
    "            features['physical_special_def_ratio'] = physical_def / (special_def + 1)\n",
    "            features['offense_defense_ratio'] = (physical_atk + special_atk) / (physical_def + special_def + 1)\n",
    "\n",
    "            features['p1_total_stats'] = sum(p1_team_stats['sum'])\n",
    "            features['p2_total_stats'] = sum(p2_stats)\n",
    "            features['total_stats_advantage'] = features['p1_total_stats'] - features['p2_total_stats']\n",
    "\n",
    "            test_features.append(features)\n",
    "\n",
    "        self.train_static_features = pd.DataFrame(train_features)\n",
    "        self.test_static_features = pd.DataFrame(test_features)\n",
    "\n",
    "        print(f\"Static features extraction completed: {self.train_static_features.shape[1]}  features\")\n",
    "        return self.train_static_features, self.test_static_features\n",
    "\n",
    "    def extract_dynamic_features(self):\n",
    "        print(\"\\n=== Extracting dynamic features (Enhanced) ===\")\n",
    "        \n",
    "        all_moves_list = self.get_all_moves_list()\n",
    "        \n",
    "        def sanitize_move_name(move_name):\n",
    "            sanitized = move_name.replace(' ', '_').replace('-', '_').replace(\"'\", '').replace('.', '')\n",
    "            sanitized = ''.join(c if c.isalnum() or c == '_' else '_' for c in sanitized)\n",
    "            return sanitized.lower()\n",
    "        \n",
    "        move_to_feature = {move: sanitize_move_name(move) for move in all_moves_list}\n",
    "\n",
    "        def analyze_battle_timeline(timeline):\n",
    "            if not timeline:\n",
    "                return {}\n",
    "\n",
    "            features = {}\n",
    "            total_turns = len(timeline)\n",
    "            features['total_turns'] = total_turns\n",
    "\n",
    "            p1_hp_changes = []\n",
    "            p2_hp_changes = []\n",
    "            p1_moves = []\n",
    "            p2_moves = []\n",
    "            p1_pokemon_status_dict = {}\n",
    "            p2_pokemon_status_dict = {}\n",
    "            p1_counter_invalid = 0\n",
    "            p2_counter_invalid = 0\n",
    "            p1_move_powers = []\n",
    "            p2_move_powers = []\n",
    "            p1_move_accuracies = []\n",
    "            p2_move_accuracies = []\n",
    "            p1_physical_moves = 0\n",
    "            p2_physical_moves = 0\n",
    "            p1_special_moves = 0\n",
    "            p2_special_moves = 0\n",
    "            p1_status_moves = 0\n",
    "            p2_status_moves = 0\n",
    "            p1_switch_count = 0\n",
    "            p2_switch_count = 0\n",
    "            p1_move_null_switch = 0\n",
    "            p2_move_null_switch = 0\n",
    "            p1_move_null_status = 0\n",
    "            p2_move_null_status = 0\n",
    "            \n",
    "            p1_move_counts = {move: 0 for move in all_moves_list}\n",
    "            p2_move_counts = {move: 0 for move in all_moves_list}\n",
    "            \n",
    "            p1_boost_changes = []\n",
    "            p2_boost_changes = []\n",
    "            p1_final_boosts = {'atk': 0, 'def': 0, 'spa': 0, 'spd': 0, 'spe': 0}\n",
    "            p2_final_boosts = {'atk': 0, 'def': 0, 'spa': 0, 'spd': 0, 'spe': 0}\n",
    "            p1_effect_turns = 0\n",
    "            p2_effect_turns = 0\n",
    "            p1_hp_losses = []\n",
    "            p2_hp_losses = []\n",
    "\n",
    "            early_end = total_turns // 3\n",
    "            mid_end = 2 * total_turns // 3\n",
    "\n",
    "            p1_early_hp = []\n",
    "            p2_early_hp = []\n",
    "            p1_mid_hp = []\n",
    "            p2_mid_hp = []\n",
    "            p1_late_hp = []\n",
    "            p2_late_hp = []\n",
    "\n",
    "            p1_consecutive_attacks = 0\n",
    "            p2_consecutive_attacks = 0\n",
    "            p1_max_consecutive = 0\n",
    "            p2_max_consecutive = 0\n",
    "            p1_last_was_attack = False\n",
    "            p2_last_was_attack = False\n",
    "\n",
    "            p1_switch_turns = []\n",
    "            p2_switch_turns = []\n",
    "            \n",
    "            p1_pokemon_appeared_30turns = set()\n",
    "            p2_pokemon_appeared_30turns = set()\n",
    "            \n",
    "            p1_pokemon_hp_dict = {}\n",
    "            p2_pokemon_hp_dict = {}\n",
    "\n",
    "            p1_prev_pokemon_name = None\n",
    "            p2_prev_pokemon_name = None\n",
    "\n",
    "            for i, turn in enumerate(timeline):\n",
    "                p1_hp = turn.get('p1_pokemon_state', {}).get('hp_pct', 0)\n",
    "                p2_hp = turn.get('p2_pokemon_state', {}).get('hp_pct', 0)\n",
    "                p1_hp_changes.append(p1_hp)\n",
    "                p2_hp_changes.append(p2_hp)\n",
    "                \n",
    "                if i < 30:\n",
    "                    p1_pokemon_name = turn.get('p1_pokemon_state', {}).get('name', '')\n",
    "                    p2_pokemon_name = turn.get('p2_pokemon_state', {}).get('name', '')\n",
    "                    \n",
    "                    if p1_pokemon_name:\n",
    "                        p1_pokemon_appeared_30turns.add(p1_pokemon_name)\n",
    "                        if p1_pokemon_name not in p1_pokemon_hp_dict:\n",
    "                            p1_pokemon_hp_dict[p1_pokemon_name] = []\n",
    "                        p1_pokemon_hp_dict[p1_pokemon_name].append(p1_hp)\n",
    "                    \n",
    "                    if p2_pokemon_name:\n",
    "                        p2_pokemon_appeared_30turns.add(p2_pokemon_name)\n",
    "                        if p2_pokemon_name not in p2_pokemon_hp_dict:\n",
    "                            p2_pokemon_hp_dict[p2_pokemon_name] = []\n",
    "                        p2_pokemon_hp_dict[p2_pokemon_name].append(p2_hp)\n",
    "\n",
    "                if i < early_end:\n",
    "                    p1_early_hp.append(p1_hp)\n",
    "                    p2_early_hp.append(p2_hp)\n",
    "                elif i < mid_end:\n",
    "                    p1_mid_hp.append(p1_hp)\n",
    "                    p2_mid_hp.append(p2_hp)\n",
    "                else:\n",
    "                    p1_late_hp.append(p1_hp)\n",
    "                    p2_late_hp.append(p2_hp)\n",
    "\n",
    "                if i > 0:\n",
    "                    p1_hp_loss = p1_hp_changes[i-1] - p1_hp\n",
    "                    p2_hp_loss = p2_hp_changes[i-1] - p2_hp\n",
    "                    p1_hp_losses.append(p1_hp_loss)\n",
    "                    p2_hp_losses.append(p2_hp_loss)\n",
    "\n",
    "                p1_move = turn.get('p1_move_details')\n",
    "                p2_move = turn.get('p2_move_details')\n",
    "                \n",
    "                p1_current_pokemon_name = turn.get('p1_pokemon_state', {}).get('name', '')\n",
    "                p2_current_pokemon_name = turn.get('p2_pokemon_state', {}).get('name', '')\n",
    "                \n",
    "                if p1_move is None:\n",
    "                    if i > 0 and p1_prev_pokemon_name is not None and p1_current_pokemon_name != p1_prev_pokemon_name:\n",
    "                        p1_move_null_switch += 1\n",
    "                    else:\n",
    "                        p1_move_null_status += 1\n",
    "                \n",
    "                if p2_move is None:\n",
    "                    if i > 0 and p2_prev_pokemon_name is not None and p2_current_pokemon_name != p2_prev_pokemon_name:\n",
    "                        p2_move_null_switch += 1\n",
    "                    else:\n",
    "                        p2_move_null_status += 1\n",
    "                \n",
    "                p1_prev_pokemon_name = p1_current_pokemon_name\n",
    "                p2_prev_pokemon_name = p2_current_pokemon_name\n",
    "                \n",
    "                if p1_move and p1_move.get('name', '').lower() == 'counter':\n",
    "                    if not p2_move:\n",
    "                        p1_counter_invalid += 1\n",
    "                    elif p2_move.get('category', 'STATUS') != 'PHYSICAL':\n",
    "                        p1_counter_invalid += 1\n",
    "                \n",
    "                if p2_move and p2_move.get('name', '').lower() == 'counter':\n",
    "                    if not p1_move:\n",
    "                        p2_counter_invalid += 1\n",
    "                    elif p1_move.get('category', 'STATUS') != 'PHYSICAL':\n",
    "                        p2_counter_invalid += 1\n",
    "\n",
    "                if p1_move:\n",
    "                    move_name = p1_move.get('name', '')\n",
    "                    p1_moves.append(move_name)\n",
    "                    \n",
    "                    if move_name in p1_move_counts:\n",
    "                        p1_move_counts[move_name] += 1\n",
    "                    \n",
    "                    power = p1_move.get('base_power', 0)\n",
    "                    accuracy = p1_move.get('accuracy', 1.0)\n",
    "                    category = p1_move.get('category', 'STATUS')\n",
    "\n",
    "                    if power > 0:\n",
    "                        p1_move_powers.append(power)\n",
    "                        p1_consecutive_attacks += 1\n",
    "                        p1_last_was_attack = True\n",
    "                    else:\n",
    "                        if p1_last_was_attack:\n",
    "                            p1_max_consecutive = max(p1_max_consecutive, p1_consecutive_attacks)\n",
    "                            p1_consecutive_attacks = 0\n",
    "                        p1_last_was_attack = False\n",
    "\n",
    "                    p1_move_accuracies.append(accuracy)\n",
    "\n",
    "                    if category == 'PHYSICAL':\n",
    "                        p1_physical_moves += 1\n",
    "                    elif category == 'SPECIAL':\n",
    "                        p1_special_moves += 1\n",
    "                    elif category == 'STATUS':\n",
    "                        p1_status_moves += 1\n",
    "                else:\n",
    "                    p1_switch_count += 1\n",
    "                    p1_switch_turns.append(i)\n",
    "                    if p1_last_was_attack:\n",
    "                        p1_max_consecutive = max(p1_max_consecutive, p1_consecutive_attacks)\n",
    "                        p1_consecutive_attacks = 0\n",
    "                    p1_last_was_attack = False\n",
    "\n",
    "                if p2_move:\n",
    "                    move_name = p2_move.get('name', '')\n",
    "                    p2_moves.append(move_name)\n",
    "                    \n",
    "                    if move_name in p2_move_counts:\n",
    "                        p2_move_counts[move_name] += 1\n",
    "                    \n",
    "                    power = p2_move.get('base_power', 0)\n",
    "                    accuracy = p2_move.get('accuracy', 1.0)\n",
    "                    category = p2_move.get('category', 'STATUS')\n",
    "\n",
    "                    if power > 0:\n",
    "                        p2_move_powers.append(power)\n",
    "                        p2_consecutive_attacks += 1\n",
    "                        p2_last_was_attack = True\n",
    "                    else:\n",
    "                        if p2_last_was_attack:\n",
    "                            p2_max_consecutive = max(p2_max_consecutive, p2_consecutive_attacks)\n",
    "                            p2_consecutive_attacks = 0\n",
    "                        p2_last_was_attack = False\n",
    "\n",
    "                    p2_move_accuracies.append(accuracy)\n",
    "\n",
    "                    if category == 'PHYSICAL':\n",
    "                        p2_physical_moves += 1\n",
    "                    elif category == 'SPECIAL':\n",
    "                        p2_special_moves += 1\n",
    "                    elif category == 'STATUS':\n",
    "                        p2_status_moves += 1\n",
    "                else:\n",
    "                    p2_switch_count += 1\n",
    "                    p2_switch_turns.append(i)\n",
    "                    if p2_last_was_attack:\n",
    "                        p2_max_consecutive = max(p2_max_consecutive, p2_consecutive_attacks)\n",
    "                        p2_consecutive_attacks = 0\n",
    "                    p2_last_was_attack = False\n",
    "\n",
    "                p1_pokemon_name = turn.get('p1_pokemon_state', {}).get('name', '')\n",
    "                p1_status = turn.get('p1_pokemon_state', {}).get('status', 'nostatus')\n",
    "                if p1_pokemon_name:\n",
    "                    p1_pokemon_status_dict[p1_pokemon_name] = p1_status\n",
    "\n",
    "                p2_pokemon_name = turn.get('p2_pokemon_state', {}).get('name', '')\n",
    "                p2_status = turn.get('p2_pokemon_state', {}).get('status', 'nostatus')\n",
    "                if p2_pokemon_name:\n",
    "                    p2_pokemon_status_dict[p2_pokemon_name] = p2_status\n",
    "\n",
    "                p1_boosts = turn.get('p1_pokemon_state', {}).get('boosts', {})\n",
    "                p2_boosts = turn.get('p2_pokemon_state', {}).get('boosts', {})\n",
    "\n",
    "                if p1_boosts:\n",
    "                    p1_final_boosts = p1_boosts\n",
    "                    boost_sum = sum(p1_boosts.values())\n",
    "                    p1_boost_changes.append(boost_sum)\n",
    "\n",
    "                if p2_boosts:\n",
    "                    p2_final_boosts = p2_boosts\n",
    "                    boost_sum = sum(p2_boosts.values())\n",
    "                    p2_boost_changes.append(boost_sum)\n",
    "\n",
    "                p1_effects = turn.get('p1_pokemon_state', {}).get('effects', ['noeffect'])\n",
    "                p2_effects = turn.get('p2_pokemon_state', {}).get('effects', ['noeffect'])\n",
    "\n",
    "                if p1_effects and 'noeffect' not in p1_effects:\n",
    "                    p1_effect_turns += 1\n",
    "                if p2_effects and 'noeffect' not in p2_effects:\n",
    "                    p2_effect_turns += 1\n",
    "\n",
    "            if p1_hp_changes:\n",
    "                features['p1_hp_start'] = p1_hp_changes[0]\n",
    "                features['p1_hp_end'] = p1_hp_changes[-1]\n",
    "                features['p1_hp_min'] = min(p1_hp_changes)\n",
    "                features['p1_hp_max'] = max(p1_hp_changes)\n",
    "                features['p1_hp_avg'] = np.mean(p1_hp_changes)\n",
    "                features['p1_hp_std'] = np.std(p1_hp_changes)\n",
    "                if len(p1_hp_changes) > 1:\n",
    "                    features['p1_hp_trend'] = np.polyfit(range(len(p1_hp_changes)), p1_hp_changes, 1)[0]\n",
    "                else:\n",
    "                    features['p1_hp_trend'] = 0\n",
    "\n",
    "            if p2_hp_changes:\n",
    "                features['p2_hp_start'] = p2_hp_changes[0]\n",
    "                features['p2_hp_end'] = p2_hp_changes[-1]\n",
    "                features['p2_hp_min'] = min(p2_hp_changes)\n",
    "                features['p2_hp_max'] = max(p2_hp_changes)\n",
    "                features['p2_hp_avg'] = np.mean(p2_hp_changes)\n",
    "                features['p2_hp_std'] = np.std(p2_hp_changes)\n",
    "                if len(p2_hp_changes) > 1:\n",
    "                    features['p2_hp_trend'] = np.polyfit(range(len(p2_hp_changes)), p2_hp_changes, 1)[0]\n",
    "                else:\n",
    "                    features['p2_hp_trend'] = 0\n",
    "\n",
    "            for phase, p1_hp_list, p2_hp_list in [\n",
    "                ('early', p1_early_hp, p2_early_hp),\n",
    "                ('mid', p1_mid_hp, p2_mid_hp),\n",
    "                ('late', p1_late_hp, p2_late_hp)\n",
    "            ]:\n",
    "                if p1_hp_list:\n",
    "                    features[f'p1_{phase}_hp_avg'] = np.mean(p1_hp_list)\n",
    "                    features[f'p1_{phase}_hp_min'] = min(p1_hp_list)\n",
    "                else:\n",
    "                    features[f'p1_{phase}_hp_avg'] = 0\n",
    "                    features[f'p1_{phase}_hp_min'] = 0\n",
    "\n",
    "                if p2_hp_list:\n",
    "                    features[f'p2_{phase}_hp_avg'] = np.mean(p2_hp_list)\n",
    "                    features[f'p2_{phase}_hp_min'] = min(p2_hp_list)\n",
    "                else:\n",
    "                    features[f'p2_{phase}_hp_avg'] = 0\n",
    "                    features[f'p2_{phase}_hp_min'] = 0\n",
    "\n",
    "            if p1_hp_losses:\n",
    "                features['p1_avg_hp_loss'] = np.mean(p1_hp_losses)\n",
    "                features['p1_max_hp_loss'] = max(p1_hp_losses)\n",
    "            else:\n",
    "                features['p1_avg_hp_loss'] = 0\n",
    "                features['p1_max_hp_loss'] = 0\n",
    "\n",
    "            if p2_hp_losses:\n",
    "                features['p2_avg_hp_loss'] = np.mean(p2_hp_losses)\n",
    "                features['p2_max_hp_loss'] = max(p2_hp_losses)\n",
    "            else:\n",
    "                features['p2_avg_hp_loss'] = 0\n",
    "                features['p2_max_hp_loss'] = 0\n",
    "\n",
    "            features['hp_advantage_start'] = features.get('p1_hp_start', 0) - features.get('p2_hp_start', 0)\n",
    "            features['hp_advantage_end'] = features.get('p1_hp_end', 0) - features.get('p2_hp_end', 0)\n",
    "            features['hp_advantage_avg'] = features.get('p1_hp_avg', 0) - features.get('p2_hp_avg', 0)\n",
    "\n",
    "\n",
    "            p1_abnormal_status_count = 0\n",
    "            for pokemon_name in p1_pokemon_appeared_30turns:\n",
    "                status = p1_pokemon_status_dict.get(pokemon_name, 'nostatus')\n",
    "                if status != 'nostatus' and status != 'fnt':\n",
    "                    p1_abnormal_status_count += 1\n",
    "            \n",
    "            p2_abnormal_status_count = 0\n",
    "            for pokemon_name in p2_pokemon_appeared_30turns:\n",
    "                status = p2_pokemon_status_dict.get(pokemon_name, 'nostatus')\n",
    "                if status != 'nostatus' and status != 'fnt':\n",
    "                    p2_abnormal_status_count += 1\n",
    "            \n",
    "            features['abnormal_status_count_ratio'] = p1_abnormal_status_count / (p2_abnormal_status_count + 1.0)\n",
    "            \n",
    "            features['p1_counter_invalid'] = p1_counter_invalid\n",
    "            features['p2_counter_invalid'] = p2_counter_invalid\n",
    "\n",
    "            if p1_move_powers:\n",
    "                features['p1_avg_move_power'] = np.mean(p1_move_powers)\n",
    "                features['p1_max_move_power'] = max(p1_move_powers)\n",
    "                features['p1_min_move_power'] = min(p1_move_powers)\n",
    "            else:\n",
    "                features['p1_avg_move_power'] = 0\n",
    "                features['p1_max_move_power'] = 0\n",
    "                features['p1_min_move_power'] = 0\n",
    "\n",
    "            if p2_move_powers:\n",
    "                features['p2_avg_move_power'] = np.mean(p2_move_powers)\n",
    "                features['p2_max_move_power'] = max(p2_move_powers)\n",
    "                features['p2_min_move_power'] = min(p2_move_powers)\n",
    "            else:\n",
    "                features['p2_avg_move_power'] = 0\n",
    "                features['p2_max_move_power'] = 0\n",
    "                features['p2_min_move_power'] = 0\n",
    "\n",
    "            if p1_move_accuracies:\n",
    "                features['p1_avg_accuracy'] = np.mean(p1_move_accuracies)\n",
    "            else:\n",
    "                features['p1_avg_accuracy'] = 1.0\n",
    "\n",
    "            if p2_move_accuracies:\n",
    "                features['p2_avg_accuracy'] = np.mean(p2_move_accuracies)\n",
    "            else:\n",
    "                features['p2_avg_accuracy'] = 1.0\n",
    "\n",
    "            total_p1_moves = max(p1_physical_moves + p1_special_moves + p1_status_moves, 1)\n",
    "            total_p2_moves = max(p2_physical_moves + p2_special_moves + p2_status_moves, 1)\n",
    "\n",
    "            features['p1_physical_move_ratio'] = p1_physical_moves / total_p1_moves\n",
    "            features['p1_special_move_ratio'] = p1_special_moves / total_p1_moves\n",
    "            features['p1_status_move_ratio'] = p1_status_moves / total_p1_moves\n",
    "\n",
    "            features['p2_physical_move_ratio'] = p2_physical_moves / total_p2_moves\n",
    "            features['p2_special_move_ratio'] = p2_special_moves / total_p2_moves\n",
    "            features['p2_status_move_ratio'] = p2_status_moves / total_p2_moves\n",
    "\n",
    "            features['p1_switch_count'] = p1_switch_count\n",
    "            features['p2_switch_count'] = p2_switch_count\n",
    "            \n",
    "            features['p1_move_null_switch'] = p1_move_null_switch\n",
    "            features['p2_move_null_switch'] = p2_move_null_switch\n",
    "            features['p1_move_null_status'] = p1_move_null_status\n",
    "            features['p2_move_null_status'] = p2_move_null_status\n",
    "            \n",
    "\n",
    "            if p1_switch_turns:\n",
    "                early_switches = sum(1 for t in p1_switch_turns if t < early_end)\n",
    "                features['p1_early_switch_ratio'] = early_switches / max(p1_switch_count, 1)\n",
    "            else:\n",
    "                features['p1_early_switch_ratio'] = 0\n",
    "\n",
    "            if p2_switch_turns:\n",
    "                early_switches = sum(1 for t in p2_switch_turns if t < early_end)\n",
    "                features['p2_early_switch_ratio'] = early_switches / max(p2_switch_count, 1)\n",
    "            else:\n",
    "                features['p2_early_switch_ratio'] = 0\n",
    "\n",
    "            p1_max_consecutive = max(p1_max_consecutive, p1_consecutive_attacks)\n",
    "            p2_max_consecutive = max(p2_max_consecutive, p2_consecutive_attacks)\n",
    "            features['p1_max_consecutive_attacks'] = p1_max_consecutive\n",
    "            features['p2_max_consecutive_attacks'] = p2_max_consecutive\n",
    "\n",
    "            features['p1_final_boost_sum'] = sum(p1_final_boosts.values())\n",
    "            features['p2_final_boost_sum'] = sum(p2_final_boosts.values())\n",
    "            features['p1_final_atk_boost'] = p1_final_boosts.get('atk', 0)\n",
    "            features['p1_final_def_boost'] = p1_final_boosts.get('def', 0)\n",
    "            features['p1_final_spa_boost'] = p1_final_boosts.get('spa', 0)\n",
    "            features['p1_final_spd_boost'] = p1_final_boosts.get('spd', 0)\n",
    "            features['p1_final_spe_boost'] = p1_final_boosts.get('spe', 0)\n",
    "\n",
    "            features['p2_final_atk_boost'] = p2_final_boosts.get('atk', 0)\n",
    "            features['p2_final_def_boost'] = p2_final_boosts.get('def', 0)\n",
    "            features['p2_final_spa_boost'] = p2_final_boosts.get('spa', 0)\n",
    "            features['p2_final_spd_boost'] = p2_final_boosts.get('spd', 0)\n",
    "            features['p2_final_spe_boost'] = p2_final_boosts.get('spe', 0)\n",
    "\n",
    "            features['boost_advantage'] = features['p1_final_boost_sum'] - features['p2_final_boost_sum']\n",
    "\n",
    "            features['p1_effect_turns'] = p1_effect_turns\n",
    "            features['p2_effect_turns'] = p2_effect_turns\n",
    "            \n",
    "            features['p1_unique_pokemon_count_30turns'] = len(p1_pokemon_appeared_30turns)\n",
    "            features['p2_unique_pokemon_count_30turns'] = len(p2_pokemon_appeared_30turns)\n",
    "            \n",
    "            p1_total_hp_pct = 0.0\n",
    "            p1_appeared_count = len(p1_pokemon_hp_dict)\n",
    "            for pokemon_name, hp_list in p1_pokemon_hp_dict.items():\n",
    "                if hp_list:\n",
    "                    last_hp = hp_list[-1]\n",
    "                    p1_total_hp_pct += last_hp\n",
    "            \n",
    "            p1_missing_count = 6 - p1_appeared_count\n",
    "            if p1_missing_count > 0:\n",
    "                p1_total_hp_pct += p1_missing_count * 1.0\n",
    "            \n",
    "            p2_total_hp_pct = 0.0\n",
    "            p2_appeared_count = len(p2_pokemon_hp_dict)\n",
    "            for pokemon_name, hp_list in p2_pokemon_hp_dict.items():\n",
    "                if hp_list:\n",
    "                    last_hp = hp_list[-1]\n",
    "                    p2_total_hp_pct += last_hp\n",
    "            \n",
    "            p2_missing_count = 6 - p2_appeared_count\n",
    "            if p2_missing_count > 0:\n",
    "                p2_total_hp_pct += p2_missing_count * 1.0\n",
    "            \n",
    "            \n",
    "            if p2_total_hp_pct > 0:\n",
    "                features['total_pokemon_hp_pct_ratio_30turns'] = p1_total_hp_pct / p2_total_hp_pct\n",
    "            else:\n",
    "                features['total_pokemon_hp_pct_ratio_30turns'] = 0.0\n",
    "            \n",
    "            p1_fnt_count = 0\n",
    "            for pokemon_name, status in p1_pokemon_status_dict.items():\n",
    "                if status == 'fnt':\n",
    "                    p1_fnt_count += 1\n",
    "            \n",
    "            p2_fnt_count = 0\n",
    "            for pokemon_name, status in p2_pokemon_status_dict.items():\n",
    "                if status == 'fnt':\n",
    "                    p2_fnt_count += 1\n",
    "            \n",
    "            features['fnt_count_ratio'] = p1_fnt_count / (p2_fnt_count + 1.0)\n",
    "            \n",
    "            features['fnt_count_diff'] = p1_fnt_count - p2_fnt_count\n",
    "\n",
    "            return features\n",
    "\n",
    "        train_battle_features = []\n",
    "        for idx, row in self.train_data.iterrows():\n",
    "            timeline = row.get('battle_timeline', [])\n",
    "            battle_features = analyze_battle_timeline(timeline)\n",
    "            train_battle_features.append(battle_features)\n",
    "\n",
    "        test_battle_features = []\n",
    "        for idx, row in self.test_data.iterrows():\n",
    "            timeline = row.get('battle_timeline', [])\n",
    "            battle_features = analyze_battle_timeline(timeline)\n",
    "            test_battle_features.append(battle_features)\n",
    "\n",
    "        self.train_dynamic_features = pd.DataFrame(train_battle_features)\n",
    "        self.test_dynamic_features = pd.DataFrame(test_battle_features)\n",
    "\n",
    "        print(f\"Dynamic features extraction completed: {self.train_dynamic_features.shape[1]}  features\")\n",
    "        return self.train_dynamic_features, self.test_dynamic_features\n",
    "\n",
    "    def create_interaction_features(self, df):\n",
    "        df_copy = df.copy()\n",
    "\n",
    "        if 'hp_advantage_end' in df_copy.columns and 'boost_advantage' in df_copy.columns:\n",
    "            df_copy['hp_boost_interaction'] = df_copy['hp_advantage_end'] * df_copy['boost_advantage']\n",
    "\n",
    "        if 'p1_avg_move_power' in df_copy.columns and 'p1_avg_accuracy' in df_copy.columns:\n",
    "            df_copy['p1_effective_power'] = df_copy['p1_avg_move_power'] * df_copy['p1_avg_accuracy']\n",
    "\n",
    "        if 'p2_avg_move_power' in df_copy.columns and 'p2_avg_accuracy' in df_copy.columns:\n",
    "            df_copy['p2_effective_power'] = df_copy['p2_avg_move_power'] * df_copy['p2_avg_accuracy']\n",
    "\n",
    "        if 'type_adv_mean' in df_copy.columns and 'total_stats_advantage' in df_copy.columns:\n",
    "            df_copy['type_stats_interaction'] = df_copy['type_adv_mean'] * df_copy['total_stats_advantage']\n",
    "\n",
    "        return df_copy\n",
    "\n",
    "    def combine_features(self):\n",
    "        print(\"\\n=== Combining features and creating interactions ===\")\n",
    "\n",
    "        self.train_combined = pd.concat([\n",
    "            self.train_static_features.reset_index(drop=True),\n",
    "            self.train_dynamic_features.reset_index(drop=True)\n",
    "        ], axis=1)\n",
    "\n",
    "        self.test_combined = pd.concat([\n",
    "            self.test_static_features.reset_index(drop=True),\n",
    "            self.test_dynamic_features.reset_index(drop=True)\n",
    "        ], axis=1)\n",
    "\n",
    "        self.train_combined = self.create_interaction_features(self.train_combined)\n",
    "        self.test_combined = self.create_interaction_features(self.test_combined)\n",
    "\n",
    "        if self.features_to_remove:\n",
    "            print(f\"\\n=== Removing configured features ({len(self.features_to_remove)}) ===\")\n",
    "            features_to_remove_actual = []\n",
    "            for feature in self.features_to_remove:\n",
    "                if feature in self.train_combined.columns:\n",
    "                    features_to_remove_actual.append(feature)\n",
    "                else:\n",
    "                    print(f\"  Warning: Feature '{feature}'  does not exist, skipping removal\")\n",
    "            \n",
    "            if features_to_remove_actual:\n",
    "                self.train_combined = self.train_combined.drop(columns=features_to_remove_actual)\n",
    "                self.test_combined = self.test_combined.drop(columns=features_to_remove_actual)\n",
    "                print(f\"  âœ“ Removed {len(features_to_remove_actual)}  features: {features_to_remove_actual}\")\n",
    "            else:\n",
    "                print(\"  âš ï¸ No features found to remove\")\n",
    "\n",
    "        self.train_combined = self.train_combined.fillna(0)\n",
    "        self.test_combined = self.test_combined.fillna(0)\n",
    "\n",
    "        train_cols = set(self.train_combined.columns)\n",
    "        test_cols = set(self.test_combined.columns)\n",
    "\n",
    "        missing_in_test = train_cols - test_cols\n",
    "        missing_in_train = test_cols - train_cols\n",
    "\n",
    "        for col in missing_in_test:\n",
    "            self.test_combined[col] = 0\n",
    "        for col in missing_in_train:\n",
    "            self.train_combined[col] = 0\n",
    "\n",
    "        self.test_combined = self.test_combined[self.train_combined.columns]\n",
    "\n",
    "        print(f\"Feature combination completed:\")\n",
    "        print(f\"Training feature shape: {self.train_combined.shape}\")\n",
    "        print(f\"Test feature shape: {self.test_combined.shape}\")\n",
    "\n",
    "        return self.train_combined, self.test_combined\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def select_features_rfecv(self, X_train, y_train, estimator=None, cv=5, scoring='accuracy', min_features_to_select=10, n_jobs=-1):\n",
    "        print(f\"\\n=== RFECV Feature Selection ===\")\n",
    "        print(f\"Initial feature count: {X_train.shape[1]}\")\n",
    "        print(f\"Cross-validation folds: {cv}\")\n",
    "        print(f\"Minimum features to select: {min_features_to_select}\")\n",
    "        print(\"Calculating optimal feature count (this may take a few minutes)...\")\n",
    "        \n",
    "        if estimator is None:\n",
    "            estimator = xgb.XGBClassifier(\n",
    "                n_estimators=100,\n",
    "                max_depth=6,\n",
    "                learning_rate=0.1,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                min_child_weight=1,\n",
    "                gamma=0,\n",
    "                reg_alpha=0.01,\n",
    "                reg_lambda=0.01,\n",
    "                random_state=42,\n",
    "                eval_metric='logloss',\n",
    "                n_jobs=n_jobs\n",
    "            )\n",
    "        \n",
    "        rfecv = RFECV(\n",
    "            estimator=estimator,\n",
    "            step=1,\n",
    "            cv=cv,\n",
    "            scoring=scoring,\n",
    "            min_features_to_select=min_features_to_select,\n",
    "            n_jobs=n_jobs\n",
    "        )\n",
    "        \n",
    "        rfecv.fit(X_train, y_train)\n",
    "        \n",
    "        self.feature_selector = rfecv\n",
    "        \n",
    "        selected_mask = rfecv.support_\n",
    "        selected_features = X_train.columns[selected_mask].tolist()\n",
    "        optimal_n_features = rfecv.n_features_\n",
    "        \n",
    "        X_train_selected = rfecv.transform(X_train)\n",
    "        \n",
    "        if isinstance(X_train, pd.DataFrame):\n",
    "            X_train_selected = pd.DataFrame(\n",
    "                X_train_selected,\n",
    "                columns=selected_features,\n",
    "                index=X_train.index\n",
    "            )\n",
    "        \n",
    "        all_features = X_train.columns.tolist()\n",
    "        removed_features = [feat for feat in all_features if feat not in selected_features]\n",
    "        \n",
    "        print(f\"âœ“ RFECV Feature Selection completed\")\n",
    "        print(f\"  Optimal feature count: {optimal_n_features}\")\n",
    "        print(f\"  Selected feature count: {len(selected_features)}\")\n",
    "        print(f\"  Features reduced: {X_train.shape[1] - optimal_n_features} ({(1 - optimal_n_features/X_train.shape[1])*100:.1f}%)\")\n",
    "        \n",
    "        if removed_features:\n",
    "            print(f\"\\nRemoved features ({len(removed_features)}):\")\n",
    "            removed_features_sorted = sorted(removed_features)\n",
    "            for i in range(0, len(removed_features_sorted), 5):\n",
    "                features_line = removed_features_sorted[i:i+5]\n",
    "                print(f\"  {', '.join(features_line)}\")\n",
    "        else:\n",
    "            print(f\"\\nNo features removed\")\n",
    "        \n",
    "        print(f\"\\nCross-validation score vs feature count:\")\n",
    "        print(f\"  Highest score: {rfecv.cv_results_['mean_test_score'].max():.4f}\")\n",
    "        print(f\"  Score at optimal feature count: {rfecv.cv_results_['mean_test_score'][rfecv.n_features_ - min_features_to_select]:.4f}\")\n",
    "        \n",
    "        return X_train_selected, selected_features, optimal_n_features\n",
    "\n",
    "    def save_misclassified_samples(self, y_true_indices, y_pred, y_true, model_name='best_model'):\n",
    "        print(f\"\\n=== Saving{model_name} misclassified samples ===\")\n",
    "        \n",
    "        misclassified_mask = y_pred != y_true.values\n",
    "        misclassified_indices = y_true_indices[misclassified_mask]\n",
    "        \n",
    "        if len(misclassified_indices) == 0:\n",
    "            print(\"No misclassified samples!\")\n",
    "            return None, None\n",
    "        \n",
    "        print(f\"Found {len(misclassified_indices)}  misclassified samples\")\n",
    "        \n",
    "        y_pred_wrong = y_pred[misclassified_mask]\n",
    "        y_true_wrong = y_true.values[misclassified_mask]\n",
    "        \n",
    "        misclassified_samples = []\n",
    "        for i, idx in enumerate(misclassified_indices):\n",
    "            sample = self.train_data.iloc[idx].to_dict()\n",
    "            \n",
    "            sample['prediction_info'] = {\n",
    "                'predicted': int(y_pred_wrong[i]),\n",
    "                'actual': int(y_true_wrong[i]),\n",
    "                'model': model_name,\n",
    "                'original_index': int(idx)\n",
    "            }\n",
    "            \n",
    "            misclassified_samples.append(sample)\n",
    "        \n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        output_file = f'misclassified/misclassified_samples_{model_name}_{timestamp}.json'\n",
    "        \n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(misclassified_samples, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"Misclassified samples saved to: {output_file}\")\n",
    "        \n",
    "        stats = {\n",
    "            'total_samples': len(y_true),\n",
    "            'misclassified_count': len(misclassified_indices),\n",
    "            'accuracy': 1 - (len(misclassified_indices) / len(y_true)),\n",
    "            'error_rate': len(misclassified_indices) / len(y_true),\n",
    "            'false_positive': int(((y_pred == 1) & (y_true == 0)).sum()),\n",
    "            'false_negative': int(((y_pred == 0) & (y_true == 1)).sum()),\n",
    "            'timestamp': timestamp,\n",
    "            'model_name': model_name\n",
    "        }\n",
    "        \n",
    "        stats_file = f'misclassified/misclassified_stats_{model_name}_{timestamp}.json'\n",
    "        with open(stats_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(stats, f, indent=2)\n",
    "        \n",
    "        print(f\"Statistics saved to: {stats_file}\")\n",
    "        print(f\"Accuracy: {stats['accuracy']:.4f}\")\n",
    "        print(f\"Error rate: {stats['error_rate']:.4f}\")\n",
    "        print(f\"False positive (predicted win but actual loss): {stats['false_positive']}\")\n",
    "        print(f\"False negative (predicted loss but actual win): {stats['false_negative']}\")\n",
    "        \n",
    "        return misclassified_samples, stats\n",
    "\n",
    "    def train_models(self):\n",
    "        print(\"\\n=== Model Training (Stacking Ensemble) ===\")\n",
    "\n",
    "        X = self.train_combined\n",
    "        y = self.train_data['player_won']\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X, y, test_size=0.1, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        \n",
    "        val_indices = y_val.index.to_numpy()\n",
    "\n",
    "        \n",
    "        use_rfecv = False\n",
    "        if use_rfecv:\n",
    "            X_train_selected, selected_features, optimal_n = self.select_features_rfecv(\n",
    "                X_train, y_train,\n",
    "                estimator=None,\n",
    "                cv=4,\n",
    "                scoring='accuracy',\n",
    "                min_features_to_select=20,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            X_val_selected = self.feature_selector.transform(X_val)\n",
    "            X_train = X_train_selected\n",
    "            X_val = X_val_selected\n",
    "            print(f\"\\nTraining models with RFECV selected features\")\n",
    "            print(f\"Training feature shape: {X_train.shape}, Validation feature shape: {X_val.shape}\")\n",
    "\n",
    "        base_models = {\n",
    "            'XGBoost': xgb.XGBClassifier(\n",
    "                n_estimators=800,\n",
    "                max_depth=8,\n",
    "                learning_rate=0.03,\n",
    "                subsample=0.85,\n",
    "                colsample_bytree=0.85,\n",
    "                min_child_weight=2,\n",
    "                gamma=0.05,\n",
    "                reg_alpha=0.1,\n",
    "                reg_lambda=0.1,\n",
    "                random_state=42,\n",
    "                eval_metric='logloss',\n",
    "                n_jobs=-1\n",
    "            ),\n",
    "            'LightGBM': lgb.LGBMClassifier(\n",
    "                n_estimators=800,\n",
    "                max_depth=10,\n",
    "                learning_rate=0.03,\n",
    "                subsample=0.85,\n",
    "                colsample_bytree=0.85,\n",
    "                min_child_samples=15,\n",
    "                reg_alpha=0.1,\n",
    "                reg_lambda=0.1,\n",
    "                num_leaves=50,\n",
    "                random_state=42,\n",
    "                verbose=-1,\n",
    "                n_jobs=-1\n",
    "            ),\n",
    "            'CatBoost': CatBoostClassifier(\n",
    "                iterations=800,\n",
    "                depth=9,\n",
    "                learning_rate=0.03,\n",
    "                l2_leaf_reg=2,\n",
    "                random_seed=42,\n",
    "                verbose=False,\n",
    "                thread_count=-1\n",
    "            )\n",
    "        }\n",
    "\n",
    "        for name, model in base_models.items():\n",
    "            print(f\"Training {name}...\")\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            y_pred = model.predict(X_val)\n",
    "            accuracy = accuracy_score(y_val, y_pred)\n",
    "\n",
    "            print(f\"{name} Validation accuracy: {accuracy:.4f}\")\n",
    "\n",
    "            self.models[name] = model\n",
    "\n",
    "            if hasattr(model, 'feature_importances_'):\n",
    "                self.feature_importance[name] = model.feature_importances_\n",
    "\n",
    "        print(\"\\nTraining Stacking ensemble model...\")\n",
    "\n",
    "        stacking_estimators = [\n",
    "            ('XGBoost', base_models['XGBoost']),\n",
    "            ('LightGBM', base_models['LightGBM']),\n",
    "            ('CatBoost', base_models['CatBoost'])\n",
    "        ]\n",
    "\n",
    "        stacking_model = StackingClassifier(\n",
    "            estimators=stacking_estimators,\n",
    "            final_estimator=LogisticRegression(C=1.0, max_iter=500, random_state=42),\n",
    "            cv='prefit',\n",
    "            n_jobs=1\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            stacking_model.fit(X_train, y_train)\n",
    "            y_pred_stacking = stacking_model.predict(X_val)\n",
    "            stacking_accuracy = accuracy_score(y_val, y_pred_stacking)\n",
    "            print(f\"Stacking ensemble model validation accuracy: {stacking_accuracy:.4f}\")\n",
    "            self.models['Stacking'] = stacking_model\n",
    "        except Exception as e:\n",
    "            print(f\"Stacking training failed: {e}\")\n",
    "            print(\"Skipping Stacking model, using Voting as main ensemble method\")\n",
    "\n",
    "\n",
    "\n",
    "        if 'Stacking' in self.models:\n",
    "            self.best_model_name = 'Stacking'\n",
    "            self.best_model = self.models['Stacking']\n",
    "            best_predictions = self.models['Stacking'].predict(X_val)\n",
    "        else:\n",
    "            self.best_model_name = 'Voting'\n",
    "            self.best_model = self.models['Voting']\n",
    "            best_predictions = y_pred_voting\n",
    "        \n",
    "        # self.save_misclassified_samples(val_indices, best_predictions, y_val, self.best_model_name)\n",
    "        \n",
    "\n",
    "        return self.models\n",
    "\n",
    "    def make_predictions(self):\n",
    "        print(\"\\n=== Generating predictions ===\")\n",
    "\n",
    "        test_features = self.test_combined\n",
    "        if hasattr(self, 'feature_selector') and self.feature_selector is not None:\n",
    "            print(\"Applying feature selection to test data...\")\n",
    "            test_features_array = self.feature_selector.transform(self.test_combined)\n",
    "            if isinstance(self.test_combined, pd.DataFrame):\n",
    "                selected_features = self.test_combined.columns[self.feature_selector.support_].tolist()\n",
    "                test_features = pd.DataFrame(\n",
    "                    test_features_array,\n",
    "                    columns=selected_features,\n",
    "                    index=self.test_combined.index\n",
    "                )\n",
    "            else:\n",
    "                test_features = test_features_array\n",
    "            print(f\"Test feature shape: {test_features.shape}\")\n",
    "\n",
    "        predictions = {}\n",
    "\n",
    "        for name, model in self.models.items():\n",
    "            pred = model.predict(test_features)\n",
    "            predictions[name] = pred\n",
    "            print(f\"{name} Prediction completed\")\n",
    "\n",
    "        if 'Stacking' in predictions:\n",
    "            best_predictions = predictions['Stacking']\n",
    "            print(\"Using Stacking model for final predictions\")\n",
    "        else:\n",
    "            best_predictions = predictions['Voting']\n",
    "            print(\"Using Voting model for final predictions\")\n",
    "\n",
    "        submission = pd.DataFrame({\n",
    "            'battle_id': self.test_data['battle_id'],\n",
    "            'player_won': best_predictions.astype(int)\n",
    "        })\n",
    "\n",
    "        submission.to_csv('submission_enhanced_v2.csv', index=False)\n",
    "        print(\"Submission file generated: submission_enhanced_v2.csv\")\n",
    "\n",
    "        return submission, predictions\n",
    "\n",
    "    def get_sample_features(self, original_index):\n",
    "        if self.train_combined is None:\n",
    "            print(\"Error: Please run feature extraction first (extract_static_features, extract_dynamic_features, combine_features)\")\n",
    "            return None\n",
    "\n",
    "        if original_index >= len(self.train_combined):\n",
    "            print(f\"Error: Index out of range (Maximum: {len(self.train_combined)-1})\")\n",
    "            return None\n",
    "\n",
    "        return self.train_combined.iloc[original_index].to_dict()\n",
    "\n",
    "    def explain_single_prediction(self, sample_index, model_name='XGBoost', top_k=20, use_shap=True):\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"Explaining sample #{sample_index} prediction\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        if self.train_combined is None:\n",
    "            print(\"Error: Please run feature extraction first\")\n",
    "            return None\n",
    "        \n",
    "        if model_name not in self.models:\n",
    "            print(f\"Error: Model '{model_name}'  does not exist\")\n",
    "            print(f\"Available models: {list(self.models.keys())}\")\n",
    "            return None\n",
    "        \n",
    "        model = self.models[model_name]\n",
    "        \n",
    "        if sample_index >= len(self.train_combined):\n",
    "            print(f\"Error: Index out of range (Maximum: {len(self.train_combined)-1})\")\n",
    "            return None\n",
    "        \n",
    "        sample_features = self.train_combined.iloc[sample_index:sample_index+1]\n",
    "        feature_names = self.train_combined.columns.tolist()\n",
    "        \n",
    "        prediction = model.predict(sample_features)[0]\n",
    "        prediction_proba = model.predict_proba(sample_features)[0]\n",
    "        \n",
    "        print(f\"\\nðŸ“Š Prediction results:\")\n",
    "        print(f\"   Predicted class: {prediction} ({'P1 wins' if prediction == 1 else 'P2 wins'})\")\n",
    "        print(f\"   Prediction probability: P1 wins={prediction_proba[1]:.4f}, P2 wins={prediction_proba[0]:.4f}\")\n",
    "        print(f\"   Confidence: {max(prediction_proba):.4f}\")\n",
    "        \n",
    "        if use_shap:\n",
    "            try:\n",
    "                import shap\n",
    "                print(f\"\\nðŸ” Using SHAP values to explain prediction (showing top {top_k} features)...\")\n",
    "                \n",
    "                explainer = shap.TreeExplainer(model)\n",
    "                \n",
    "                \n",
    "                if self.X_val is not None and len(self.X_val) > 100:\n",
    "                    background_data = self.X_val.iloc[:100]\n",
    "                    shap_values = explainer.shap_values(sample_features, background_data)\n",
    "                else:\n",
    "                    shap_values = explainer.shap_values(sample_features)\n",
    "                \n",
    "                if isinstance(shap_values, list):\n",
    "                    shap_values = shap_values[1] if len(shap_values) > 1 else shap_values[0]\n",
    "                \n",
    "                if len(shap_values.shape) > 1:\n",
    "                    sample_shap = shap_values[0]\n",
    "                else:\n",
    "                    sample_shap = shap_values\n",
    "                \n",
    "                feature_contributions = pd.DataFrame({\n",
    "                    'feature': feature_names,\n",
    "                    'shap_value': sample_shap,\n",
    "                    'feature_value': sample_features.iloc[0].values,\n",
    "                    'abs_shap': np.abs(sample_shap)\n",
    "                })\n",
    "                \n",
    "                feature_contributions = feature_contributions.sort_values('abs_shap', ascending=False)\n",
    "                \n",
    "                print(f\"\\nðŸ“ˆ Top {top_k} features contributing to this prediction:\")\n",
    "                print(\"-\" * 80)\n",
    "                print(f\"{'Rank':<6} {'Feature':<40} {'Value':<15} {'SHAP Value':<12} {'Direction':<10}\")\n",
    "                print(\"-\" * 80)\n",
    "                \n",
    "                for i, (idx, row) in enumerate(feature_contributions.head(top_k).iterrows(), 1):\n",
    "                    direction = \"â†‘ Supports P1\" if row['shap_value'] > 0 else \"â†“ Supports P2\"\n",
    "                    print(f\"{i:<6} {row['feature']:<40} {row['feature_value']:<15.4f} {row['shap_value']:<12.6f} {direction:<10}\")\n",
    "                \n",
    "                positive_contrib = feature_contributions[feature_contributions['shap_value'] > 0]['shap_value'].sum()\n",
    "                negative_contrib = feature_contributions[feature_contributions['shap_value'] < 0]['shap_value'].sum()\n",
    "                \n",
    "                print(f\"\\nðŸ’¡ Contribution summary:\")\n",
    "                print(f\"   Total contribution supporting P1 win: {positive_contrib:.4f}\")\n",
    "                print(f\"   Total contribution supporting P2 win: {abs(negative_contrib):.4f}\")\n",
    "                print(f\"   Net contribution: {positive_contrib + negative_contrib:.4f}\")\n",
    "                \n",
    "                return {\n",
    "                    'sample_index': sample_index,\n",
    "                    'prediction': int(prediction),\n",
    "                    'prediction_proba': prediction_proba,\n",
    "                    'feature_contributions': feature_contributions,\n",
    "                    'method': 'SHAP'\n",
    "                }\n",
    "                \n",
    "            except ImportError:\n",
    "                print(\"âš ï¸ SHAP library not installed, using feature importance method...\")\n",
    "                use_shap = False\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ SHAP calculation failed: {e}\")\n",
    "                print(\"Using feature importance method...\")\n",
    "                use_shap = False\n",
    "        \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        return None\n",
    "\n",
    "    def analyze_results(self):\n",
    "        print(\"\\n=== Results analysis ===\")\n",
    "\n",
    "        if self.feature_importance:\n",
    "            print(\"\\nFeature importance analysis:\")\n",
    "            for model_name, importance in self.feature_importance.items():\n",
    "                print(f\"\\n{model_name} Top 15 important features:\")\n",
    "                feature_names = self.train_combined.columns\n",
    "                importance_df = pd.DataFrame({\n",
    "                    'feature': feature_names,\n",
    "                    'importance': importance\n",
    "                }).sort_values('importance', ascending=False)\n",
    "                print(importance_df.head(15))\n",
    "\n",
    "        return self.feature_importance\n",
    "\n",
    "    def analyze_feature_usefulness(self):\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"Feature Usefulness Analysis\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        if self.X_val is None or self.y_val is None or self.best_model is None:\n",
    "            print(\"Error: Please train model first\")\n",
    "            return None\n",
    "        \n",
    "        feature_names = self.train_combined.columns.tolist()\n",
    "        n_features = len(feature_names)\n",
    "        \n",
    "        print(\"\\n[1/4] Calculating tree-based feature importance...\")\n",
    "        \n",
    "        tree_importance_dict = {}\n",
    "        \n",
    "        for name, model in self.models.items():\n",
    "            if hasattr(model, 'feature_importances_'):\n",
    "                tree_importance_dict[name] = model.feature_importances_\n",
    "        \n",
    "        print(\"\\n[2/4] Calculating permutation importance (this may take a few minutes)...\")\n",
    "        \n",
    "        try:\n",
    "            perm_importance = permutation_importance(\n",
    "                self.best_model, \n",
    "                self.X_val, \n",
    "                self.y_val,\n",
    "                n_repeats=10,\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            perm_importance_mean = perm_importance.importances_mean\n",
    "            perm_importance_std = perm_importance.importances_std\n",
    "            \n",
    "            print(f\"âœ“ Permutation importance calculation completed\")\n",
    "        except Exception as e:\n",
    "            print(f\"âœ— Permutation importance calculation failed: {e}\")\n",
    "            perm_importance_mean = np.zeros(n_features)\n",
    "            perm_importance_std = np.zeros(n_features)\n",
    "        \n",
    "        print(\"\\n[3/4] Analyzing feature-target correlation...\")\n",
    "        \n",
    "        correlations = []\n",
    "        for col in feature_names:\n",
    "            try:\n",
    "                corr = np.corrcoef(self.X_val[col], self.y_val)[0, 1]\n",
    "                correlations.append(abs(corr))\n",
    "            except:\n",
    "                correlations.append(0)\n",
    "        \n",
    "        correlations = np.array(correlations)\n",
    "        \n",
    "        print(\"\\n[4/4] Summarizing analysis results...\")\n",
    "        \n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'perm_importance_mean': perm_importance_mean,\n",
    "            'perm_importance_std': perm_importance_std,\n",
    "            'correlation': correlations\n",
    "        })\n",
    "        \n",
    "        for name, importance in tree_importance_dict.items():\n",
    "            importance_df[f'{name}_importance'] = importance\n",
    "        \n",
    "        scores = []\n",
    "        for col in importance_df.columns:\n",
    "            if col != 'feature' and 'std' not in col:\n",
    "                values = importance_df[col].values\n",
    "                if values.max() > 0:\n",
    "                    normalized = values / values.max()\n",
    "                else:\n",
    "                    normalized = values\n",
    "                scores.append(normalized)\n",
    "        \n",
    "        if scores:\n",
    "            importance_df['comprehensive_score'] = np.mean(scores, axis=0)\n",
    "        else:\n",
    "            importance_df['comprehensive_score'] = 0\n",
    "        \n",
    "        importance_df = importance_df.sort_values('comprehensive_score', ascending=False)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"Feature Classification Results\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        useful_threshold = 0.01\n",
    "        very_useful_threshold = 0.1\n",
    "        \n",
    "        very_useful_features = importance_df[importance_df['comprehensive_score'] > very_useful_threshold]\n",
    "        useful_features = importance_df[\n",
    "            (importance_df['comprehensive_score'] > useful_threshold) & \n",
    "            (importance_df['comprehensive_score'] <= very_useful_threshold)\n",
    "        ]\n",
    "        useless_features = importance_df[importance_df['comprehensive_score'] <= useful_threshold]\n",
    "        \n",
    "        print(f\"\\nðŸ† Very useful features (score > {very_useful_threshold}): {len(very_useful_features)}\")\n",
    "        print(\"-\" * 80)\n",
    "        print(very_useful_features[['feature', 'comprehensive_score', 'perm_importance_mean', 'correlation']].head(20).to_string(index=False))\n",
    "        \n",
    "        print(f\"\\nâœ… Useful features ({useful_threshold} < score <= {very_useful_threshold}): {len(useful_features)}\")\n",
    "        print(\"-\" * 80)\n",
    "        if len(useful_features) > 0:\n",
    "            print(useful_features[['feature', 'comprehensive_score']].head(15).to_string(index=False))\n",
    "        \n",
    "        print(f\"\\nâŒ Potentially useless features (score <= {useful_threshold}): {len(useless_features)}\")\n",
    "        print(\"-\" * 80)\n",
    "        if len(useless_features) > 0:\n",
    "            print(useless_features[['feature', 'comprehensive_score']].to_string(index=False))\n",
    "        \n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        report_file = f'feature_importance_report_{timestamp}.csv'\n",
    "        importance_df.to_csv(report_file, index=False, encoding='utf-8-sig')\n",
    "        print(f\"\\nðŸ“„ Detailed report saved to: {report_file}\")\n",
    "        \n",
    "\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"Feature Optimization Suggestions\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        if len(useless_features) > 10:\n",
    "            print(f\"\\nâš ï¸ Found {len(useless_features)} potentially useless features, suggestions:\")\n",
    "            print(f\"   1. Removing these features may improve training speed\")\n",
    "            print(f\"   2. Does not affect model accuracy (may even slightly improve)\")\n",
    "            print(f\"   3. Reduces overfitting risk\")\n",
    "        elif len(useless_features) > 0:\n",
    "            print(f\"\\nâœ“ Found {len(useless_features)}  low importance features, minimal impact\")\n",
    "        else:\n",
    "            print(f\"\\nâœ“ All features have some contribution, feature engineering is well done!\")\n",
    "        \n",
    "        print(f\"\\nðŸ’¡ Top 10 most important features:\")\n",
    "        top10 = importance_df.head(10)\n",
    "        for i, row in enumerate(top10.iterrows(), 1):\n",
    "            idx, data = row\n",
    "            print(f\"   {i:2d}. {data['feature']:40s} (Score: {data['comprehensive_score']:.4f})\")\n",
    "        \n",
    "        return importance_df\n",
    "\n",
    "\n",
    "    def test_feature_removal_impact(self, top_n=20, n_repeats=2):\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"Feature Removal Impact Test\")\n",
    "        print(\"=\"*80)\n",
    "        print(\"âš ï¸ Note: This will retrain models and may take a long time\")\n",
    "        print(f\"   Will test top {top_n} features, each feature repeated {n_repeats} times\")\n",
    "        \n",
    "        if self.X_val is None or self.y_val is None:\n",
    "            print(\"Error: Please train model first\")\n",
    "            return None\n",
    "        \n",
    "        if hasattr(self, 'feature_importance') and self.feature_importance:\n",
    "            if 'XGBoost' in self.feature_importance:\n",
    "                importances = self.feature_importance['XGBoost']\n",
    "                feature_names = self.train_combined.columns.tolist()\n",
    "                top_indices = np.argsort(importances)[-top_n:][::-1]\n",
    "            else:\n",
    "                feature_names = self.train_combined.columns.tolist()\n",
    "                top_indices = list(range(min(top_n, len(feature_names))))\n",
    "        else:\n",
    "            feature_names = self.train_combined.columns.tolist()\n",
    "            top_indices = list(range(min(top_n, len(feature_names))))\n",
    "        \n",
    "        X_full = pd.concat([self.train_combined, self.X_val], axis=0)\n",
    "        y_full = pd.concat([self.train_data['player_won'], self.y_val], axis=0)\n",
    "        \n",
    "        print(\"\\n[Step 1/3] Calculating baseline accuracy (using all features)...\")\n",
    "        baseline_accuracies = []\n",
    "        for repeat in range(n_repeats):\n",
    "            X_train_base, X_val_base, y_train_base, y_val_base = train_test_split(\n",
    "                X_full, y_full, test_size=0.2, random_state=42+repeat, stratify=y_full\n",
    "            )\n",
    "            \n",
    "            base_model = xgb.XGBClassifier(\n",
    "                n_estimators=200,\n",
    "                max_depth=6,\n",
    "                learning_rate=0.05,\n",
    "                random_state=42,\n",
    "                eval_metric='logloss',\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            base_model.fit(X_train_base, y_train_base)\n",
    "            y_pred_base = base_model.predict(X_val_base)\n",
    "            acc_base = accuracy_score(y_val_base, y_pred_base)\n",
    "            baseline_accuracies.append(acc_base)\n",
    "        \n",
    "        baseline_acc = np.mean(baseline_accuracies)\n",
    "        baseline_std = np.std(baseline_accuracies)\n",
    "        print(f\"âœ“ Baseline accuracy: {baseline_acc:.4f} Â± {baseline_std:.4f}\")\n",
    "        \n",
    "        print(f\"\\n[Step 2/3] Testing removal of top {len(top_indices)} features...\")\n",
    "        results = []\n",
    "        \n",
    "        for idx, feature_idx in enumerate(top_indices, 1):\n",
    "            feature_name = feature_names[feature_idx]\n",
    "            print(f\"\\n[{idx}/{len(top_indices)}] Testing removal of feature: {feature_name}\")\n",
    "            \n",
    "            X_full_removed = X_full.drop(columns=[feature_name])\n",
    "            \n",
    "            accuracies_removed = []\n",
    "            for repeat in range(n_repeats):\n",
    "                X_train_rem, X_val_rem, y_train_rem, y_val_rem = train_test_split(\n",
    "                    X_full_removed, y_full, test_size=0.2, random_state=42+repeat, stratify=y_full\n",
    "                )\n",
    "                \n",
    "                model_removed = xgb.XGBClassifier(\n",
    "                    n_estimators=200,\n",
    "                    max_depth=6,\n",
    "                    learning_rate=0.05,\n",
    "                    random_state=42,\n",
    "                    eval_metric='logloss',\n",
    "                    n_jobs=-1\n",
    "                )\n",
    "                model_removed.fit(X_train_rem, y_train_rem)\n",
    "                y_pred_rem = model_removed.predict(X_val_rem)\n",
    "                acc_rem = accuracy_score(y_val_rem, y_pred_rem)\n",
    "                accuracies_removed.append(acc_rem)\n",
    "            \n",
    "            acc_removed = np.mean(accuracies_removed)\n",
    "            std_removed = np.std(accuracies_removed)\n",
    "            impact = baseline_acc - acc_removed\n",
    "            \n",
    "            results.append({\n",
    "                'feature': feature_name,\n",
    "                'baseline_acc': baseline_acc,\n",
    "                'removed_acc': acc_removed,\n",
    "                'impact': impact,\n",
    "                'impact_std': std_removed,\n",
    "                'relative_impact': impact / baseline_acc * 100\n",
    "            })\n",
    "            \n",
    "            status = \"âœ… Useful\" if impact > 0.001 else \"âŒ Useless\" if impact < -0.001 else \"âž– Neutral\"\n",
    "            print(f\"   Accuracy after removal: {acc_removed:.4f} Â± {std_removed:.4f}\")\n",
    "            print(f\"   Impact: {impact:+.4f} ({impact/baseline_acc*100:+.2f}%) {status}\")\n",
    "        \n",
    "        print(\"\\n[Step 3/3] Summarizing results...\")\n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df = results_df.sort_values('impact', ascending=False)\n",
    "        \n",
    "        useful_features = results_df[results_df['impact'] > 0.001]\n",
    "        harmful_features = results_df[results_df['impact'] < -0.001]\n",
    "        neutral_features = results_df[\n",
    "            (results_df['impact'] >= -0.001) & (results_df['impact'] <= 0.001)\n",
    "        ]\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"Feature Removal Impact Analysis Results\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        print(f\"\\nâœ… Useful features (accuracy drops > 0.1% after removal): {len(useful_features)}\")\n",
    "        print(\"-\" * 80)\n",
    "        if len(useful_features) > 0:\n",
    "            print(useful_features[['feature', 'impact', 'relative_impact']].to_string(index=False))\n",
    "        \n",
    "        print(f\"\\nâŒ Potentially useless features (accuracy unchanged or improved after removal): {len(harmful_features) + len(neutral_features)}\")\n",
    "        print(\"-\" * 80)\n",
    "        if len(harmful_features) > 0:\n",
    "            print(\"\\nFeatures that improve accuracy after removal (potentially harmful):\")\n",
    "            print(harmful_features[['feature', 'impact', 'relative_impact']].to_string(index=False))\n",
    "        if len(neutral_features) > 0:\n",
    "            print(\"\\nFeatures with minimal impact after removal (potentially redundant):\")\n",
    "            print(neutral_features[['feature', 'impact', 'relative_impact']].head(10).to_string(index=False))\n",
    "        \n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        results_file = f'feature_removal_test_{timestamp}.csv'\n",
    "        results_df.to_csv(results_file, index=False, encoding='utf-8-sig')\n",
    "        print(f\"\\nðŸ“„ Detailed results saved to: {results_file}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"Optimization Suggestions\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        if len(harmful_features) > 0:\n",
    "            print(f\"\\nâš ï¸ Found {len(harmful_features)}  potentially harmful features:\")\n",
    "            print(\"   Removing these features may improve model performance!\")\n",
    "            print(\"   Suggestion: Consider removing these features from the feature set\")\n",
    "        \n",
    "        if len(neutral_features) > 5:\n",
    "            print(f\"\\nðŸ’¡ Found {len(neutral_features)}  redundant features:\")\n",
    "            print(\"   Removing these features won't affect performance, but can:\")\n",
    "            print(\"   - Speed up training\")\n",
    "            print(\"   - Reduces overfitting risk\")\n",
    "            print(\"   - Simplify model\")\n",
    "        \n",
    "        if len(useful_features) == len(results_df):\n",
    "            print(f\"\\nâœ“ All tested features are useful, feature engineering is well done!\")\n",
    "        \n",
    "        return results_df\n",
    "\n",
    "def main():\n",
    "    log_file_path = setup_logging(log_dir='print_log')\n",
    "    print(f\"Logging system started, output will be saved to: {log_file_path}\")\n",
    "    \n",
    "    try:\n",
    "        print(\"Pokemon Battles Prediction 2025 - Enhanced Version\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        predictor = PokemonBattlePredictorEnhanced()\n",
    "        # train_data, test_data = predictor.load_data('input/train.jsonl', 'input/test.jsonl')\n",
    "        if os.path.exists('input/train.jsonl') and os.path.exists('input/test.jsonl'):\n",
    "            train_data, test_data = predictor.load_data('input/train.jsonl', 'input/test.jsonl')\n",
    "        else:\n",
    "            train_data, test_data = predictor.load_data('../input/fds-pokemon-battles-prediction-2025/train.jsonl', '../input/fds-pokemon-battles-prediction-2025/test.jsonl')\n",
    "\n",
    "        predictor.extract_static_features()\n",
    "        predictor.extract_dynamic_features()\n",
    "        predictor.combine_features()\n",
    "\n",
    "        predictor.train_models()\n",
    "\n",
    "        submission, predictions = predictor.make_predictions()\n",
    "\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Starting feature removal impact test...\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "\n",
    "        explanation = predictor.explain_single_prediction(\n",
    "            sample_index=7433,\n",
    "            model_name='XGBoost',\n",
    "            top_k=20,\n",
    "            use_shap=True\n",
    "        )\n",
    "\n",
    "        print(\"\\nTask completed!\")\n",
    "        print(\"Please check submission_enhanced_v2.csv  file\")\n",
    "        print(\"Feature analysis report generated\")\n",
    "        print(\"\\nðŸ’¡ Tip: To explain a single sample prediction, you can use:\")\n",
    "        print(\"   predictor.explain_single_prediction(sample_index=6678, model_name='XGBoost', top_k=20)\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: Data file not found - {e}\")\n",
    "        print(\"Please ensure train.jsonl and test.jsonl files exist in the input/ directory\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        import traceback\n",
    "        print(traceback.format_exc())\n",
    "    finally:\n",
    "        close_logging()\n",
    "        print(f\"\\nLog file saved: {log_file_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13033998,
     "sourceId": 107555,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 133.180731,
   "end_time": "2025-11-14T18:40:53.244762",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-14T18:38:40.064031",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
