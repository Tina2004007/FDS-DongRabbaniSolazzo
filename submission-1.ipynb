{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bac9b16",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-14T18:58:03.897997Z",
     "iopub.status.busy": "2025-11-14T18:58:03.897643Z",
     "iopub.status.idle": "2025-11-14T19:25:44.337254Z",
     "shell.execute_reply": "2025-11-14T19:25:44.336099Z"
    },
    "papermill": {
     "duration": 1660.447285,
     "end_time": "2025-11-14T19:25:44.339102",
     "exception": false,
     "start_time": "2025-11-14T18:58:03.891817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pokemon Battles Prediction 2025 - Advanced Solution\n",
      "============================================================\n",
      "Loading data...\n",
      "Training data: 10000 records\n",
      "Test data: 5000 records\n",
      "Target variable distribution: \n",
      "player_won\n",
      "True     0.5\n",
      "False    0.5\n",
      "Name: proportion, dtype: float64\n",
      "Extracting advanced features (A/B Test Strategy)...\n",
      "Processing training data...\n",
      "Processing test data...\n",
      "Advanced feature extraction complete: 35 features created.\n",
      "\n",
      "--- A/B Test: Linear vs. Ensemble ---\n",
      "\n",
      "--- Test A: Training Linear (LogReg) Strategy ---\n",
      "\n",
      "Running Backward Selection to find top 17 features...\n",
      "Initial mean CV accuracy: 0.8351 with 35 features\n",
      "âž– Removed 'lead_type_disadvantage_gen1' â†’ mean CV=0.8367 (Î”=+0.0016) | Remaining: 34\n",
      "âž– Removed 'p1_avg_power' â†’ mean CV=0.8375 (Î”=+0.0008) | Remaining: 33\n",
      "âž– Removed 'team_vs_lead_atk_diff' â†’ mean CV=0.8378 (Î”=+0.0003) | Remaining: 32\n",
      "âž– Removed 'hp_loss_rate' â†’ mean CV=0.8381 (Î”=+0.0003) | Remaining: 31\n",
      "âž– Removed 'p1_phys_pressure' â†’ mean CV=0.8383 (Î”=+0.0002) | Remaining: 30\n",
      "âž– Removed 'team_vs_lead_spa_diff' â†’ mean CV=0.8383 (Î”=+0.0000) | Remaining: 29\n",
      "âž– Removed 'lead_vs_lead_spa_diff' â†’ mean CV=0.8383 (Î”=+0.0000) | Remaining: 28\n",
      "âž– Removed 'total_turns' â†’ mean CV=0.8383 (Î”=+0.0000) | Remaining: 27\n",
      "âž– Removed 'team_vs_lead_spe_diff' â†’ mean CV=0.8382 (Î”=-0.0001) | Remaining: 26\n",
      "âž– Removed 'hp_gain_per_turn' â†’ mean CV=0.8385 (Î”=+0.0003) | Remaining: 25\n",
      "âž– Removed 'hp_delta_trend' â†’ mean CV=0.8391 (Î”=+0.0006) | Remaining: 24\n",
      "âž– Removed 'p1_bad_status_advantage' â†’ mean CV=0.8393 (Î”=+0.0002) | Remaining: 23\n",
      "âž– Removed 'diff_fainted_count' â†’ mean CV=0.8394 (Î”=+0.0001) | Remaining: 22\n",
      "âž– Removed 'lead_vs_lead_def_diff' â†’ mean CV=0.8396 (Î”=+0.0002) | Remaining: 21\n",
      "âž– Removed 'p1_spec_pressure' â†’ mean CV=0.8394 (Î”=-0.0002) | Remaining: 20\n",
      "âž– Removed 'lead_type_advantage_gen1' â†’ mean CV=0.8393 (Î”=-0.0001) | Remaining: 19\n",
      "âž– Removed 'hp_delta_std' â†’ mean CV=0.8391 (Î”=-0.0002) | Remaining: 18\n",
      "âž– Removed 'p2_hp_volatility' â†’ mean CV=0.8387 (Î”=-0.0004) | Remaining: 17\n",
      "\n",
      "ðŸ Reached target of 17 features. Stopping.\n",
      "Selection complete. Final CV score: 0.8387\n",
      "  - FINAL Linear CV Score (on 17 features): 0.8387 (+/- 0.0087)\n",
      "\n",
      "--- Test B: Training Full Ensemble (RF+XGB+LGBM) Strategy ---\n",
      "  Testing individual ensemble models on all 35 features...\n",
      "    - RandomForest CV Score: 0.8309 (+/- 0.0094) [Time: 33.3s]\n",
      "    - XGBoost CV Score: 0.8312 (+/- 0.0094) [Time: 7.0s]\n",
      "    - LightGBM CV Score: 0.8264 (+/- 0.0044) [Time: 4.9s]\n",
      "  Testing full (RF+XGB+LGBM) Ensemble...\n",
      "    - FINAL Ensemble CV Score: 0.8334 (+/- 0.0096) [Time: 45.2s]\n",
      "\n",
      "--- A/B Test Results (Full Comparison) ---\n",
      "  - LogisticRegression: 0.8387\n",
      "  - RandomForest: 0.8309\n",
      "  - XGBoost: 0.8312\n",
      "  - LightGBM: 0.8264\n",
      "  - Ensemble: 0.8334\n",
      "\n",
      "WINNER (based on CV): LogisticRegression (Using Linear_Model for submission)\n",
      "Generating predictions...\n",
      "Using winning model 'Linear_Model' for submission.\n",
      "Submission file generated: submission.csv\n",
      "Prediction distribution: False    2537\n",
      "True     2463\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Analyzing winning model's feature importance...\n",
      "(Analyzing Linear_Model)\n",
      "Top 17 most impactful features (Coefficients):\n",
      "                  feature  coefficient  abs_coefficient\n",
      "15        battle_duration    -3.309636         3.309636\n",
      "12       p1_fainted_count    -3.240078         3.240078\n",
      "14     final_hp_advantage     1.687428         1.687428\n",
      "11    diff_n_pokemon_used    -0.616988         0.616988\n",
      "16           status_chaos     0.365854         0.365854\n",
      "3    lead_vs_lead_hp_diff    -0.305139         0.305139\n",
      "9      status_change_diff    -0.304366         0.304366\n",
      "8    p1_hp_advantage_mean    -0.191978         0.191978\n",
      "7        p1_hp_volatility    -0.168147         0.168147\n",
      "5   lead_vs_lead_spd_diff    -0.167063         0.167063\n",
      "13       p2_fainted_count    -0.126860         0.126860\n",
      "1   team_vs_lead_def_diff     0.125759         0.125759\n",
      "2   team_vs_lead_spd_diff     0.121320         0.121320\n",
      "4   lead_vs_lead_atk_diff    -0.117862         0.117862\n",
      "10           p2_avg_power     0.099957         0.099957\n",
      "0    team_vs_lead_hp_diff     0.086726         0.086726\n",
      "6   lead_vs_lead_spe_diff    -0.079901         0.079901\n",
      "\n",
      "Task completed in 1648.52 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Pokemon Battles Prediction 2025 - Advanced Solution (Final A/B Test)\n",
    "# FDS Kaggle Competition\n",
    "\n",
    "'''\n",
    " This script tests our two competing strategies in parallel.\n",
    "\n",
    " 1. LINEAR: A LogisticRegression model on a small, clean set of\n",
    "    aggregate features (CV ~83.7%).\n",
    " 2. ENSEMBLE: The hypothesis that ensemble models (RF, XGB, LGBM) can\n",
    "    perform better on the full, complex feature set.\n",
    "\n",
    " WORKFLOW:\n",
    " 1. Extract a \"Master Set\" of ~35 smart aggregate and non-linear features.\n",
    " 2. Run Test A (Linear Path):\n",
    "    - Use Backward Selection to filter the master set down to 17 features.\n",
    "    - Train a LogisticRegression model and record its CV score.\n",
    " 3. Run Test B (Ensemble Path):\n",
    "    - Train a powerful (RF + XGB + LGBM) ensemble on the FULL master set.\n",
    "    - Record the CV scores for RF, XGB, LGBM, and the final Ensemble.\n",
    "4. Compare CV scores and use the winning model for submission.\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import warnings\n",
    "import os\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.stats import linregress\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "# We re-include RandomForestClassifier for the full test\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Generation 1 Type Chart ---\n",
    "GEN_1_TYPE_CHART = {\n",
    "    'normal': {'rock': 0.5, 'ghost': 0.0},\n",
    "    'fire': {'fire': 0.5, 'water': 0.5, 'grass': 2.0, 'ice': 2.0, 'bug': 2.0, 'rock': 0.5, 'dragon': 0.5},\n",
    "    'water': {'fire': 2.0, 'water': 0.5, 'grass': 0.5, 'ground': 2.0, 'rock': 2.0, 'dragon': 0.5},\n",
    "    'electric': {'water': 2.0, 'electric': 0.5, 'grass': 0.5, 'ground': 0.0, 'flying': 2.0, 'dragon': 0.5},\n",
    "    'grass': {'fire': 0.5, 'water': 2.0, 'grass': 0.5, 'poison': 0.5, 'ground': 2.0, 'flying': 0.5, 'bug': 0.5, 'rock': 2.0, 'dragon': 0.5},\n",
    "    'ice': {'water': 0.5, 'grass': 2.0, 'ground': 2.0, 'flying': 2.0, 'dragon': 2.0},\n",
    "    'fighting': {'normal': 2.0, 'ice': 2.0, 'rock': 2.0, 'poison': 0.5, 'flying': 0.5, 'psychic': 0.5, 'bug': 0.5, 'ghost': 0.0},\n",
    "    'poison': {'grass': 2.0, 'poison': 0.5, 'ground': 0.5, 'rock': 0.5, 'ghost': 0.5},\n",
    "    'ground': {'fire': 2.0, 'electric': 2.0, 'grass': 0.5, 'poison': 2.0, 'flying': 0.0, 'bug': 0.5, 'rock': 2.0},\n",
    "    'flying': {'electric': 0.5, 'grass': 2.0, 'fighting': 2.0, 'bug': 2.0, 'rock': 0.5},\n",
    "    'psychic': {'fighting': 2.0, 'poison': 2.0, 'psychic': 0.5, 'ghost': 0.0}, # Gen 1 Bug\n",
    "    'bug': {'fire': 0.5, 'grass': 2.0, 'fighting': 0.5, 'poison': 0.5, 'flying': 0.5, 'psychic': 2.0, 'ghost': 0.5},\n",
    "    'rock': {'fire': 2.0, 'ice': 2.0, 'fighting': 0.5, 'ground': 0.5, 'flying': 2.0, 'bug': 2.0},\n",
    "    'ghost': {'normal': 0.0, 'psychic': 0.0, 'ghost': 2.0}, # Gen 1 Bug\n",
    "    'dragon': {'dragon': 2.0}\n",
    "}\n",
    "\n",
    "\n",
    "class AdvancedPokemonPredictor:\n",
    "    \"\"\"\n",
    "    Advanced Pokemon Battle Predictor\n",
    "    Implements an A/B test to compare a Linear vs. Ensemble strategy.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Class initializer\"\"\"\n",
    "        self.train_data = None\n",
    "        self.test_data = None\n",
    "        self.train_features_df = None # Stores the full DF with all features\n",
    "        self.test_features_df = None  # Stores the full DF with all features\n",
    "        self.models = {}              # Will store 'Linear_Model' and 'Ensemble_Model'\n",
    "        self.selected_feature_names = [] # Stores the features for the Linear model\n",
    "        self.all_feature_names = []      # Stores ALL generated features\n",
    "        self.final_model_name = None     # Name of the winning model\n",
    "        self.cv_scores = {}              # NEW: Will store all CV scores for comparison\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load data\"\"\"\n",
    "        print(\"Loading data...\")\n",
    "        \n",
    "        base_path = '../input/fds-pokemon-battles-prediction-2025'\n",
    "        if not os.path.exists(base_path):\n",
    "            base_path = './'\n",
    "\n",
    "        train_file_path = os.path.join(base_path, 'train.jsonl')\n",
    "        test_file_path = os.path.join(base_path, 'test.jsonl')\n",
    "        \n",
    "        train_records = []\n",
    "        try:\n",
    "            with open(train_file_path, 'r', encoding='utf-8') as f:\n",
    "                for line in f:\n",
    "                    train_records.append(json.loads(line.strip()))\n",
    "            \n",
    "            test_records = []\n",
    "            with open(test_file_path, 'r', encoding='utf-8') as f:\n",
    "                for line in f:\n",
    "                    test_records.append(json.loads(line.strip()))\n",
    "            \n",
    "            self.train_data = pd.DataFrame(train_records)\n",
    "            self.test_data = pd.DataFrame(test_records)\n",
    "            \n",
    "            print(f\"Training data: {len(self.train_data)} records\")\n",
    "            print(f\"Test data: {len(self.test_data)} records\")\n",
    "            print(f\"Target variable distribution: \\n{self.train_data['player_won'].value_counts(normalize=True)}\")\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"ERROR: Could not find the training file at '{train_file_path}'.\")\n",
    "            return False\n",
    "            \n",
    "        return True\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward_selection_to_n(X, y, base_pipe, target_n=15, cv=5, verbose=True):\n",
    "        \"\"\"\n",
    "        Our feature selection function.\n",
    "        Performs backward elimination to find the optimal 'target_n' features.\n",
    "        \"\"\"\n",
    "        print(f\"\\nRunning Backward Selection to find top {target_n} features...\")\n",
    "        kfold = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "        selected = list(X.columns)\n",
    "        history = []\n",
    "\n",
    "        best_score = np.mean(cross_val_score(base_pipe, X[selected], y, cv=kfold, scoring='accuracy', n_jobs=1))\n",
    "        print(f\"Initial mean CV accuracy: {best_score:.4f} with {len(selected)} features\")\n",
    "\n",
    "        iteration = 0\n",
    "        while len(selected) > target_n:\n",
    "            iteration += 1\n",
    "            scores_with_candidates = []\n",
    "            for f in selected:\n",
    "                candidate_features = [feat for feat in selected if feat != f]\n",
    "                score = np.mean(cross_val_score(base_pipe, X[candidate_features], y, cv=kfold, scoring='accuracy', n_jobs=1))\n",
    "                scores_with_candidates.append((f, score))\n",
    "\n",
    "            worst_candidate, worst_candidate_score = max(scores_with_candidates, key=lambda x: x[1])\n",
    "            delta = worst_candidate_score - best_score\n",
    "            selected.remove(worst_candidate)\n",
    "            best_score = worst_candidate_score\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"âž– Removed '{worst_candidate}' â†’ mean CV={best_score:.4f} (Î”={delta:+.4f}) | Remaining: {len(selected)}\")\n",
    "            history.append((iteration, len(selected), best_score))\n",
    "\n",
    "            if len(selected) <= target_n:\n",
    "                if verbose:\n",
    "                    print(f\"\\nðŸ Reached target of {target_n} features. Stopping.\")\n",
    "                break\n",
    "        \n",
    "        print(f\"Selection complete. Final CV score: {best_score:.4f}\")\n",
    "        return selected, pd.DataFrame(history, columns=[\"iteration\", \"n_features\", \"cv_accuracy\"])\n",
    "\n",
    "    def extract_advanced_features(self):\n",
    "        \"\"\"\n",
    "        Extract advanced features: a master set of aggregates AND\n",
    "        new non-linear \"interaction\" features for the ensemble models.\n",
    "        \"\"\"\n",
    "        print(\"Extracting advanced features (A/B Test Strategy)...\")\n",
    "        \n",
    "        # --- Helper 1: Stat Getters ---\n",
    "        def get_pokemon_stats(pokemon_dict):\n",
    "            if not pokemon_dict or not isinstance(pokemon_dict, dict):\n",
    "                return [0, 0, 0, 0, 0, 0]\n",
    "            stats = [\n",
    "                pokemon_dict.get('base_hp', 0),\n",
    "                pokemon_dict.get('base_atk', 0),\n",
    "                pokemon_dict.get('base_def', 0),\n",
    "                pokemon_dict.get('base_spa', 0),\n",
    "                pokemon_dict.get('base_spd', 0),\n",
    "                pokemon_dict.get('base_spe', 0)\n",
    "            ]\n",
    "            return [s if s is not None else 0 for s in stats]\n",
    "\n",
    "        def get_team_stats(team_list):\n",
    "            if not team_list or not isinstance(team_list, list):\n",
    "                return [0, 0, 0, 0, 0, 0]\n",
    "            total_stats = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "            for pokemon in team_list:\n",
    "                total_stats += np.array(get_pokemon_stats(pokemon))\n",
    "            return total_stats\n",
    "\n",
    "        # --- Helper 2: Type Chart (Gen 1) ---\n",
    "        def calculate_type_effectiveness(p1_types, p2_types):\n",
    "            p1_types = [str(t).lower() for t in p1_types if t != 'notype']\n",
    "            p2_types = [str(t).lower() for t in p2_types if t != 'notype']\n",
    "            if not p1_types or not p2_types: return 1.0\n",
    "            scores = []\n",
    "            for p1_type in p1_types:\n",
    "                if p1_type in GEN_1_TYPE_CHART:\n",
    "                    type_score = 1.0\n",
    "                    for p2_type in p2_types:\n",
    "                        type_score *= GEN_1_TYPE_CHART[p1_type].get(p2_type, 1.0)\n",
    "                    scores.append(type_score)\n",
    "            return np.mean(scores) if scores else 1.0\n",
    "        \n",
    "        # --- Helper 3: Efficiency & Final State ---\n",
    "        def get_battle_duration(timeline):\n",
    "            try:\n",
    "                return len([t for t in timeline if t['p1_pokemon_state']['hp_pct'] > 0 and\n",
    "                                                 t['p2_pokemon_state']['hp_pct'] > 0])\n",
    "            except:\n",
    "                return 0\n",
    "\n",
    "        def get_final_hp_states(timeline):\n",
    "            p1_hp_final, p2_hp_final = {}, {}\n",
    "            for t in timeline:\n",
    "                if t.get('p1_pokemon_state'):\n",
    "                    p1_hp_final[t['p1_pokemon_state']['name']] = t['p1_pokemon_state']['hp_pct']\n",
    "                if t.get('p2_pokemon_state'):\n",
    "                    p2_hp_final[t['p2_pokemon_state']['name']] = t['p2_pokemon_state']['hp_pct']\n",
    "            return p1_hp_final, p2_hp_final\n",
    "\n",
    "        # --- Helper 4: Refactored Momentum Analysis ---\n",
    "        def analyze_timeline_aggregates(timeline):\n",
    "            if not timeline: return {}\n",
    "            features = {}\n",
    "            p1_hp, p2_hp = [], []\n",
    "            p1_status, p2_status = [], []\n",
    "            p1_move_power, p2_move_power = [], []\n",
    "            \n",
    "            for t in timeline:\n",
    "                if t.get('p1_pokemon_state'): p1_hp.append(t['p1_pokemon_state']['hp_pct'])\n",
    "                if t.get('p2_pokemon_state'): p2_hp.append(t['p2_pokemon_state']['hp_pct'])\n",
    "                p1_status.append(t.get('p1_pokemon_state', {}).get('status', 'nostatus'))\n",
    "                p2_status.append(t.get('p2_pokemon_state', {}).get('status', 'nostatus'))\n",
    "                \n",
    "                p1_move = t.get('p1_move_details')\n",
    "                p2_move = t.get('p2_move_details')\n",
    "                if p1_move: p1_move_power.append(p1_move.get('base_power', 0) or 0)\n",
    "                if p2_move: p2_move_power.append(p2_move.get('base_power', 0) or 0)\n",
    "\n",
    "            min_len = min(len(p1_hp), len(p2_hp))\n",
    "            if min_len < 2: return {}\n",
    "                \n",
    "            p1_hp, p2_hp = p1_hp[:min_len], p2_hp[:min_len]\n",
    "            p1_status, p2_status = p1_status[:min_len], p2_status[:min_len]\n",
    "            hp_delta = np.array(p1_hp) - np.array(p2_hp)\n",
    "\n",
    "            features['p1_hp_volatility'] = np.std(p1_hp)\n",
    "            features['p2_hp_volatility'] = np.std(p2_hp)\n",
    "            features['hp_delta_trend'] = np.polyfit(range(len(hp_delta)), hp_delta, 1)[0]\n",
    "            features['hp_delta_std'] = np.std(hp_delta)\n",
    "            features['p1_hp_advantage_mean'] = np.mean(hp_delta > 0)\n",
    "\n",
    "            negative_status = {'brn', 'par', 'psn', 'tox', 'frz', 'slp'}\n",
    "            p1_neg_status_mean = np.mean([s in negative_status for s in p1_status])\n",
    "            p2_neg_status_mean = np.mean([s in negative_status for s in p2_status])\n",
    "            features['p1_bad_status_advantage'] = p2_neg_status_mean - p1_neg_status_mean\n",
    "            \n",
    "            p1_status_change = np.sum(np.array(p1_status[1:]) != np.array(p1_status[:-1]))\n",
    "            p2_status_change = np.sum(np.array(p2_status[1:]) != np.array(p2_status[:-1]))\n",
    "            features['status_change_diff'] = p1_status_change - p2_status_change\n",
    "            \n",
    "            features['p1_avg_power'] = np.mean(p1_move_power) if p1_move_power else 0\n",
    "            features['p2_avg_power'] = np.mean(p2_move_power) if p2_move_power else 0\n",
    "\n",
    "            return features\n",
    "\n",
    "        # --- Main Processing Loop ---\n",
    "        def process_data(data_rows):\n",
    "            feature_list = []\n",
    "            stat_names = ['hp', 'atk', 'def', 'spa', 'spd', 'spe']\n",
    "\n",
    "            for _, row in data_rows.iterrows():\n",
    "                features = {}\n",
    "                p1_team = row.get('p1_team_details', [])\n",
    "                p2_lead = row.get('p2_lead_details', {})\n",
    "                timeline = row.get('battle_timeline', [])\n",
    "\n",
    "                # 1. Static: P1 Team (Average) vs P2 Lead\n",
    "                p1_team_stats = get_team_stats(p1_team)\n",
    "                p2_lead_stats = get_pokemon_stats(p2_lead)\n",
    "                for i, stat in enumerate(stat_names):\n",
    "                    features[f'team_vs_lead_{stat}_diff'] = p1_team_stats[i] - p2_lead_stats[i]\n",
    "\n",
    "                # 2. Static: P1 Lead vs P2 Lead\n",
    "                p1_lead_stats = get_pokemon_stats(p1_team[0]) if p1_team else [0]*6\n",
    "                for i, stat in enumerate(stat_names):\n",
    "                    features[f'lead_vs_lead_{stat}_diff'] = p1_lead_stats[i] - p2_lead_stats[i]\n",
    "\n",
    "                # 3. Static: Type Advantage (Gen 1)\n",
    "                p1_lead_types = p1_team[0].get('types', []) if p1_team else []\n",
    "                p2_lead_types = p2_lead.get('types', [])\n",
    "                features['lead_type_advantage_gen1'] = calculate_type_effectiveness(p1_lead_types, p2_lead_types)\n",
    "                features['lead_type_disadvantage_gen1'] = calculate_type_effectiveness(p2_lead_types, p1_lead_types)\n",
    "\n",
    "                # 4. Dynamic: Timeline Aggregates\n",
    "                momentum_features = analyze_timeline_aggregates(timeline)\n",
    "                features.update(momentum_features)\n",
    "\n",
    "                # 5. Final State & Efficiency Features\n",
    "                p1_hp_final, p2_hp_final = get_final_hp_states(timeline)\n",
    "                p1_n_pokemon_used = len(p1_hp_final.keys())\n",
    "                p2_n_pokemon_used = len(p2_hp_final.keys())\n",
    "                features['diff_n_pokemon_used'] = p1_n_pokemon_used - p2_n_pokemon_used\n",
    "                features['p1_fainted_count'] = np.sum([1 for hp in p1_hp_final.values() if hp == 0])\n",
    "                features['p2_fainted_count'] = np.sum([1 for hp in p2_hp_final.values() if hp == 0])\n",
    "                features['diff_fainted_count'] = features['p1_fainted_count'] - features['p2_fainted_count']\n",
    "                \n",
    "                p1_total_final_hp = np.sum(list(p1_hp_final.values())) + (6 - p1_n_pokemon_used)\n",
    "                p2_total_final_hp = np.sum(list(p2_hp_final.values())) + (6 - p2_n_pokemon_used)\n",
    "                features['final_hp_advantage'] = p1_total_final_hp - p2_total_final_hp\n",
    "\n",
    "                features['battle_duration'] = get_battle_duration(timeline)\n",
    "                features['hp_loss_rate'] = (\n",
    "                    features['final_hp_advantage'] / features['battle_duration']\n",
    "                    if features['battle_duration'] > 0 else 0.0\n",
    "                )\n",
    "                features['total_turns'] = len(timeline)\n",
    "\n",
    "                # 6. Non-Linear Interaction Features\n",
    "                p1_lead_atk = p1_lead_stats[1]\n",
    "                p1_lead_spa = p1_lead_stats[3]\n",
    "                p2_lead_def = p2_lead_stats[2]\n",
    "                p2_lead_spd = p2_lead_stats[4]\n",
    "                features['p1_phys_pressure'] = p1_lead_atk / (p2_lead_def + 1)\n",
    "                features['p1_spec_pressure'] = p1_lead_spa / (p2_lead_spd + 1)\n",
    "                features['status_chaos'] = features.get('hp_delta_std', 0) * (features.get('p1_bad_status_advantage', 0) + 1)\n",
    "                features['hp_gain_per_turn'] = features.get('hp_delta_trend', 0) * features.get('battle_duration', 0)\n",
    "\n",
    "                # ID and Target\n",
    "                features['battle_id'] = row.get('battle_id')\n",
    "                if 'player_won' in row:\n",
    "                    features['player_won'] = int(row['player_won'])\n",
    "                \n",
    "                feature_list.append(features)\n",
    "            \n",
    "            return pd.DataFrame(feature_list).fillna(0)\n",
    "\n",
    "        # --- Run Feature Extraction ---\n",
    "        print(\"Processing training data...\")\n",
    "        self.train_features_df = process_data(self.train_data)\n",
    "        print(\"Processing test data...\")\n",
    "        self.test_features_df = process_data(self.test_data)\n",
    "        \n",
    "        train_cols = set(self.train_features_df.columns)\n",
    "        test_cols = set(self.test_features_df.columns)\n",
    "        \n",
    "        missing_in_test = list(train_cols - test_cols - {'player_won'})\n",
    "        for col in missing_in_test: self.test_features_df[col] = 0\n",
    "        missing_in_train = list(test_cols - train_cols)\n",
    "        for col in missing_in_train: self.train_features_df[col] = 0\n",
    "        \n",
    "        self.all_feature_names = [c for c in self.train_features_df.columns if c not in ['battle_id', 'player_won']]\n",
    "        self.test_features_df = self.test_features_df[['battle_id'] + self.all_feature_names]\n",
    "        \n",
    "        print(f\"Advanced feature extraction complete: {len(self.all_feature_names)} features created.\")\n",
    "        return True\n",
    "\n",
    "    def run_ab_test_and_train(self, linear_target_n=17, linear_cv=7, ensemble_cv=5):\n",
    "        \"\"\"\n",
    "        NEW FUNCTION: Replaces all previous training functions.\n",
    "        This function runs our two main strategies in parallel and picks the winner.\n",
    "        \"\"\"\n",
    "        \n",
    "        print(f\"\\n--- A/B Test: Linear vs. Ensemble ---\")\n",
    "        \n",
    "        if self.train_features_df is None:\n",
    "            print(\"ERROR: Features not extracted. Run extract_advanced_features() first.\")\n",
    "            return False\n",
    "            \n",
    "        X_all = self.train_features_df[self.all_feature_names]\n",
    "        y = self.train_data['player_won']\n",
    "        \n",
    "        kfold_linear = KFold(n_splits=linear_cv, shuffle=True, random_state=42)\n",
    "        kfold_ensemble = KFold(n_splits=ensemble_cv, shuffle=True, random_state=42)\n",
    "        \n",
    "        self.cv_scores = {}\n",
    "\n",
    "        # --- STRATEGY A: Linear Model on Selected Features ---\n",
    "        print(\"\\n--- Test A: Training Linear (LogReg) Strategy ---\")\n",
    "        try:\n",
    "            selection_pipe = Pipeline([\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                (\"logreg\", LogisticRegression(max_iter=2000, random_state=42))\n",
    "            ])\n",
    "            \n",
    "            selected, _ = self.backward_selection_to_n(\n",
    "                X_all, y,\n",
    "                base_pipe=selection_pipe,\n",
    "                target_n=linear_target_n,\n",
    "                cv=linear_cv,\n",
    "                verbose=True\n",
    "            )\n",
    "            self.selected_feature_names = selected\n",
    "            X_selected = self.train_features_df[self.selected_feature_names]\n",
    "            \n",
    "            linear_model_pipe = Pipeline([\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                (\"logreg\", LogisticRegression(max_iter=2000, random_state=42))\n",
    "            ])\n",
    "            cv_scores_linear = cross_val_score(linear_model_pipe, X_selected, y, cv=kfold_linear, scoring='accuracy', n_jobs=1)\n",
    "            \n",
    "            self.cv_scores['LogisticRegression'] = cv_scores_linear.mean()\n",
    "            print(f\"  - FINAL Linear CV Score (on {len(selected)} features): {self.cv_scores['LogisticRegression']:.4f} (+/- {cv_scores_linear.std() * 2:.4f})\")\n",
    "            \n",
    "            linear_model_pipe.fit(X_selected, y)\n",
    "            self.models['Linear_Model'] = linear_model_pipe\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"ERROR during Linear Strategy: {e}\")\n",
    "            self.cv_scores['LogisticRegression'] = 0.0\n",
    "\n",
    "        # --- STRATEGY B: Ensemble Model on All Features ---\n",
    "        print(\"\\n--- Test B: Training Full Ensemble (RF+XGB+LGBM) Strategy ---\")\n",
    "        try:\n",
    "            # 1. Define all pipelines\n",
    "            rf_pipe = Pipeline([\n",
    "                ('model', RandomForestClassifier(n_estimators=300, max_depth=10, random_state=42, n_jobs=1))\n",
    "            ])\n",
    "            \n",
    "            xgb_pipe = Pipeline([\n",
    "                ('model', xgb.XGBClassifier(n_estimators=400, learning_rate=0.1, max_depth=5,\n",
    "                                           random_state=42, eval_metric='logloss',\n",
    "                                           use_label_encoder=False, n_jobs=1))\n",
    "            ])\n",
    "            \n",
    "            lgbm_pipe = Pipeline([\n",
    "                ('model', lgb.LGBMClassifier(n_estimators=400, learning_rate=0.1, max_depth=5,\n",
    "                                            random_state=42, verbose=-1, n_jobs=1))\n",
    "            ])\n",
    "            \n",
    "            models_to_test = {\n",
    "                'RandomForest': rf_pipe,\n",
    "                'XGBoost': xgb_pipe,\n",
    "                'LightGBM': lgbm_pipe\n",
    "            }\n",
    "\n",
    "            # 2. Test all models individually on ALL features\n",
    "            print(f\"  Testing individual ensemble models on all {len(self.all_feature_names)} features...\")\n",
    "            \n",
    "            for name, pipe in models_to_test.items():\n",
    "                start_time_model = time.time()\n",
    "                cv_scores = cross_val_score(pipe, X_all, y, cv=kfold_ensemble, scoring='accuracy', n_jobs=1)\n",
    "                self.cv_scores[name] = cv_scores.mean()\n",
    "                print(f\"    - {name} CV Score: {self.cv_scores[name]:.4f} (+/- {cv_scores.std() * 2:.4f}) [Time: {time.time() - start_time_model:.1f}s]\")\n",
    "\n",
    "            # 3. Define the final ensemble\n",
    "            print(\"  Testing full (RF+XGB+LGBM) Ensemble...\")\n",
    "            ensemble_model_pipe = VotingClassifier(\n",
    "                estimators=[\n",
    "                    ('rf', rf_pipe),\n",
    "                    ('xgb', xgb_pipe),\n",
    "                    ('lgbm', lgbm_pipe)\n",
    "                ],\n",
    "                voting='soft'\n",
    "            )\n",
    "            \n",
    "            # 4. Validate the full ensemble\n",
    "            start_time_ensemble = time.time()\n",
    "            cv_scores_ensemble = cross_val_score(ensemble_model_pipe, X_all, y, cv=kfold_ensemble, scoring='accuracy', n_jobs=1)\n",
    "            self.cv_scores['Ensemble'] = cv_scores_ensemble.mean()\n",
    "            print(f\"    - FINAL Ensemble CV Score: {self.cv_scores['Ensemble']:.4f} (+/- {cv_scores_ensemble.std() * 2:.4f}) [Time: {time.time() - start_time_ensemble:.1f}s]\")\n",
    "\n",
    "            # 5. Train final model on all data\n",
    "            ensemble_model_pipe.fit(X_all, y)\n",
    "            self.models['Ensemble_Model'] = ensemble_model_pipe\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"ERROR during Ensemble Strategy: {e}\")\n",
    "            self.cv_scores['Ensemble'] = 0.0\n",
    "\n",
    "        # --- A/B Test Conclusion ---\n",
    "        print(\"\\n--- A/B Test Results (Full Comparison) ---\")\n",
    "        best_model_name = \"\"\n",
    "        best_score = 0.0\n",
    "        # Print all scores from our dictionary\n",
    "        for name, score in self.cv_scores.items():\n",
    "            print(f\"  - {name}: {score:.4f}\")\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_model_name = name\n",
    "        \n",
    "        # Map friendly name to the actual model object name\n",
    "        if best_model_name == 'LogisticRegression':\n",
    "            self.final_model_name = 'Linear_Model'\n",
    "        else:\n",
    "            # If any ensemble model (or the ensemble itself) wins,\n",
    "            # we use the full Ensemble_Model for submission,\n",
    "            # as it represents the winning strategy.\n",
    "            self.final_model_name = 'Ensemble_Model'\n",
    "            \n",
    "        print(f\"\\nWINNER (based on CV): {best_model_name} (Using {self.final_model_name} for submission)\")\n",
    "        return True\n",
    "\n",
    "\n",
    "    def make_predictions(self):\n",
    "        \"\"\"\n",
    "        Generate predictions using the winning model from the A/B test.\n",
    "        \"\"\"\n",
    "        print(\"Generating predictions...\")\n",
    "        \n",
    "        if self.final_model_name is None:\n",
    "            print(\"ERROR: No model was selected as the winner. Run run_ab_test_and_train() first.\")\n",
    "            return\n",
    "\n",
    "        print(f\"Using winning model '{self.final_model_name}' for submission.\")\n",
    "        \n",
    "        model_to_use = self.models[self.final_model_name]\n",
    "        \n",
    "        # Select the correct set of features for the winning model\n",
    "        if self.final_model_name == 'Linear_Model':\n",
    "            X_test = self.test_features_df[self.selected_feature_names]\n",
    "        else:\n",
    "            # Ensemble models use ALL features\n",
    "            X_test = self.test_features_df[self.all_feature_names]\n",
    "\n",
    "        predictions = model_to_use.predict(X_test)\n",
    "        \n",
    "        submission = pd.DataFrame({\n",
    "            'battle_id': self.test_data['battle_id'],\n",
    "            'player_won': predictions.astype(int)\n",
    "        })\n",
    "        \n",
    "        submission.to_csv('submission.csv', index=False)\n",
    "        print(\"Submission file generated: submission.csv\")\n",
    "        # Reverted to original value_counts() to match style\n",
    "        print(f\"Prediction distribution: {pd.Series(predictions).value_counts()}\")\n",
    "        return submission\n",
    "    \n",
    "    def analyze_feature_importance(self):\n",
    "        \"\"\"\n",
    "        Analyzes the feature importance of the WINNING model.\n",
    "        \"\"\"\n",
    "        print(\"\\nAnalyzing winning model's feature importance...\")\n",
    "        \n",
    "        if self.final_model_name is None:\n",
    "            print(\"No model was selected as the winner.\")\n",
    "            return\n",
    "\n",
    "        model_pipe = self.models[self.final_model_name]\n",
    "\n",
    "        if self.final_model_name == 'Linear_Model':\n",
    "            # --- Analysis for Linear Model ---\n",
    "            print(f\"(Analyzing {self.final_model_name})\")\n",
    "            try:\n",
    "                model = model_pipe.named_steps['logreg']\n",
    "                coeffs = model.coef_[0]\n",
    "                \n",
    "                coeff_df = pd.DataFrame({\n",
    "                    'feature': self.selected_feature_names,\n",
    "                    'coefficient': coeffs,\n",
    "                    'abs_coefficient': np.abs(coeffs)\n",
    "                }).sort_values('abs_coefficient', ascending=False)\n",
    "                \n",
    "                print(f\"Top {len(self.selected_feature_names)} most impactful features (Coefficients):\")\n",
    "                print(coeff_df)\n",
    "            except Exception as e:\n",
    "                print(f\"Could not analyze coefficients: {e}\")\n",
    "        \n",
    "        else:\n",
    "            # --- Analysis for Ensemble Model ---\n",
    "            print(f\"(Analyzing {self.final_model_name})\")\n",
    "            # We will show importance for all members of the ensemble\n",
    "            for name, pipe in model_pipe.named_steps['estimators']:\n",
    "                try:\n",
    "                    model = pipe.named_steps['model']\n",
    "                    if hasattr(model, 'feature_importances_'):\n",
    "                        print(f\"\\n--- Top 10 Features for: {name.upper()} (in Ensemble) ---\")\n",
    "                        \n",
    "                        importance_df = pd.DataFrame({\n",
    "                            'feature': self.all_feature_names,\n",
    "                            'importance': model.feature_importances_\n",
    "                        }).sort_values('importance', ascending=False)\n",
    "                        \n",
    "                        print(importance_df.head(10))\n",
    "                except Exception as e:\n",
    "                    print(f\"Could not analyze importance for {name}: {e}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function\"\"\"\n",
    "    print(\"Pokemon Battles Prediction 2025 - Advanced Solution\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    predictor = AdvancedPokemonPredictor()\n",
    "    \n",
    "    # Execute complete workflow\n",
    "    if predictor.load_data():\n",
    "        if predictor.extract_advanced_features():\n",
    "            \n",
    "            # --- UPDATED WORKFLOW ---\n",
    "            # Run the A/B test to select and train the best model\n",
    "            if predictor.run_ab_test_and_train(linear_target_n=17, linear_cv=7, ensemble_cv=5):\n",
    "                \n",
    "                # Make predictions with the winner\n",
    "                predictor.make_predictions()\n",
    "                \n",
    "                # Analyze the winner\n",
    "                predictor.analyze_feature_importance()\n",
    "    \n",
    "    print(f\"\\nTask completed in {time.time() - start_time:.2f} seconds.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13033998,
     "sourceId": 107555,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1666.730201,
   "end_time": "2025-11-14T19:25:45.267078",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-14T18:57:58.536877",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
