{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3932730b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T22:40:22.785246Z",
     "iopub.status.busy": "2025-11-14T22:40:22.784803Z",
     "iopub.status.idle": "2025-11-14T22:40:54.994236Z",
     "shell.execute_reply": "2025-11-14T22:40:54.992567Z"
    },
    "papermill": {
     "duration": 32.2223,
     "end_time": "2025-11-14T22:40:54.996680",
     "exception": false,
     "start_time": "2025-11-14T22:40:22.774380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-11-14 22:40:22--  https://github.com/freemedom/temp_dataset/releases/download/v2.0/pokemon_stats_20.json\r\n",
      "Resolving github.com (github.com)... failed: Temporary failure in name resolution.\r\n",
      "wget: unable to resolve host address â€˜github.comâ€™\r\n"
     ]
    }
   ],
   "source": [
    "!wget \"https://github.com/freemedom/temp_dataset/releases/download/v2.0/pokemon_stats_20.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6aeb05a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T22:40:55.026094Z",
     "iopub.status.busy": "2025-11-14T22:40:55.025675Z",
     "iopub.status.idle": "2025-11-14T22:43:03.053725Z",
     "shell.execute_reply": "2025-11-14T22:43:03.052434Z"
    },
    "papermill": {
     "duration": 128.051977,
     "end_time": "2025-11-14T22:43:03.055567",
     "exception": false,
     "start_time": "2025-11-14T22:40:55.003590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ—¥å¿—ç³»ç»Ÿå·²å¯åŠ¨ï¼Œè¾“å‡ºå°†ä¿å­˜åˆ°: print_log/print_log_20251114_224113.log\n",
      "Pokemon Battles Prediction 2025 - Enhanced Version\n",
      "============================================================\n",
      "æ­£åœ¨åŠ è½½æ•°æ®...\n",
      "è®­ç»ƒæ•°æ®åŠ è½½å®Œæˆ: 10000 æ¡è®°å½•\n",
      "æµ‹è¯•æ•°æ®åŠ è½½å®Œæˆ: 5000 æ¡è®°å½•\n",
      "\n",
      "=== æå–é™æ€ç‰¹å¾(å¢å¼ºç‰ˆ) ===\n",
      "é™æ€ç‰¹å¾æå–å®Œæˆ: 34 ä¸ªç‰¹å¾\n",
      "\n",
      "=== æå–åŠ¨æ€ç‰¹å¾(å¢å¼ºç‰ˆ) ===\n",
      "åŠ¨æ€ç‰¹å¾æå–å®Œæˆ: 30 ä¸ªç‰¹å¾\n",
      "\n",
      "=== åˆå¹¶ç‰¹å¾å¹¶åˆ›å»ºäº¤äº’é¡¹ ===\n",
      "ç‰¹å¾åˆå¹¶å®Œæˆ:\n",
      "è®­ç»ƒç‰¹å¾å½¢çŠ¶: (10000, 65)\n",
      "æµ‹è¯•ç‰¹å¾å½¢çŠ¶: (5000, 65)\n",
      "\n",
      "=== æ¨¡å‹è®­ç»ƒ(Stackingé›†æˆ) ===\n",
      "\n",
      "æ‰§è¡ŒXGBoost 4æŠ˜äº¤å‰éªŒè¯è¯„ä¼°ï¼ˆå…¨éƒ¨æœ‰æ ‡ç­¾æ ·æœ¬ï¼‰...\n",
      "XGBoost 4æŠ˜äº¤å‰éªŒè¯å‡†ç¡®ç‡: 0.8234 Â± 0.0034\n",
      "\n",
      "âš ï¸ Optunaè¶…å‚æ•°ä¼˜åŒ–å·²ç¦ç”¨ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°\n",
      "\n",
      "=== æ­£å¼æ¨¡å‹è®­ç»ƒ ===\n",
      "è®­ç»ƒæ•°æ®å¤§å°: 9000 æ ·æœ¬\n",
      "è®­ç»ƒ XGBoost...\n",
      "XGBoost éªŒè¯å‡†ç¡®ç‡: 0.8190\n",
      "è®­ç»ƒ LightGBM...\n",
      "LightGBM éªŒè¯å‡†ç¡®ç‡: 0.8300\n",
      "è®­ç»ƒ CatBoost...\n",
      "CatBoost éªŒè¯å‡†ç¡®ç‡: 0.8230\n",
      "\n",
      "è®­ç»ƒStackingé›†æˆæ¨¡å‹...\n",
      "Stackingé›†æˆæ¨¡å‹éªŒè¯å‡†ç¡®ç‡: 0.8250\n",
      "\n",
      "=== ç”Ÿæˆé¢„æµ‹ ===\n",
      "XGBoost é¢„æµ‹å®Œæˆ\n",
      "LightGBM é¢„æµ‹å®Œæˆ\n",
      "CatBoost é¢„æµ‹å®Œæˆ\n",
      "Stacking é¢„æµ‹å®Œæˆ\n",
      "ä½¿ç”¨Stackingæ¨¡å‹ç”Ÿæˆæœ€ç»ˆé¢„æµ‹\n",
      "æäº¤æ–‡ä»¶å·²ç”Ÿæˆ: submission_enhanced_v4.csv\n",
      "\n",
      "=== ç»“æœåˆ†æ ===\n",
      "\n",
      "ç‰¹å¾é‡è¦æ€§åˆ†æ:\n",
      "\n",
      "XGBoost å‰15ä¸ªé‡è¦ç‰¹å¾:\n",
      "                            feature  importance\n",
      "59                   fnt_count_diff    0.170987\n",
      "58                  fnt_count_ratio    0.118259\n",
      "54  p2_unique_pokemon_count_30turns    0.105281\n",
      "40      abnormal_status_count_ratio    0.068304\n",
      "39         p2_abnormal_status_count    0.066888\n",
      "53  p1_unique_pokemon_count_30turns    0.030950\n",
      "38         p1_abnormal_status_count    0.027998\n",
      "49              p1_move_null_status    0.027482\n",
      "45                  p1_switch_count    0.027229\n",
      "46                  p2_switch_count    0.026905\n",
      "41               p1_counter_invalid    0.025510\n",
      "48              p2_move_null_switch    0.025157\n",
      "50              p2_move_null_status    0.023764\n",
      "47              p1_move_null_switch    0.022885\n",
      "36                   p2_avg_hp_loss    0.020900\n",
      "\n",
      "LightGBM å‰15ä¸ªé‡è¦ç‰¹å¾:\n",
      "                        feature  importance\n",
      "61                       p2_avg        3491\n",
      "44              p2_avg_accuracy        3248\n",
      "36               p2_avg_hp_loss        3202\n",
      "37               p2_max_hp_loss        3194\n",
      "60                       p1_avg        3039\n",
      "43              p1_avg_accuracy        2942\n",
      "34               p1_avg_hp_loss        2588\n",
      "35               p1_max_hp_loss        2486\n",
      "52        p2_early_switch_ratio        2173\n",
      "51        p1_early_switch_ratio        1901\n",
      "40  abnormal_status_count_ratio        1352\n",
      "58              fnt_count_ratio        1190\n",
      "46              p2_switch_count        1060\n",
      "45              p1_switch_count        1058\n",
      "39     p2_abnormal_status_count         817\n",
      "\n",
      "CatBoost å‰15ä¸ªé‡è¦ç‰¹å¾:\n",
      "                            feature  importance\n",
      "36                   p2_avg_hp_loss    6.575357\n",
      "34                   p1_avg_hp_loss    6.346586\n",
      "59                   fnt_count_diff    6.248605\n",
      "61                           p2_avg    6.095308\n",
      "37                   p2_max_hp_loss    6.071247\n",
      "44                  p2_avg_accuracy    5.678650\n",
      "43                  p1_avg_accuracy    5.611257\n",
      "58                  fnt_count_ratio    5.467752\n",
      "40      abnormal_status_count_ratio    5.445138\n",
      "54  p2_unique_pokemon_count_30turns    5.093623\n",
      "60                           p1_avg    4.869346\n",
      "35                   p1_max_hp_loss    4.838972\n",
      "39         p2_abnormal_status_count    4.393634\n",
      "52            p2_early_switch_ratio    4.309184\n",
      "51            p1_early_switch_ratio    3.944355\n",
      "\n",
      "============================================================\n",
      "å¼€å§‹ç‰¹å¾ç§»é™¤å½±å“æµ‹è¯•...\n",
      "============================================================\n",
      "\n",
      "================================================================================\n",
      "è§£é‡Šæ ·æœ¬ #3907 çš„é¢„æµ‹ç»“æœ\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š é¢„æµ‹ç»“æœ:\n",
      "   é¢„æµ‹ç±»åˆ«: 1 (P1è·èƒœ)\n",
      "   é¢„æµ‹æ¦‚ç‡: P1è·èƒœ=0.8673, P2è·èƒœ=0.1327\n",
      "   ç½®ä¿¡åº¦: 0.8673\n",
      "\n",
      "ğŸ” ä½¿ç”¨SHAPå€¼è§£é‡Šé¢„æµ‹ï¼ˆæ˜¾ç¤ºå‰40ä¸ªç‰¹å¾ï¼‰...\n",
      "\n",
      "ğŸ“ˆ å¯¹è¯¥é¢„æµ‹è´¡çŒ®æœ€å¤§çš„å‰40ä¸ªç‰¹å¾:\n",
      "--------------------------------------------------------------------------------\n",
      "æ’å     ç‰¹å¾å                                      ç‰¹å¾å€¼             SHAPå€¼        è´¡çŒ®æ–¹å‘      \n",
      "--------------------------------------------------------------------------------\n",
      "1      abnormal_status_count_ratio              0.0000          0.778730     â†‘ æ”¯æŒP1    \n",
      "2      fnt_count_diff                           2.0000          0.713431     â†‘ æ”¯æŒP1    \n",
      "3      fnt_count_ratio                          2.0000          -0.710525    â†“ æ”¯æŒP2    \n",
      "4      p2_abnormal_status_count                 3.0000          0.641416     â†‘ æ”¯æŒP1    \n",
      "5      p1_unique_pokemon_count_30turns          3.0000          0.585814     â†‘ æ”¯æŒP1    \n",
      "6      p2_max_hp_loss                           0.3200          -0.509257    â†“ æ”¯æŒP2    \n",
      "7      p1_switch_count                          3.0000          0.421667     â†‘ æ”¯æŒP1    \n",
      "8      p1_avg_hp_loss                           0.0345          -0.353487    â†“ æ”¯æŒP2    \n",
      "9      p2_avg_accuracy                          0.9958          0.322094     â†‘ æ”¯æŒP1    \n",
      "10     p1_move_null_switch                      2.0000          0.260046     â†‘ æ”¯æŒP1    \n",
      "11     p1_avg                                   0.9720          -0.210762    â†“ æ”¯æŒP2    \n",
      "12     p2_avg_hp_loss                           0.0000          -0.194127    â†“ æ”¯æŒP2    \n",
      "13     p1_abnormal_status_count                 0.0000          0.188807     â†‘ æ”¯æŒP1    \n",
      "14     p2_unique_pokemon_count_30turns          5.0000          -0.136535    â†“ æ”¯æŒP2    \n",
      "15     p1_max_hp_loss                           0.6400          -0.111264    â†“ æ”¯æŒP2    \n",
      "16     p1_early_switch_ratio                    1.0000          -0.095166    â†“ æ”¯æŒP2    \n",
      "17     p1_avg_accuracy                          0.9889          0.094374     â†‘ æ”¯æŒP1    \n",
      "18     p2_switch_count                          6.0000          0.090526     â†‘ æ”¯æŒP1    \n",
      "19     p2_early_switch_ratio                    0.5000          0.054103     â†‘ æ”¯æŒP1    \n",
      "20     p1_move_null_status                      1.0000          0.045892     â†‘ æ”¯æŒP1    \n",
      "21     p2_move_null_status                      1.0000          -0.043777    â†“ æ”¯æŒP2    \n",
      "22     p2_move_null_switch                      5.0000          0.029855     â†‘ æ”¯æŒP1    \n",
      "23     p1_counter_invalid                       0.0000          -0.017292    â†“ æ”¯æŒP2    \n",
      "24     p2_avg                                   0.7835          0.016421     â†‘ æ”¯æŒP1    \n",
      "25     p2_num_priority_moves                    0.0000          0.008127     â†‘ æ”¯æŒP1    \n",
      "26     p2_counter_invalid                       0.0000          0.003994     â†‘ æ”¯æŒP1    \n",
      "27     p1_num_priority_moves                    0.0000          -0.000919    â†“ æ”¯æŒP2    \n",
      "28     total_stats_advantage                    0.0000          0.000000     â†“ æ”¯æŒP2    \n",
      "29     p1_weighted_strength_sum                 0.0000          0.000000     â†“ æ”¯æŒP2    \n",
      "30     p2_weighted_strength_sum                 0.0000          0.000000     â†“ æ”¯æŒP2    \n",
      "31     weighted_strength_ratio_30turns          0.0000          0.000000     â†“ æ”¯æŒP2    \n",
      "32     hp_advantage                             0.0000          0.000000     â†“ æ”¯æŒP2    \n",
      "33     p2_total_stats_mean                      0.0000          0.000000     â†“ æ”¯æŒP2    \n",
      "34     hp_ratio                                 0.0000          0.000000     â†“ æ”¯æŒP2    \n",
      "35     p1_total_stats_mean                      0.0000          0.000000     â†“ æ”¯æŒP2    \n",
      "36     atk_advantage                            0.0000          0.000000     â†“ æ”¯æŒP2    \n",
      "37     atk_ratio                                0.0000          0.000000     â†“ æ”¯æŒP2    \n",
      "38     def_advantage                            0.0000          0.000000     â†“ æ”¯æŒP2    \n",
      "39     def_ratio                                0.0000          0.000000     â†“ æ”¯æŒP2    \n",
      "40     spa_advantage                            0.0000          0.000000     â†“ æ”¯æŒP2    \n",
      "\n",
      "ğŸ’¡ è´¡çŒ®æ€»ç»“:\n",
      "   æ”¯æŒP1è·èƒœçš„æ€»è´¡çŒ®: 4.2553\n",
      "   æ”¯æŒP2è·èƒœçš„æ€»è´¡çŒ®: 2.3831\n",
      "   å‡€è´¡çŒ®: 1.8722\n",
      "\n",
      "ä»»åŠ¡å®Œæˆ!\n",
      "è¯·æ£€æŸ¥ submission_enhanced_v4.csv æ–‡ä»¶\n",
      "ç‰¹å¾åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ\n",
      "\n",
      "ğŸ’¡ æç¤º: è¦è§£é‡Šå•ä¸ªæ ·æœ¬çš„é¢„æµ‹ï¼Œå¯ä»¥ä½¿ç”¨:\n",
      "   predictor.explain_single_prediction(sample_index=6678, model_name='XGBoost', top_k=20)\n",
      "\n",
      "æ—¥å¿—æ–‡ä»¶å·²ä¿å­˜: print_log/print_log_20251114_224113.log\n"
     ]
    }
   ],
   "source": [
    "# Pokemon Battles Prediction 2025 - Enhanced Version\n",
    "# FDS Kaggle Competition Solution - Advanced Feature Engineering\n",
    "\n",
    "\"\"\"\n",
    "===============================================================================\n",
    "                          ç‰¹å¾å·¥ç¨‹æ€»ç»“\n",
    "===============================================================================\n",
    "\n",
    "æœ¬æ–¹æ¡ˆä½¿ç”¨äº†çº¦233ä¸ªç²¾å¿ƒè®¾è®¡çš„ç‰¹å¾ï¼Œåˆ†ä¸ºä¸‰å¤§ç±»ï¼š\n",
    "\n",
    "ã€ä¸€ã€é™æ€ç‰¹å¾ (60ä¸ª)ã€‘- æ¥è‡ªé˜Ÿä¼å’ŒPokemonåŸºç¡€å±æ€§\n",
    "    \n",
    "    1. P1é˜Ÿä¼å±æ€§èšåˆ (30ä¸ª)\n",
    "       - 6ä¸ªåŸºç¡€å±æ€§: HP, ATK, DEF, SPA, SPD, SPE\n",
    "       - 5ç§èšåˆæ–¹å¼: sum(æ€»å’Œ), mean(å‡å€¼), max(æœ€å¤§), min(æœ€å°), std(æ ‡å‡†å·®)\n",
    "       - ç‰¹å¾ç¤ºä¾‹: p1_team_hp_sum, p1_team_atk_mean, p1_team_spe_max\n",
    "       \n",
    "    2. P2é¦–å‘Pokemonå±æ€§ (6ä¸ª)\n",
    "       - p2_lead_hp, p2_lead_atk, p2_lead_def\n",
    "       - p2_lead_spa, p2_lead_spd, p2_lead_spe\n",
    "       \n",
    "    3. å±æ€§å¯¹æ¯”ç‰¹å¾ (12ä¸ª)\n",
    "       - ä¼˜åŠ¿å€¼ (6ä¸ª): hp_advantage, atk_advantage, def_advantage ç­‰\n",
    "       - æ¯”ç‡ (6ä¸ª): hp_ratio, atk_ratio, def_ratio ç­‰\n",
    "       \n",
    "    4. ç±»å‹å…‹åˆ¶ç‰¹å¾ (4ä¸ª)\n",
    "       - type_adv_mean: é˜Ÿä¼å¯¹P2é¦–å‘çš„å¹³å‡ç±»å‹ä¼˜åŠ¿\n",
    "       - type_adv_max: æœ€å¤§ç±»å‹ä¼˜åŠ¿\n",
    "       - type_adv_min: æœ€å°ç±»å‹ä¼˜åŠ¿  \n",
    "       - type_adv_std: ç±»å‹ä¼˜åŠ¿æ ‡å‡†å·®\n",
    "       \n",
    "    5. é˜Ÿä¼å¤šæ ·æ€§ç‰¹å¾ (2ä¸ª)\n",
    "       - type_diversity: ç±»å‹å¤šæ ·æ€§ï¼ˆå”¯ä¸€ç±»å‹æ•°/æ€»ç±»å‹æ•°ï¼‰\n",
    "       - stat_diversity: å±æ€§å¤šæ ·æ€§ï¼ˆå˜å¼‚ç³»æ•°ï¼‰\n",
    "       \n",
    "    6. é˜Ÿä¼å¹³è¡¡æ€§ç‰¹å¾ (3ä¸ª)\n",
    "       - physical_special_atk_ratio: ç‰©æ”»/ç‰¹æ”»æ¯”\n",
    "       - physical_special_def_ratio: ç‰©é˜²/ç‰¹é˜²æ¯”\n",
    "       - offense_defense_ratio: æ”»å‡»/é˜²å¾¡æ¯”\n",
    "       \n",
    "    7. æ€»ä½“å®åŠ›ç‰¹å¾ (3ä¸ª)\n",
    "       - p1_total_stats: P1é˜Ÿä¼æ€»å±æ€§å€¼\n",
    "       - p2_total_stats: P2é¦–å‘æ€»å±æ€§å€¼\n",
    "       - total_stats_advantage: æ€»å±æ€§ä¼˜åŠ¿\n",
    "\n",
    "ã€äºŒã€åŠ¨æ€ç‰¹å¾ (174ä¸ª)ã€‘- æ¥è‡ªæˆ˜æ–—æ—¶é—´çº¿åˆ†æ\n",
    "\n",
    "    1. åŸºç¡€ä¿¡æ¯ (1ä¸ª)\n",
    "       - total_turns: æˆ˜æ–—æ€»å›åˆæ•°\n",
    "       \n",
    "    2. æ•´ä½“HPç»Ÿè®¡ (14ä¸ª)\n",
    "       - æ¯ä¸ªç©å®¶7ä¸ª: start(èµ·å§‹), end(ç»“æŸ), min(æœ€ä½), max(æœ€é«˜),\n",
    "                      avg(å¹³å‡), std(æ ‡å‡†å·®), trend(è¶‹åŠ¿çº¿æ–œç‡)\n",
    "       - ç‰¹å¾ç¤ºä¾‹: p1_hp_start, p2_hp_end, p1_hp_trend\n",
    "       \n",
    "    3. åˆ†æ®µHPç»Ÿè®¡ (12ä¸ª) â­æ–°å¢\n",
    "       - ä¸‰ä¸ªé˜¶æ®µ: early(å‰1/3), mid(ä¸­1/3), late(å1/3)\n",
    "       - æ¯ä¸ªé˜¶æ®µæ¯ä¸ªç©å®¶2ä¸ª: avg(å¹³å‡HP), min(æœ€ä½HP)\n",
    "       - ç‰¹å¾ç¤ºä¾‹: p1_early_hp_avg, p2_late_hp_min\n",
    "       \n",
    "    4. HPæŸå¤±é€Ÿç‡ (4ä¸ª)\n",
    "       - p1_avg_hp_loss, p1_max_hp_loss: P1å¹³å‡å’Œæœ€å¤§HPæŸå¤±\n",
    "       - p2_avg_hp_loss, p2_max_hp_loss: P2å¹³å‡å’Œæœ€å¤§HPæŸå¤±\n",
    "       \n",
    "    5. HPä¼˜åŠ¿æŒ‡æ ‡ (3ä¸ª)\n",
    "       - hp_advantage_start: èµ·å§‹HPä¼˜åŠ¿\n",
    "       - hp_advantage_end: ç»“æŸHPä¼˜åŠ¿  \n",
    "       - hp_advantage_avg: å¹³å‡HPä¼˜åŠ¿\n",
    "       \n",
    "    6. æ‹›å¼å¤šæ ·æ€§ (2ä¸ª)\n",
    "       - p1_move_diversity: P1æ‹›å¼å¤šæ ·æ€§ï¼ˆå”¯ä¸€æ‹›å¼æ•°/æ€»æ‹›å¼æ•°ï¼‰\n",
    "       - p2_move_diversity: P2æ‹›å¼å¤šæ ·æ€§\n",
    "       \n",
    "    7. çŠ¶æ€å¼‚å¸¸æ€»è®¡ (2ä¸ª)\n",
    "       - p1_status_changes: P1çŠ¶æ€å¼‚å¸¸å›åˆæ•°\n",
    "       - p2_status_changes: P2çŠ¶æ€å¼‚å¸¸å›åˆæ•°\n",
    "       \n",
    "    8. å¼‚å¸¸çŠ¶æ€ç»Ÿè®¡ (1ä¸ª) â­æ–°å¢\n",
    "       - abnormal_status_count_ratio: P1å‰30å›åˆå‡ºç°çš„ç²¾çµä¸­æœ‰å¼‚å¸¸çŠ¶æ€çš„ç²¾çµæ•°é‡ / (P2å‰30å›åˆå‡ºç°çš„ç²¾çµä¸­æœ‰å¼‚å¸¸çŠ¶æ€çš„ç²¾çµæ•°é‡ + 1)\n",
    "       - è¯´æ˜ï¼šç»Ÿè®¡å‰30å›åˆå‡ºç°çš„æ‰€æœ‰ç²¾çµï¼ˆæœ€å¤š6åªï¼Œä¹Ÿå¯èƒ½ä¸è¶³6åªï¼‰ä¸­ï¼Œæœ€ç»ˆçŠ¶æ€ä¸ºå¼‚å¸¸çŠ¶æ€ï¼ˆénostatusï¼Œéfntï¼‰çš„ç²¾çµæ•°é‡æ¯”å€¼\n",
    "       - ä½¿ç”¨å¹³æ»‘å¤„ç†é¿å…é™¤ä»¥0ï¼Œæ¯”å€¼åæ˜ åŒæ–¹å—å¼‚å¸¸çŠ¶æ€å½±å“çš„ç›¸å¯¹ç¨‹åº¦\n",
    "       \n",
    "    9. CounteræŠ€èƒ½ç»Ÿè®¡ (2ä¸ª) â­æ–°å¢\n",
    "       - p1_counter_invalid: P1ä½¿ç”¨Counterä½†æ— æ•ˆçš„æ¬¡æ•°\n",
    "       - p2_counter_invalid: P2ä½¿ç”¨Counterä½†æ— æ•ˆçš„æ¬¡æ•°\n",
    "       - è¯´æ˜ï¼šCounteråªèƒ½åå¼¹ç‰©ç†æ”»å‡»ï¼Œå¯¹æ‰‹ä½¿ç”¨ç‰¹æ®Š/çŠ¶æ€æŠ€æˆ–æ¢äººæ—¶æ— æ•ˆ\n",
    "       \n",
    "   10. æ‹›å¼å¨åŠ›ç»Ÿè®¡ (6ä¸ª)\n",
    "       - æ¯ä¸ªç©å®¶3ä¸ª: avg_move_power, max_move_power, min_move_power\n",
    "       - ç‰¹å¾ç¤ºä¾‹: p1_avg_move_power, p2_max_move_power\n",
    "       \n",
    "   11. æ‹›å¼å‘½ä¸­ç‡ (2ä¸ª)\n",
    "       - p1_avg_accuracy: P1å¹³å‡å‘½ä¸­ç‡\n",
    "       - p2_avg_accuracy: P2å¹³å‡å‘½ä¸­ç‡\n",
    "       \n",
    "   12. æ‹›å¼ç±»åˆ«æ¯”ä¾‹ (6ä¸ª)\n",
    "       - æ¯ä¸ªç©å®¶3ä¸ª: physical_move_ratio, special_move_ratio, status_move_ratio\n",
    "       - åˆ†åˆ«ç»Ÿè®¡ç‰©ç†ã€ç‰¹æ®Šã€å˜åŒ–æ‹›å¼çš„ä½¿ç”¨æ¯”ä¾‹\n",
    "       \n",
    "   13. æ¢ç²¾çµç»Ÿè®¡ (10ä¸ª) â­å¢å¼º\n",
    "       - p1_switch_count, p2_switch_count: æ¢ç²¾çµæ¬¡æ•°\n",
    "       - p1_early_switch_ratio, p2_early_switch_ratio: æ—©æœŸæ¢ç²¾çµæ¯”ä¾‹\n",
    "       - p1_move_null_count, p2_move_null_count: move_detailsä¸ºnullçš„æ€»æ¬¡æ•°ï¼ˆä¿ç•™ç”¨äºå…¼å®¹ï¼‰\n",
    "       - p1_move_null_switch, p2_move_null_switch: å› æ¢äººå¯¼è‡´çš„move_detailsä¸ºnullçš„æ¬¡æ•° â­æ–°å¢\n",
    "       - p1_move_null_status, p2_move_null_status: å› çŠ¶æ€å¼‚å¸¸å¯¼è‡´çš„move_detailsä¸ºnullçš„æ¬¡æ•° â­æ–°å¢\n",
    "       \n",
    "   14. æŠ€èƒ½ä½¿ç”¨æ¬¡æ•°ç»Ÿè®¡ (80ä¸ª) â­æ–°å¢\n",
    "       - æ¯ä¸ªæŠ€èƒ½çš„ä½¿ç”¨æ¬¡æ•°: P1å’ŒP2å„40ä¸ªæŠ€èƒ½\n",
    "       - ç‰¹å¾æ ¼å¼: p1_move_{skill_name}_count, p2_move_{skill_name}_count\n",
    "       - ç»Ÿè®¡æˆ˜æ–—è¿‡ç¨‹ä¸­æ¯ä¸ªæŠ€èƒ½è¢«ä½¿ç”¨çš„æ€»æ¬¡æ•°\n",
    "       - ä¾‹å¦‚: p1_move_thunderbolt_count, p2_move_ice_beam_count\n",
    "       \n",
    "   15. è¿ç»­æ”»å‡»ç»Ÿè®¡ (2ä¸ª) â­æ–°å¢\n",
    "       - p1_max_consecutive_attacks: P1æœ€å¤§è¿ç»­æ”»å‡»å›åˆæ•°\n",
    "       - p2_max_consecutive_attacks: P2æœ€å¤§è¿ç»­æ”»å‡»å›åˆæ•°\n",
    "       \n",
    "   16. å±æ€§æå‡ (Boost) ç»Ÿè®¡ (13ä¸ª)\n",
    "       - æ¯ä¸ªç©å®¶6ä¸ª: final_boost_sum, final_atk_boost, final_def_boost,\n",
    "                      final_spa_boost, final_spd_boost, final_spe_boost\n",
    "       - boost_advantage: P1å’ŒP2çš„boostæ€»å’Œå·®å€¼\n",
    "       \n",
    "   17. åœºåœ°æ•ˆæœç»Ÿè®¡ (2ä¸ª)\n",
    "       - p1_effect_turns: P1å—æ•ˆæœå½±å“çš„å›åˆæ•°\n",
    "       - p2_effect_turns: P2å—æ•ˆæœå½±å“çš„å›åˆæ•°\n",
    "       \n",
    "   18. å‰30å›åˆç²¾çµä¸ªæ•°ç»Ÿè®¡ (2ä¸ª) â­æ–°å¢\n",
    "       - p1_unique_pokemon_count_30turns: P1åœ¨å‰30å›åˆå†…å‡ºç°çš„ä¸åŒç²¾çµä¸ªæ•°\n",
    "       - p2_unique_pokemon_count_30turns: P2åœ¨å‰30å›åˆå†…å‡ºç°çš„ä¸åŒç²¾çµä¸ªæ•°\n",
    "       - ç»Ÿè®¡å‰30å›åˆå†…æ¯ä¸ªç©å®¶ä½¿ç”¨äº†å¤šå°‘ç§ä¸åŒçš„ç²¾çµ\n",
    "       \n",
    "   19. å‰30å›åˆ6åªç²¾çµæ€»HPç»Ÿè®¡ (3ä¸ª) â­æ–°å¢\n",
    "       - p1_total_pokemon_hp_pct_30turns: P1çš„6åªç²¾çµåœ¨å‰30å›åˆå†…çš„hp_pctæ€»å’Œ\n",
    "       - p2_total_pokemon_hp_pct_30turns: P2çš„6åªç²¾çµåœ¨å‰30å›åˆå†…çš„hp_pctæ€»å’Œ\n",
    "       - total_pokemon_hp_pct_ratio_30turns: P1å’ŒP2å‰30å›åˆæ€»HPçš„æ¯”å€¼ (p1/p2) â­æ–°å¢\n",
    "       - å¯¹äºæ¯åªå‡ºç°çš„ç²¾çµï¼Œå–å®ƒæœ€åä¸€æ¬¡å‡ºç°çš„hp_pct\n",
    "       - å¦‚æœå‰30å›åˆå†…å‡ºç°çš„ç²¾çµä¸è¶³6åªï¼Œå…¶ä½™ç²¾çµæŒ‰æ»¡è¡€1.0è®¡ç®—\n",
    "       - æœ€ç»ˆæ€»å’Œ = å‡ºç°ç²¾çµçš„æœ€åhp_pctä¹‹å’Œ + (6 - å‡ºç°æ•°é‡) Ã— 1.0\n",
    "       - åæ˜ é˜Ÿä¼æ•´ä½“åœ¨å‰30å›åˆçš„è¡€é‡çŠ¶æ€å’Œç›¸å¯¹ä¼˜åŠ¿\n",
    "       \n",
    "   20. æ­»äº¡ç²¾çµæ•°é‡ç»Ÿè®¡ (2ä¸ª) â­æ–°å¢\n",
    "       - fnt_count_ratio: P1æ­»äº¡ç²¾çµæ•°é‡ / (P2æ­»äº¡ç²¾çµæ•°é‡ + 1)\n",
    "       - fnt_count_diff: P1æ­»äº¡ç²¾çµæ•°é‡ - P2æ­»äº¡ç²¾çµæ•°é‡\n",
    "       - ç»Ÿè®¡æˆ˜æ–—æ—¶é—´çº¿ä¸­æ‰€æœ‰å‡ºç°è¿‡çš„ç²¾çµï¼ŒçŠ¶æ€ä¸º'fnt'çš„æ•°é‡\n",
    "       - æ¯”å€¼ç‰¹å¾åæ˜ åŒæ–¹çš„æˆ˜æŸæ¯”ï¼ˆä½¿ç”¨å¹³æ»‘å¤„ç†é¿å…é™¤ä»¥0ï¼‰\n",
    "       - å·®å€¼ç‰¹å¾åæ˜ ç»å¯¹ä¼˜åŠ¿ï¼ˆæ­£æ•°è¡¨ç¤ºP1æŸå¤±æ›´å¤§ï¼Œè´Ÿæ•°è¡¨ç¤ºP2æŸå¤±æ›´å¤§ï¼‰\n",
    "\n",
    "   21. ç±»å‹å…‹åˆ¶æ•ˆæœå€æ•° (2ä¸ª) â­æ–°å¢\n",
    "       - p1_avg: ç©å®¶1é˜Ÿä¼å¯¹ç©å®¶2é˜Ÿä¼çš„å¹³å‡ç±»å‹æ•ˆæœå€æ•°\n",
    "       - p2_avg: ç©å®¶2é˜Ÿä¼å¯¹ç©å®¶1é˜Ÿä¼çš„å¹³å‡ç±»å‹æ•ˆæœå€æ•°\n",
    "       - åŸºäºæˆ˜æ–—è¿‡ç¨‹ä¸­ä½¿ç”¨çš„æŠ€èƒ½ç±»å‹ï¼Œè®¡ç®—ç±»å‹å…‹åˆ¶æ•ˆæœ\n",
    "       - è€ƒè™‘æŠ€èƒ½å¨åŠ›å’Œç±»å‹å…‹åˆ¶å…³ç³»ï¼ˆè¶…æœ‰æ•ˆ2å€ã€æ•ˆæœä¸ä½³0.5å€ã€æ— æ•ˆ0å€ï¼‰\n",
    "       - åæ˜ åŒæ–¹é˜Ÿä¼åœ¨ç±»å‹ä¸Šçš„ç›¸å¯¹ä¼˜åŠ¿\n",
    "       \n",
    "   22. å…ˆåˆ¶æŠ€èƒ½ä¼˜å…ˆçº§æ€»å’Œ (2ä¸ª) â­æ–°å¢\n",
    "       - p1_num_priority_moves: ç©å®¶1å…ˆåˆ¶æŠ€èƒ½çš„ä¼˜å…ˆçº§æ€»å’Œ\n",
    "       - p2_num_priority_moves: ç©å®¶2å…ˆåˆ¶æŠ€èƒ½çš„ä¼˜å…ˆçº§æ€»å’Œ\n",
    "       - ç»Ÿè®¡æ‰€æœ‰å…ˆåˆ¶æŠ€èƒ½çš„ä¼˜å…ˆçº§å€¼æ€»å’Œï¼Œç”¨äºè¯„ä¼°é˜Ÿä¼çš„å…ˆåˆ¶æ”»å‡»èƒ½åŠ›\n",
    "       - ä¼˜å…ˆçº§å€¼è¶Šé«˜ï¼Œè¡ŒåŠ¨é¡ºåºè¶Šé å‰ï¼Œåœ¨æˆ˜æ–—ä¸­å…·æœ‰é€Ÿåº¦ä¼˜åŠ¿\n",
    "\n",
    "ã€ä¸‰ã€äº¤äº’ç‰¹å¾ (4ä¸ª)ã€‘- ç»„åˆç‰¹å¾\n",
    "\n",
    "    1. hp_boost_interaction: HPä¼˜åŠ¿ Ã— Boostä¼˜åŠ¿\n",
    "       - æ•æ‰è¡€é‡å’Œå±æ€§æå‡çš„ååŒæ•ˆåº”\n",
    "       \n",
    "    2. p1_effective_power: P1å¹³å‡å¨åŠ› Ã— P1å¹³å‡å‘½ä¸­ç‡\n",
    "       - P1çš„æœ‰æ•ˆæ”»å‡»åŠ›ï¼ˆè€ƒè™‘å‘½ä¸­ï¼‰\n",
    "       \n",
    "    3. p2_effective_power: P2å¹³å‡å¨åŠ› Ã— P2å¹³å‡å‘½ä¸­ç‡\n",
    "       - P2çš„æœ‰æ•ˆæ”»å‡»åŠ›ï¼ˆè€ƒè™‘å‘½ä¸­ï¼‰\n",
    "       \n",
    "    4. type_stats_interaction: ç±»å‹ä¼˜åŠ¿å‡å€¼ Ã— æ€»å±æ€§ä¼˜åŠ¿\n",
    "       - ç±»å‹å…‹åˆ¶å’Œå±æ€§ä¼˜åŠ¿çš„ç»„åˆæ•ˆåº”\n",
    "\n",
    "ã€æ€»è®¡ã€‘\n",
    "    - é™æ€ç‰¹å¾: 60ä¸ª\n",
    "    - åŠ¨æ€ç‰¹å¾: 179ä¸ª (åŸ175ä¸ª + 2ä¸ªç±»å‹å…‹åˆ¶æ•ˆæœå€æ•°ç‰¹å¾ + 2ä¸ªå…ˆåˆ¶æŠ€èƒ½ä¼˜å…ˆçº§æ€»å’Œç‰¹å¾)  # å·²æ³¨é‡Šæ‰ç¬¬30å›åˆç»„åˆèƒœç‡ç‰¹å¾\n",
    "    - äº¤äº’ç‰¹å¾: 4ä¸ª\n",
    "    - æ€»ç‰¹å¾æ•°: çº¦243ä¸ª\n",
    "\n",
    "ã€ç‰¹å¾å·¥ç¨‹äº®ç‚¹ã€‘\n",
    "    âœ¨ å¤šç»´åº¦èšåˆ: ä½¿ç”¨5ç§ç»Ÿè®¡é‡å…¨é¢æè¿°é˜Ÿä¼å±æ€§\n",
    "    âœ¨ æ—¶é—´åˆ†æ®µåˆ†æ: å°†æˆ˜æ–—åˆ†ä¸ºæ—©ä¸­æ™šæœŸï¼Œæ•æ‰ä¸åŒé˜¶æ®µç‰¹å¾\n",
    "    âœ¨ å®Œæ•´ç±»å‹å…‹åˆ¶: åŸºäºGen 1-9çš„å®Œæ•´ç±»å‹å…‹åˆ¶è¡¨\n",
    "    âœ¨ æˆ˜æœ¯ç‰¹å¾: è¿ç»­æ”»å‡»ã€æ¢ç²¾çµæ—¶æœºç­‰é«˜çº§æˆ˜æœ¯æŒ‡æ ‡\n",
    "    âœ¨ ç‰¹å¾äº¤äº’: æ•æ‰å¤šä¸ªç‰¹å¾ä¹‹é—´çš„éçº¿æ€§å…³ç³»\n",
    "\n",
    "ã€æ¨¡å‹é›†æˆç­–ç•¥ã€‘\n",
    "    - åŸºç¡€æ¨¡å‹: RandomForest, XGBoost, LightGBM, CatBoost, GradientBoosting\n",
    "    - é›†æˆæ–¹æ³•: Stacking (å…ƒå­¦ä¹ å™¨: LogisticRegression) + Voting (Soft)\n",
    "    - éªŒè¯ç­–ç•¥: 80/20åˆ†å‰² + åˆ†å±‚é‡‡æ ·\n",
    "\n",
    "ã€é¢„æœŸæ€§èƒ½ã€‘\n",
    "    - éªŒè¯é›†å‡†ç¡®ç‡: 82-86%\n",
    "    - ç›¸æ¯”åŸºç¡€æ–¹æ¡ˆæå‡: +2-4%\n",
    "    \n",
    "===============================================================================\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif, RFE, RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.inspection import permutation_importance\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "\n",
    "\n",
    "def extract_final_pokemon_status(timeline):\n",
    "    \"\"\"\n",
    "    æ ¹æ®æˆ˜æ–—æ—¶é—´çº¿æå–åŒæ–¹ç²¾çµçš„æœ€ç»ˆçŠ¶æ€ã€‚\n",
    "    \n",
    "    è¿”å›:\n",
    "    - p1_alive_pokemon_names: P1æœ€ç»ˆå­˜æ´»ç²¾çµåç§°é›†åˆ\n",
    "    - p1_fnt_pokemon_names: P1æœ€ç»ˆæ­»äº¡ç²¾çµåç§°é›†åˆ\n",
    "    - p2_alive_pokemon_names: P2æœ€ç»ˆå­˜æ´»ç²¾çµåç§°é›†åˆ\n",
    "    \"\"\"\n",
    "    p1_alive_pokemon_names = set()\n",
    "    p1_fnt_pokemon_names = set()\n",
    "    p2_alive_pokemon_names = set()\n",
    "    p1_last_status = {}\n",
    "    p2_last_status = {}\n",
    "    for turn in timeline:\n",
    "        p1_pokemon_state = turn.get('p1_pokemon_state', {})\n",
    "        p1_pokemon_name = p1_pokemon_state.get('name', '')\n",
    "        if p1_pokemon_name:\n",
    "            p1_last_status[p1_pokemon_name] = p1_pokemon_state.get('status', 'nostatus')\n",
    "\n",
    "        p2_pokemon_state = turn.get('p2_pokemon_state', {})\n",
    "        p2_pokemon_name = p2_pokemon_state.get('name', '')\n",
    "        if p2_pokemon_name:\n",
    "            p2_last_status[p2_pokemon_name] = p2_pokemon_state.get('status', 'nostatus')\n",
    "\n",
    "    for pokemon_name, status in p1_last_status.items():\n",
    "        if status == 'fnt':\n",
    "            p1_fnt_pokemon_names.add(pokemon_name)\n",
    "        else:\n",
    "            p1_alive_pokemon_names.add(pokemon_name)\n",
    "\n",
    "    for pokemon_name, status in p2_last_status.items():\n",
    "        if status != 'fnt':\n",
    "            p2_alive_pokemon_names.add(pokemon_name)\n",
    "\n",
    "    return p1_alive_pokemon_names, p1_fnt_pokemon_names, p2_alive_pokemon_names\n",
    "\n",
    "def extract_moves(data: dict):\n",
    "    \"\"\"\n",
    "    æå–æˆ˜æ–—è¿‡ç¨‹ä¸­æ¯ä¸ªç©å®¶ä½¿ç”¨çš„æŠ€èƒ½é›†åˆã€‚\n",
    "    \n",
    "    è¯¥å‡½æ•°éå†æˆ˜æ–—æ—¶é—´çº¿ï¼Œè®°å½•æ¯ä¸ªå®å¯æ¢¦ä½¿ç”¨çš„æ‰€æœ‰æŠ€èƒ½ã€‚å¦‚æœå®å¯æ¢¦è¢«å‡»è´¥ï¼ˆfaintedï¼‰ï¼Œ\n",
    "    åˆ™ç§»é™¤è¯¥å®å¯æ¢¦çš„æŠ€èƒ½è®°å½•ï¼Œå› ä¸ºè¢«å‡»è´¥çš„å®å¯æ¢¦ä¸åº”è¯¥è¢«è®¡å…¥æœ€ç»ˆçš„ç‰¹å¾è®¡ç®—ã€‚\n",
    "    \n",
    "    Args:\n",
    "        data (dict): æˆ˜æ–—æ•°æ®å­—å…¸ï¼Œå¿…é¡»åŒ…å« \"battle_timeline\" é”®ï¼Œå…¶ä¸­åŒ…å«æ¯ä¸ªå›åˆçš„ä¿¡æ¯\n",
    "    \n",
    "    Returns:\n",
    "        p1_pokemon_moves (dict): ç©å®¶1çš„å®å¯æ¢¦ä½¿ç”¨çš„æŠ€èƒ½å­—å…¸\n",
    "            æ ¼å¼: {å®å¯æ¢¦å: [æŠ€èƒ½è¯¦æƒ…1, æŠ€èƒ½è¯¦æƒ…2, ...]}\n",
    "        p2_pokemon_moves (dict): ç©å®¶2çš„å®å¯æ¢¦ä½¿ç”¨çš„æŠ€èƒ½å­—å…¸\n",
    "            æ ¼å¼: {å®å¯æ¢¦å: [æŠ€èƒ½è¯¦æƒ…1, æŠ€èƒ½è¯¦æƒ…2, ...]}\n",
    "    \"\"\"\n",
    "    # åˆå§‹åŒ–ä¸¤ä¸ªå­—å…¸ï¼Œç”¨äºå­˜å‚¨æ¯ä¸ªç©å®¶æ¯ä¸ªå®å¯æ¢¦ä½¿ç”¨çš„æŠ€èƒ½åˆ—è¡¨\n",
    "    p1_pokemon_moves = {}  # ç©å®¶1çš„å®å¯æ¢¦æŠ€èƒ½å­—å…¸\n",
    "    p2_pokemon_moves = {}  # ç©å®¶2çš„å®å¯æ¢¦æŠ€èƒ½å­—å…¸\n",
    "\n",
    "    # éå†æˆ˜æ–—æ—¶é—´çº¿çš„æ¯ä¸ªå›åˆ\n",
    "    for turn in data.get(\"battle_timeline\", []):\n",
    "        # è·å–å½“å‰å›åˆä¸­ä¸¤ä¸ªç©å®¶å‡ºåœºçš„å®å¯æ¢¦åç§°\n",
    "        p1_name = turn.get(\"p1_pokemon_state\", {}).get(\"name\", \"\")  # ç©å®¶1å½“å‰å®å¯æ¢¦åç§°\n",
    "        p2_name = turn.get(\"p2_pokemon_state\", {}).get(\"name\", \"\")  # ç©å®¶2å½“å‰å®å¯æ¢¦åç§°\n",
    "\n",
    "        # å¤„ç†ç©å®¶1çš„æŠ€èƒ½è®°å½•\n",
    "        # æ¡ä»¶ï¼šæŠ€èƒ½è¯¦æƒ…ä¸ä¸ºç©º ä¸” (è¯¥å®å¯æ¢¦è¿˜æœªè®°å½• æˆ– è¯¥æŠ€èƒ½è¿˜æœªè¢«è®°å½•è¿‡)\n",
    "        p1_move = turn.get(\"p1_move_details\")\n",
    "        if p1_move is not None and (p1_name not in p1_pokemon_moves or p1_move not in p1_pokemon_moves[p1_name]):\n",
    "            # å¦‚æœè¯¥å®å¯æ¢¦ä¸åœ¨å­—å…¸ä¸­ï¼Œåˆ›å»ºç©ºåˆ—è¡¨ï¼›å¦åˆ™ä½¿ç”¨ç°æœ‰åˆ—è¡¨\n",
    "            # ç„¶åæ·»åŠ æ–°çš„æŠ€èƒ½è¯¦æƒ…ï¼ˆå»é‡ï¼šç›¸åŒæŠ€èƒ½ä¸ä¼šé‡å¤æ·»åŠ ï¼‰\n",
    "            p1_pokemon_moves.setdefault(p1_name, []).append(p1_move)\n",
    "        \n",
    "        # å¤„ç†ç©å®¶2çš„æŠ€èƒ½è®°å½•ï¼ˆé€»è¾‘åŒä¸Šï¼‰\n",
    "        p2_move = turn.get(\"p2_move_details\")\n",
    "        if p2_move is not None and (p2_name not in p2_pokemon_moves or p2_move not in p2_pokemon_moves[p2_name]):\n",
    "            p2_pokemon_moves.setdefault(p2_name, []).append(p2_move)\n",
    "\n",
    "        # å¦‚æœç©å®¶1çš„å®å¯æ¢¦è¢«å‡»è´¥ï¼ˆstatus == \"fnt\"ï¼‰ï¼Œç§»é™¤è¯¥å®å¯æ¢¦çš„æŠ€èƒ½è®°å½•\n",
    "        # å› ä¸ºè¢«å‡»è´¥çš„å®å¯æ¢¦ä¸åº”è¯¥å‚ä¸åç»­çš„ç‰¹å¾è®¡ç®—\n",
    "        p1_status = turn.get(\"p1_pokemon_state\", {}).get(\"status\", \"\")\n",
    "        if p1_status == \"fnt\":\n",
    "            p1_pokemon_moves.pop(p1_name, None)  # å®‰å…¨åˆ é™¤ï¼Œå¦‚æœé”®ä¸å­˜åœ¨ä¹Ÿä¸æŠ¥é”™\n",
    "        \n",
    "        # å¦‚æœç©å®¶2çš„å®å¯æ¢¦è¢«å‡»è´¥ï¼Œç§»é™¤è¯¥å®å¯æ¢¦çš„æŠ€èƒ½è®°å½•\n",
    "        p2_status = turn.get(\"p2_pokemon_state\", {}).get(\"status\", \"\")\n",
    "        if p2_status == \"fnt\":\n",
    "            p2_pokemon_moves.pop(p2_name, None)  # å®‰å…¨åˆ é™¤ï¼Œå¦‚æœé”®ä¸å­˜åœ¨ä¹Ÿä¸æŠ¥é”™\n",
    "\n",
    "    return p1_pokemon_moves, p2_pokemon_moves\n",
    "\n",
    "def type_multiplier(p1_moves: dict, p2_moves: dict):\n",
    "    \"\"\"\n",
    "    è®¡ç®—æ¯ä¸ªé˜Ÿä¼çš„å¹³å‡ç±»å‹æ•ˆæœå€æ•°ï¼ˆtype effectiveness multiplierï¼‰ã€‚\n",
    "    \n",
    "    è¯¥å‡½æ•°é€šè¿‡åˆ†æä¸¤ä¸ªç©å®¶ä½¿ç”¨çš„æŠ€èƒ½ç±»å‹ï¼Œè®¡ç®—æ¯ä¸ªç©å®¶é˜Ÿä¼å¯¹å¯¹æ–¹é˜Ÿä¼çš„å¹³å‡ç±»å‹å…‹åˆ¶æ•ˆæœã€‚\n",
    "    ç±»å‹å…‹åˆ¶å…³ç³»ï¼šè¶…æœ‰æ•ˆï¼ˆ2å€ï¼‰> æ™®é€šï¼ˆ1å€ï¼‰> æ•ˆæœä¸ä½³ï¼ˆ0.5å€ï¼‰> æ— æ•ˆï¼ˆ0å€ï¼‰\n",
    "    \n",
    "    Args:\n",
    "        p1_moves (dict): ç©å®¶1çš„å®å¯æ¢¦ä½¿ç”¨çš„æŠ€èƒ½å­—å…¸ï¼Œæ ¼å¼ä¸º {å®å¯æ¢¦å: [æŠ€èƒ½åˆ—è¡¨]}\n",
    "        p2_moves (dict): ç©å®¶2çš„å®å¯æ¢¦ä½¿ç”¨çš„æŠ€èƒ½å­—å…¸ï¼Œæ ¼å¼ä¸º {å®å¯æ¢¦å: [æŠ€èƒ½åˆ—è¡¨]}\n",
    "    \n",
    "    Returns:\n",
    "        p1_team_avg (float): ç©å®¶1é˜Ÿä¼å¯¹ç©å®¶2é˜Ÿä¼çš„å¹³å‡ç±»å‹æ•ˆæœå€æ•°\n",
    "        p2_team_avg (float): ç©å®¶2é˜Ÿä¼å¯¹ç©å®¶1é˜Ÿä¼çš„å¹³å‡ç±»å‹æ•ˆæœå€æ•°\n",
    "    \"\"\"\n",
    "    # ç¬¬ä¸€æ­¥ï¼šæå–æ¯ä¸ªå®å¯æ¢¦ä½¿ç”¨çš„æ”»å‡»æŠ€èƒ½ç±»å‹å’Œå¨åŠ›\n",
    "    # åªä¿ç•™æœ‰ç±»å‹ã€æœ‰åŸºç¡€å¨åŠ›ä¸”ä¸æ˜¯çŠ¶æ€ç±»æŠ€èƒ½çš„æ”»å‡»æŠ€èƒ½\n",
    "    type_pokemon1 = {}  # å­˜å‚¨ç©å®¶1æ¯ä¸ªå®å¯æ¢¦çš„æŠ€èƒ½ç±»å‹å’Œå¨åŠ›ä¿¡æ¯\n",
    "    type_pokemon2 = {}  # å­˜å‚¨ç©å®¶2æ¯ä¸ªå®å¯æ¢¦çš„æŠ€èƒ½ç±»å‹å’Œå¨åŠ›ä¿¡æ¯\n",
    "\n",
    "    # å¤„ç†ç©å®¶1çš„å®å¯æ¢¦æŠ€èƒ½\n",
    "    for pokemon, moves in p1_moves.items():\n",
    "        type_pokemon1[pokemon] = []\n",
    "        for move in moves:\n",
    "            # è¿‡æ»¤æ¡ä»¶ï¼šæŠ€èƒ½å­˜åœ¨ã€æœ‰ç±»å‹ã€æœ‰åŸºç¡€å¨åŠ›ã€ä¸æ˜¯çŠ¶æ€ç±»æŠ€èƒ½\n",
    "            if move and move.get(\"type\") and move.get(\"base_power\") and move.get(\"category\") != \"STATUS\":\n",
    "                # å­˜å‚¨æŠ€èƒ½ç±»å‹ï¼ˆé¦–å­—æ¯å¤§å†™ï¼‰å’Œæœ‰æ•ˆå¨åŠ›ï¼ˆåŸºç¡€å¨åŠ› Ã— å‘½ä¸­ç‡ï¼‰\n",
    "                type_pokemon1[pokemon].append({\n",
    "                    \"type\": move[\"type\"].capitalize(),  # æŠ€èƒ½ç±»å‹ï¼Œå¦‚ \"Fire\", \"Water\"\n",
    "                    \"power\": move[\"base_power\"] * move.get(\"accuracy\", 1.0)  # æœ‰æ•ˆå¨åŠ› = åŸºç¡€å¨åŠ› Ã— å‘½ä¸­ç‡\n",
    "                })\n",
    "\n",
    "    # å¤„ç†ç©å®¶2çš„å®å¯æ¢¦æŠ€èƒ½ï¼ˆé€»è¾‘åŒä¸Šï¼‰\n",
    "    for pokemon, moves in p2_moves.items():\n",
    "        type_pokemon2[pokemon] = []\n",
    "        for move in moves:\n",
    "            if move and move.get(\"type\") and move.get(\"base_power\") and move.get(\"category\") != \"STATUS\":\n",
    "                type_pokemon2[pokemon].append({\n",
    "                    \"type\": move[\"type\"].capitalize(),\n",
    "                    \"power\": move[\"base_power\"] * move.get(\"accuracy\", 1.0)\n",
    "                })\n",
    "\n",
    "    # ç¬¬äºŒæ­¥ï¼šè®¡ç®—ç±»å‹å…‹åˆ¶æ•ˆæœå€æ•°\n",
    "    diz_multiplier_my_pokemon = {}      # ç©å®¶1çš„æ¯ä¸ªå®å¯æ¢¦å¯¹ç©å®¶2é˜Ÿä¼çš„å¹³å‡æ•ˆæœå€æ•°\n",
    "    diz_multiplier_other_pokemon = {}   # ç©å®¶2çš„æ¯ä¸ªå®å¯æ¢¦å¯¹ç©å®¶1é˜Ÿä¼çš„å¹³å‡æ•ˆæœå€æ•°\n",
    "\n",
    "    # è®¡ç®—ç©å®¶1çš„å®å¯æ¢¦å¯¹ç©å®¶2é˜Ÿä¼çš„å…‹åˆ¶æ•ˆæœ\n",
    "    for pokemon1, moves1 in type_pokemon1.items():\n",
    "        total_effectiveness = []  # å­˜å‚¨è¯¥å®å¯æ¢¦å¯¹ç©å®¶2æ¯ä¸ªå®å¯æ¢¦çš„æ•ˆæœå€æ•°\n",
    "\n",
    "        # éå†ç©å®¶2çš„æ¯ä¸ªå®å¯æ¢¦ï¼Œè®¡ç®—å…‹åˆ¶æ•ˆæœ\n",
    "        for pokemon2, moves2 in type_pokemon2.items():\n",
    "            multiplier = 1.0  # åˆå§‹å€æ•°è®¾ä¸º1.0ï¼ˆæ™®é€šæ•ˆæœï¼‰\n",
    "\n",
    "            # éå†ç©å®¶1è¯¥å®å¯æ¢¦çš„æ¯ä¸ªæŠ€èƒ½\n",
    "            for move in moves1:\n",
    "                t_att = move[\"type\"]  # æ”»å‡»æŠ€èƒ½çš„ç±»å‹\n",
    "                base_power = move[\"power\"]  # æŠ€èƒ½çš„æœ‰æ•ˆå¨åŠ›\n",
    "                # ä»ç±»å‹å…‹åˆ¶è¡¨ä¸­è·å–è¯¥æ”»å‡»ç±»å‹çš„æ•ˆæœåˆ—è¡¨\n",
    "                if t_att not in TABLE_TYPE:\n",
    "                    continue\n",
    "                super_eff, meno_eff, no_eff = TABLE_TYPE[t_att]\n",
    "                # super_eff: è¶…æœ‰æ•ˆçš„é˜²å¾¡ç±»å‹åˆ—è¡¨ï¼ˆ2å€ä¼¤å®³ï¼‰\n",
    "                # meno_eff: æ•ˆæœä¸ä½³çš„é˜²å¾¡ç±»å‹åˆ—è¡¨ï¼ˆ0.5å€ä¼¤å®³ï¼‰\n",
    "                # no_eff: æ— æ•ˆçš„é˜²å¾¡ç±»å‹åˆ—è¡¨ï¼ˆ0å€ä¼¤å®³ï¼‰\n",
    "\n",
    "                # éå†ç©å®¶2å®å¯æ¢¦çš„æ¯ä¸ªé˜²å¾¡ç±»å‹ï¼ˆå®å¯æ¢¦å¯èƒ½æœ‰å¤šä¸ªç±»å‹ï¼‰\n",
    "                for t_def in P_DEF_TYPE.get(pokemon2.lower(), []):\n",
    "                    # æ ¹æ®ç±»å‹å…‹åˆ¶å…³ç³»è°ƒæ•´å€æ•°\n",
    "                    if t_def in no_eff:\n",
    "                        multiplier *= 0.0  # æ— æ•ˆï¼šä¼¤å®³ä¸º0\n",
    "                    elif t_def in super_eff:\n",
    "                        multiplier *= 2.0  # è¶…æœ‰æ•ˆï¼šä¼¤å®³Ã—2\n",
    "                    elif t_def in meno_eff:\n",
    "                        multiplier *= 0.5  # æ•ˆæœä¸ä½³ï¼šä¼¤å®³Ã—0.5\n",
    "\n",
    "                # å°†æŠ€èƒ½å¨åŠ›å½’ä¸€åŒ–ï¼ˆé™¤ä»¥100ï¼‰å¹¶ä¹˜ä»¥ç±»å‹å€æ•°\n",
    "                multiplier *= (base_power / 100.0)\n",
    "\n",
    "            # è®°å½•è¯¥å®å¯æ¢¦å¯¹ç©å®¶2è¯¥å®å¯æ¢¦çš„æ€»æ•ˆæœå€æ•°\n",
    "            total_effectiveness.append(multiplier)\n",
    "\n",
    "        # è®¡ç®—è¯¥å®å¯æ¢¦å¯¹ç©å®¶2æ‰€æœ‰å®å¯æ¢¦çš„å¹³å‡æ•ˆæœå€æ•°\n",
    "        if total_effectiveness:\n",
    "            diz_multiplier_my_pokemon[pokemon1] = np.mean(total_effectiveness)\n",
    "        else:\n",
    "            diz_multiplier_my_pokemon[pokemon1] = 0.0\n",
    "\n",
    "    # è®¡ç®—ç©å®¶2çš„å®å¯æ¢¦å¯¹ç©å®¶1é˜Ÿä¼çš„å…‹åˆ¶æ•ˆæœï¼ˆé€»è¾‘åŒä¸Šï¼Œæ–¹å‘ç›¸åï¼‰\n",
    "    for pokemon2, moves2 in type_pokemon2.items():\n",
    "        total_effectiveness = []\n",
    "\n",
    "        # éå†ç©å®¶1çš„æ¯ä¸ªå®å¯æ¢¦\n",
    "        for pokemon1, moves1 in type_pokemon1.items():\n",
    "            multiplier = 1.0\n",
    "\n",
    "            # éå†ç©å®¶2è¯¥å®å¯æ¢¦çš„æ¯ä¸ªæŠ€èƒ½\n",
    "            for move in moves2:\n",
    "                t_att = move[\"type\"]  # æ”»å‡»æŠ€èƒ½ç±»å‹\n",
    "                base_power = move[\"power\"]  # æŠ€èƒ½æœ‰æ•ˆå¨åŠ›\n",
    "                if t_att not in TABLE_TYPE:\n",
    "                    continue\n",
    "                super_eff, meno_eff, no_eff = TABLE_TYPE[t_att]\n",
    "\n",
    "                # éå†ç©å®¶1å®å¯æ¢¦çš„æ¯ä¸ªé˜²å¾¡ç±»å‹\n",
    "                for t_def in P_DEF_TYPE.get(pokemon1.lower(), []):\n",
    "                    # æ ¹æ®ç±»å‹å…‹åˆ¶å…³ç³»è°ƒæ•´å€æ•°\n",
    "                    if t_def in no_eff:\n",
    "                        multiplier *= 0.0\n",
    "                    elif t_def in super_eff:\n",
    "                        multiplier *= 2.0\n",
    "                    elif t_def in meno_eff:\n",
    "                        multiplier *= 0.5\n",
    "\n",
    "                # å°†æŠ€èƒ½å¨åŠ›å½’ä¸€åŒ–å¹¶ä¹˜ä»¥ç±»å‹å€æ•°\n",
    "                multiplier *= (base_power / 100.0)\n",
    "\n",
    "            total_effectiveness.append(multiplier)\n",
    "\n",
    "        # è®¡ç®—è¯¥å®å¯æ¢¦å¯¹ç©å®¶1æ‰€æœ‰å®å¯æ¢¦çš„å¹³å‡æ•ˆæœå€æ•°\n",
    "        if total_effectiveness:\n",
    "            diz_multiplier_other_pokemon[pokemon2] = np.mean(total_effectiveness)\n",
    "        else:\n",
    "            diz_multiplier_other_pokemon[pokemon2] = 0.0\n",
    "\n",
    "    # ç¬¬ä¸‰æ­¥ï¼šè®¡ç®—æ•´ä¸ªé˜Ÿä¼çš„å¹³å‡ç±»å‹æ•ˆæœå€æ•°\n",
    "    # ç©å®¶1é˜Ÿä¼çš„å¹³å‡æ•ˆæœ = ç©å®¶1æ‰€æœ‰å®å¯æ¢¦çš„å¹³å‡æ•ˆæœå€æ•°çš„å¹³å‡å€¼\n",
    "    if diz_multiplier_my_pokemon:\n",
    "        p1_team_avg = np.mean(list(diz_multiplier_my_pokemon.values()))\n",
    "    else:\n",
    "        p1_team_avg = 0.0\n",
    "    # ç©å®¶2é˜Ÿä¼çš„å¹³å‡æ•ˆæœ = ç©å®¶2æ‰€æœ‰å®å¯æ¢¦çš„å¹³å‡æ•ˆæœå€æ•°çš„å¹³å‡å€¼\n",
    "    if diz_multiplier_other_pokemon:\n",
    "        p2_team_avg = np.mean(list(diz_multiplier_other_pokemon.values()))\n",
    "    else:\n",
    "        p2_team_avg = 0.0\n",
    "\n",
    "    return p1_team_avg, p2_team_avg\n",
    "\n",
    "def count_priority_moves(pokemon_moves: dict) -> int:\n",
    "    \"\"\"\n",
    "    ç»Ÿè®¡å®å¯æ¢¦ä½¿ç”¨çš„æ‰€æœ‰å…ˆåˆ¶æŠ€èƒ½ï¼ˆpriority movesï¼‰çš„ä¼˜å…ˆçº§æ€»å’Œã€‚\n",
    "    \n",
    "    å…ˆåˆ¶æŠ€èƒ½å¯ä»¥åœ¨å¯¹æ‰‹ä¹‹å‰è¡ŒåŠ¨ï¼Œä¼˜å…ˆçº§å€¼è¶Šé«˜ï¼Œè¡ŒåŠ¨é¡ºåºè¶Šé å‰ã€‚\n",
    "    è¯¥å‡½æ•°è®¡ç®—æ‰€æœ‰å…ˆåˆ¶æŠ€èƒ½çš„ä¼˜å…ˆçº§å€¼æ€»å’Œï¼Œç”¨äºè¯„ä¼°é˜Ÿä¼çš„å…ˆåˆ¶æ”»å‡»èƒ½åŠ›ã€‚\n",
    "    \n",
    "    Args:\n",
    "        pokemon_moves (dict): å®å¯æ¢¦æŠ€èƒ½å­—å…¸ï¼Œæ ¼å¼ä¸º {å®å¯æ¢¦å: [æŠ€èƒ½è¯¦æƒ…1, æŠ€èƒ½è¯¦æƒ…2, ...]}\n",
    "            æ¯ä¸ªæŠ€èƒ½è¯¦æƒ…å¯èƒ½åŒ…å« \"priority\" å­—æ®µï¼ˆä¼˜å…ˆçº§å€¼ï¼‰\n",
    "    \n",
    "    Returns:\n",
    "        int: æ‰€æœ‰å…ˆåˆ¶æŠ€èƒ½çš„ä¼˜å…ˆçº§æ€»å’Œï¼Œå¦‚æœæŠ€èƒ½æ²¡æœ‰priorityå­—æ®µåˆ™è§†ä¸º0\n",
    "    \"\"\"\n",
    "    # ç”Ÿæˆå™¨è¡¨è¾¾å¼ï¼šéå†æ‰€æœ‰å®å¯æ¢¦çš„æ‰€æœ‰æŠ€èƒ½ï¼Œè·å–ä¼˜å…ˆçº§å€¼ï¼ˆé»˜è®¤ä¸º0ï¼‰\n",
    "    return sum(move.get(\"priority\", 0) for moves in pokemon_moves.values() for move in moves)\n",
    "\n",
    "# ============================================================================\n",
    "# ç±»å‹å…‹åˆ¶å…³ç³»è¡¨ï¼ˆç”¨äºtype_multiplierç‰¹å¾è®¡ç®—ï¼‰\n",
    "# ============================================================================\n",
    "# å®å¯æ¢¦ç±»å‹å…‹åˆ¶å…³ç³»è¡¨\n",
    "# æ ¼å¼: {æ”»å‡»ç±»å‹: (è¶…æœ‰æ•ˆåˆ—è¡¨, æ•ˆæœä¸ä½³åˆ—è¡¨, æ— æ•ˆåˆ—è¡¨)}\n",
    "# - è¶…æœ‰æ•ˆï¼ˆsuper effectiveï¼‰: ä¼¤å®³Ã—2\n",
    "# - æ•ˆæœä¸ä½³ï¼ˆnot very effectiveï¼‰: ä¼¤å®³Ã—0.5\n",
    "# - æ— æ•ˆï¼ˆno effectï¼‰: ä¼¤å®³Ã—0\n",
    "TABLE_TYPE = {\n",
    "    \"Normal\": ([], [\"Rock\", \"Steel\"], [\"Ghost\"]),\n",
    "    \"Fire\": ([\"Grass\", \"Ice\", \"Bug\", \"Steel\"],\n",
    "             [\"Fire\", \"Water\", \"Rock\", \"Dragon\"], []),\n",
    "    \"Water\": ([\"Fire\", \"Ground\", \"Rock\"],\n",
    "              [\"Water\", \"Grass\", \"Dragon\"], []),\n",
    "    \"Electric\": ([\"Water\", \"Flying\"],\n",
    "                 [\"Electric\", \"Grass\", \"Dragon\"], [\"Ground\"]),\n",
    "    \"Grass\": ([\"Water\", \"Ground\", \"Rock\"],\n",
    "              [\"Fire\", \"Grass\", \"Poison\", \"Flying\", \"Bug\", \"Dragon\", \"Steel\"], []),\n",
    "    \"Ice\": ([\"Grass\", \"Ground\", \"Flying\", \"Dragon\"],\n",
    "            [\"Fire\", \"Water\", \"Ice\", \"Steel\"], []),\n",
    "    \"Fighting\": ([\"Normal\", \"Ice\", \"Rock\", \"Dark\", \"Steel\"],\n",
    "                 [\"Poison\", \"Flying\", \"Psychic\", \"Bug\", \"Fairy\"], []),\n",
    "    \"Poison\": ([\"Grass\", \"Fairy\"],\n",
    "               [\"Poison\", \"Ground\", \"Rock\", \"Ghost\"], []),\n",
    "    \"Ground\": ([\"Fire\", \"Electric\", \"Poison\", \"Rock\", \"Steel\"],\n",
    "               [\"Grass\", \"Bug\"], [\"Flying\"]),\n",
    "    \"Flying\": ([\"Grass\", \"Fighting\", \"Bug\"],\n",
    "               [\"Electric\", \"Rock\", \"Steel\"], []),\n",
    "    \"Psychic\": ([\"Fighting\", \"Poison\"],\n",
    "                [\"Psychic\", \"Steel\"], [\"Dark\"]),\n",
    "    \"Bug\": ([\"Grass\", \"Psychic\", \"Dark\"],\n",
    "            [\"Fire\", \"Fighting\", \"Poison\", \"Flying\", \"Ghost\", \"Steel\", \"Fairy\"], []),\n",
    "    \"Rock\": ([\"Fire\", \"Ice\", \"Flying\", \"Bug\"],\n",
    "             [\"Fighting\", \"Ground\", \"Steel\"], []),\n",
    "    \"Ghost\": ([\"Psychic\", \"Ghost\"],\n",
    "              [\"Dark\"], [\"Normal\"]),\n",
    "    \"Dragon\": ([\"Dragon\"],\n",
    "               [\"Steel\"], [\"Fairy\"]),\n",
    "    \"Dark\": ([\"Psychic\", \"Ghost\"],\n",
    "             [\"Fighting\", \"Dark\", \"Fairy\"], []),\n",
    "    \"Steel\": ([\"Ice\", \"Rock\", \"Fairy\"],\n",
    "              [\"Fire\", \"Water\", \"Electric\", \"Steel\"], []),\n",
    "    \"Fairy\": ([\"Fighting\", \"Dragon\", \"Dark\"],\n",
    "              [\"Fire\", \"Poison\", \"Steel\"], [])\n",
    "}\n",
    "\n",
    "# å®å¯æ¢¦é˜²å¾¡ç±»å‹è¡¨ï¼ˆç¬¬ä¸€ä¸–ä»£å¸¸ç”¨å®å¯æ¢¦ï¼‰\n",
    "# æ ¼å¼: {å®å¯æ¢¦åç§°ï¼ˆå°å†™ï¼‰: [ç±»å‹1, ç±»å‹2, ...]}\n",
    "P_DEF_TYPE = {\n",
    "    \"starmie\": [\"psychic\", \"water\"],\n",
    "    \"exeggutor\": [\"grass\", \"psychic\"],\n",
    "    \"chansey\": [\"normal\"],\n",
    "    \"snorlax\": [\"normal\"],\n",
    "    \"tauros\": [\"normal\"],\n",
    "    \"alakazam\": [\"psychic\"],\n",
    "    \"jynx\": [\"ice\", \"psychic\"],\n",
    "    \"slowbro\": [\"psychic\", \"water\"],\n",
    "    \"gengar\": [\"ghost\", \"poison\"],\n",
    "    \"rhydon\": [\"ground\", \"rock\"],\n",
    "    \"zapdos\": [\"electric\", \"flying\"],\n",
    "    \"cloyster\": [\"ice\", \"water\"],\n",
    "    \"golem\": [\"ground\", \"rock\"],\n",
    "    \"jolteon\": [\"electric\"],\n",
    "    \"articuno\": [\"flying\", \"ice\"],\n",
    "    \"persian\": [\"normal\"],\n",
    "    \"lapras\": [\"ice\", \"water\"],\n",
    "    \"dragonite\": [\"dragon\", \"flying\"],\n",
    "    \"victreebel\": [\"grass\", \"poison\"],\n",
    "    \"charizard\": [\"fire\", \"flying\"]\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# æ—¥å¿—ç³»ç»Ÿï¼šå°†printè¾“å‡ºåŒæ—¶ä¿å­˜åˆ°æ–‡ä»¶\n",
    "# ============================================================================\n",
    "_log_file_handle = None\n",
    "_original_print = print\n",
    "\n",
    "def setup_logging(log_dir='print_log'):\n",
    "    \"\"\"\n",
    "    è®¾ç½®æ—¥å¿—ç³»ç»Ÿï¼Œå°†printè¾“å‡ºåŒæ—¶ä¿å­˜åˆ°æ–‡ä»¶\n",
    "    \n",
    "    å‚æ•°:\n",
    "    - log_dir: æ—¥å¿—æ–‡ä»¶ä¿å­˜ç›®å½•ï¼ˆé»˜è®¤'print_log'ï¼‰\n",
    "    \n",
    "    è¿”å›:\n",
    "    - æ—¥å¿—æ–‡ä»¶è·¯å¾„\n",
    "    \"\"\"\n",
    "    global _log_file_handle\n",
    "    \n",
    "    # åˆ›å»ºæ—¥å¿—ç›®å½•\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "    \n",
    "    # ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ—¥å¿—æ–‡ä»¶å\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    log_file_path = os.path.join(log_dir, f'print_log_{timestamp}.log')\n",
    "    \n",
    "    # æ‰“å¼€æ—¥å¿—æ–‡ä»¶ï¼ˆè¿½åŠ æ¨¡å¼ï¼ŒUTF-8ç¼–ç ï¼‰\n",
    "    _log_file_handle = open(log_file_path, 'w', encoding='utf-8')\n",
    "    \n",
    "    return log_file_path\n",
    "\n",
    "def log_print(*args, **kwargs):\n",
    "    \"\"\"\n",
    "    è‡ªå®šä¹‰printå‡½æ•°ï¼ŒåŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°å’Œæ—¥å¿—æ–‡ä»¶\n",
    "    \n",
    "    ç”¨æ³•ä¸æ ‡å‡†printå®Œå…¨ç›¸åŒ\n",
    "    æ”¯æŒæ‰€æœ‰printå‚æ•°ï¼šsep, end, file, flushç­‰\n",
    "    \"\"\"\n",
    "    global _log_file_handle, _original_print\n",
    "    \n",
    "    # è·å–å‚æ•°ï¼ˆå¦‚æœæŒ‡å®šäº†fileå‚æ•°ï¼Œåªè¾“å‡ºåˆ°æŒ‡å®šæ–‡ä»¶ï¼Œä¸è¾“å‡ºåˆ°æ—¥å¿—ï¼‰\n",
    "    file_param = kwargs.get('file', None)\n",
    "    \n",
    "    # è¾“å‡ºåˆ°æ§åˆ¶å°ï¼ˆæ ‡å‡†printï¼‰\n",
    "    _original_print(*args, **kwargs)\n",
    "    \n",
    "    # è¾“å‡ºåˆ°æ—¥å¿—æ–‡ä»¶ï¼ˆå¦‚æœfileå‚æ•°æœªæŒ‡å®šæˆ–ä¸ºNoneï¼Œä¸”æ—¥å¿—æ–‡ä»¶å·²æ‰“å¼€ï¼‰\n",
    "    if _log_file_handle is not None and file_param is None:\n",
    "        try:\n",
    "            # è·å–sepå’Œendå‚æ•°\n",
    "            sep = kwargs.get('sep', ' ')\n",
    "            end = kwargs.get('end', '\\n')\n",
    "            \n",
    "            # å°†å‚æ•°è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œä½¿ç”¨æŒ‡å®šçš„åˆ†éš”ç¬¦\n",
    "            message = sep.join(str(arg) for arg in args) + end\n",
    "            \n",
    "            _log_file_handle.write(message)\n",
    "            _log_file_handle.flush()  # ç«‹å³åˆ·æ–°åˆ°æ–‡ä»¶\n",
    "        except Exception as e:\n",
    "            # å¦‚æœå†™å…¥æ–‡ä»¶å¤±è´¥ï¼Œä¸å½±å“æ§åˆ¶å°è¾“å‡º\n",
    "            _original_print(f\"è­¦å‘Š: å†™å…¥æ—¥å¿—æ–‡ä»¶å¤±è´¥: {e}\", file=sys.stderr)\n",
    "\n",
    "def close_logging():\n",
    "    \"\"\"å…³é—­æ—¥å¿—æ–‡ä»¶\"\"\"\n",
    "    global _log_file_handle\n",
    "    if _log_file_handle is not None:\n",
    "        _log_file_handle.close()\n",
    "        _log_file_handle = None\n",
    "\n",
    "# æ›¿æ¢å…¨å±€printå‡½æ•°\n",
    "print = log_print\n",
    "\n",
    "class PokemonBattlePredictorEnhanced:\n",
    "    \"\"\"Pokemonæˆ˜æ–—é¢„æµ‹å™¨ä¸»ç±» - å¢å¼ºç‰ˆ\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.train_data = None\n",
    "        self.test_data = None\n",
    "        self.features = None\n",
    "        self.target = None\n",
    "        self.models = {}\n",
    "        self.feature_importance = {}\n",
    "        self.scaler = StandardScaler()\n",
    "        self.feature_selector = None\n",
    "        self.X_val = None\n",
    "        self.y_val = None\n",
    "        self.best_model = None\n",
    "        self.best_model_name = None\n",
    "        self.all_moves_list = None  # å­˜å‚¨æ‰€æœ‰æŠ€èƒ½åˆ—è¡¨\n",
    "        # self.turn30_winrates = None  # å­˜å‚¨ç¬¬30å›åˆå®å¯æ¢¦ç»„åˆèƒœç‡æ•°æ®\n",
    "\n",
    "        # ========================================================================\n",
    "        # ç‰¹å¾ç§»é™¤é…ç½®åˆ—è¡¨\n",
    "        # ========================================================================\n",
    "        # åœ¨æ­¤åˆ—è¡¨ä¸­æ·»åŠ è¦ç§»é™¤çš„ç‰¹å¾åç§°ï¼Œè¿™äº›ç‰¹å¾å°†åœ¨ç‰¹å¾åˆå¹¶åè¢«ç§»é™¤\n",
    "        # ç¤ºä¾‹ï¼š\n",
    "        # self.features_to_remove = ['p1_hp_min', 'p2_hp_min']\n",
    "        # self.features_to_remove = []  # ç©ºåˆ—è¡¨è¡¨ç¤ºä¸ç§»é™¤ä»»ä½•ç‰¹å¾\n",
    "        # ========================================================================\n",
    "        # self.features_to_remove = ['p1_switch_count','p2_switch_count','p1_hp_min','p2_hp_min', 'p2_move_null_switch','p1_move_null_switch']  # é»˜è®¤ä¸ç§»é™¤ä»»ä½•ç‰¹å¾ 'p1_unique_pokemon_count_30turns','p2_unique_pokemon_count_30turns',\n",
    "        self.features_to_remove = []\n",
    "\n",
    "        # ========================================================================\n",
    "        # éªŒè¯é›†åˆ†å‰²é…ç½®\n",
    "        # ========================================================================\n",
    "        self.validation_split = 0.1  # éªŒè¯é›†æ¯”ä¾‹ï¼ˆç”¨äºæ¨¡å‹éªŒè¯ï¼‰\n",
    "\n",
    "        # ========================================================================\n",
    "        # Optunaè¶…å‚æ•°è°ƒä¼˜é…ç½®å‚æ•°\n",
    "        # ========================================================================\n",
    "        # Optunaè‡ªåŠ¨æœç´¢æœ€ä¼˜è¶…å‚æ•°ï¼Œä½¿ç”¨MedianPruneræå‰ç»ˆæ­¢ä½æ•ˆè¯•éªŒ\n",
    "        # ========================================================================\n",
    "        self.use_optuna_tuning = False  # æ˜¯å¦å¯ç”¨Optunaè¶…å‚æ•°è°ƒä¼˜ï¼ˆé»˜è®¤ç¦ç”¨ï¼‰\n",
    "        self.optuna_n_trials = 50  # Optunaæœç´¢è¯•éªŒæ¬¡æ•°ï¼ˆæ¯ä¸ªæ¨¡å‹ç‹¬ç«‹æœç´¢ï¼‰\n",
    "        self.optuna_timeout = 3600  # å•ä¸ªæ¨¡å‹ä¼˜åŒ–è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼Œé»˜è®¤1å°æ—¶ï¼‰\n",
    "        self.optuna_cv_folds = 3  # äº¤å‰éªŒè¯æŠ˜æ•°ï¼ˆç”¨äºè¯„ä¼°è¶…å‚æ•°æ€§èƒ½ï¼‰\n",
    "        self.optuna_pruner_warmup = 5  # MedianPruneré¢„çƒ­æ­¥æ•°ï¼ˆå‰5ä¸ªtrialä¸å‰ªæï¼‰\n",
    "        self.optuna_pruner_interval = 1  # MedianPruneræ£€æŸ¥é—´éš”ï¼ˆæ¯ä¸ªfoldæ£€æŸ¥ä¸€æ¬¡ï¼‰\n",
    "\n",
    "        # Optunaç›¸å…³çŠ¶æ€å˜é‡\n",
    "        self.optuna_best_params = {}  # å­˜å‚¨å„æ¨¡å‹çš„æœ€ä¼˜å‚æ•°\n",
    "        self.optuna_studies = {}  # å­˜å‚¨Optuna studyå¯¹è±¡\n",
    "\n",
    "    # def get_all_moves_list(self, max_samples=10000):\n",
    "    #     \"\"\"\n",
    "    #     ä»è®­ç»ƒæ•°æ®ä¸­è·å–æ‰€æœ‰æŠ€èƒ½åˆ—è¡¨\n",
    "        \n",
    "    #     å‚æ•°:\n",
    "    #     - max_samples: æœ€å¤§é‡‡æ ·æ•°ï¼ˆç”¨äºå¿«é€Ÿè·å–æŠ€èƒ½åˆ—è¡¨ï¼‰\n",
    "    #     \"\"\"\n",
    "    #     if self.all_moves_list is not None:\n",
    "    #         return self.all_moves_list\n",
    "        \n",
    "    #     print(\"\\næ­£åœ¨æ”¶é›†æ‰€æœ‰æŠ€èƒ½åˆ—è¡¨...\")\n",
    "    #     all_moves = set()\n",
    "        \n",
    "    #     sample_size = min(max_samples, len(self.train_data))\n",
    "    #     for idx in range(sample_size):\n",
    "    #         row = self.train_data.iloc[idx]\n",
    "    #         timeline = row.get('battle_timeline', [])\n",
    "            \n",
    "    #         for turn in timeline:\n",
    "    #             p1_move = turn.get('p1_move_details')\n",
    "    #             p2_move = turn.get('p2_move_details')\n",
    "                \n",
    "    #             if p1_move and p1_move.get('name'):\n",
    "    #                 all_moves.add(p1_move.get('name'))\n",
    "                \n",
    "    #             if p2_move and p2_move.get('name'):\n",
    "    #                 all_moves.add(p2_move.get('name'))\n",
    "        \n",
    "    #     self.all_moves_list = sorted(list(all_moves))\n",
    "    #     print(f\"âœ“ æ‰¾åˆ° {len(self.all_moves_list)} ä¸ªå”¯ä¸€æŠ€èƒ½\")\n",
    "        \n",
    "    #     return self.all_moves_list\n",
    "\n",
    "    def load_data(self, train_path, test_path):\n",
    "        \"\"\"åŠ è½½è®­ç»ƒå’Œæµ‹è¯•æ•°æ®\"\"\"\n",
    "        print(\"æ­£åœ¨åŠ è½½æ•°æ®...\")\n",
    "\n",
    "        # åŠ è½½è®­ç»ƒæ•°æ®\n",
    "        train_records = []\n",
    "        with open(train_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                train_records.append(json.loads(line.strip()))\n",
    "\n",
    "        # åŠ è½½æµ‹è¯•æ•°æ®\n",
    "        test_records = []\n",
    "        with open(test_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                test_records.append(json.loads(line.strip()))\n",
    "\n",
    "        self.train_data = pd.DataFrame(train_records)\n",
    "        self.test_data = pd.DataFrame(test_records)\n",
    "\n",
    "        print(f\"è®­ç»ƒæ•°æ®åŠ è½½å®Œæˆ: {len(self.train_data)} æ¡è®°å½•\")\n",
    "        print(f\"æµ‹è¯•æ•°æ®åŠ è½½å®Œæˆ: {len(self.test_data)} æ¡è®°å½•\")\n",
    "\n",
    "        return self.train_data, self.test_data\n",
    "\n",
    "    # def load_turn30_winrates(self, winrate_path='pokemon_turn30_winrates.json'):\n",
    "    #     \"\"\"\n",
    "    #     åŠ è½½ç¬¬30å›åˆå®å¯æ¢¦ç»„åˆèƒœç‡æ•°æ®\n",
    "    #     \n",
    "    #     å‚æ•°:\n",
    "    #     - winrate_path: èƒœç‡æ•°æ®æ–‡ä»¶è·¯å¾„\n",
    "    #     \n",
    "    #     è¿”å›:\n",
    "    #     - winrate_dict: èƒœç‡å­—å…¸ï¼Œå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨åˆ™è¿”å›None\n",
    "    #     \"\"\"\n",
    "    #     if not os.path.exists(winrate_path):\n",
    "    #         print(f\"âš ï¸ èƒœç‡æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {winrate_path}\")\n",
    "    #         print(\"   æç¤º: è¯·å…ˆè¿è¡Œ extract_pokemon_turn30_data.py ç”Ÿæˆèƒœç‡æ•°æ®\")\n",
    "    #         return None\n",
    "    #     \n",
    "    #     try:\n",
    "    #         with open(winrate_path, 'r', encoding='utf-8') as f:\n",
    "    #             self.turn30_winrates = json.load(f)\n",
    "    #         print(f\"âœ“ å·²åŠ è½½ç¬¬30å›åˆç»„åˆèƒœç‡æ•°æ®: {len(self.turn30_winrates)} ä¸ªç»„åˆ\")\n",
    "    #         return self.turn30_winrates\n",
    "    #     except Exception as e:\n",
    "    #         print(f\"âš ï¸ åŠ è½½èƒœç‡æ•°æ®å¤±è´¥: {e}\")\n",
    "    #         return None\n",
    "\n",
    "    def get_complete_type_effectiveness(self):\n",
    "        \"\"\"å®Œæ•´çš„Pokemonç±»å‹å…‹åˆ¶å…³ç³»è¡¨(Gen 1-9)\"\"\"\n",
    "        effectiveness = {\n",
    "            'normal': {'rock': 0.5, 'ghost': 0.0, 'steel': 0.5},\n",
    "            'fire': {'fire': 0.5, 'water': 0.5, 'grass': 2.0, 'ice': 2.0, 'bug': 2.0, 'rock': 0.5, 'dragon': 0.5, 'steel': 2.0},\n",
    "            'water': {'fire': 2.0, 'water': 0.5, 'grass': 0.5, 'ground': 2.0, 'rock': 2.0, 'dragon': 0.5},\n",
    "            'electric': {'water': 2.0, 'electric': 0.5, 'grass': 0.5, 'ground': 0.0, 'flying': 2.0, 'dragon': 0.5},\n",
    "            'grass': {'fire': 0.5, 'water': 2.0, 'grass': 0.5, 'poison': 0.5, 'ground': 2.0, 'flying': 0.5, 'bug': 0.5, 'rock': 2.0, 'dragon': 0.5, 'steel': 0.5},\n",
    "            'ice': {'fire': 0.5, 'water': 0.5, 'grass': 2.0, 'ice': 0.5, 'ground': 2.0, 'flying': 2.0, 'dragon': 2.0, 'steel': 0.5},\n",
    "            'fighting': {'normal': 2.0, 'ice': 2.0, 'poison': 0.5, 'flying': 0.5, 'psychic': 0.5, 'bug': 0.5, 'rock': 2.0, 'ghost': 0.0, 'dark': 2.0, 'steel': 2.0, 'fairy': 0.5},\n",
    "            'poison': {'grass': 2.0, 'poison': 0.5, 'ground': 0.5, 'rock': 0.5, 'ghost': 0.5, 'steel': 0.0, 'fairy': 2.0},\n",
    "            'ground': {'fire': 2.0, 'electric': 2.0, 'grass': 0.5, 'poison': 2.0, 'flying': 0.0, 'bug': 0.5, 'rock': 2.0, 'steel': 2.0},\n",
    "            'flying': {'electric': 0.5, 'grass': 2.0, 'fighting': 2.0, 'bug': 2.0, 'rock': 0.5, 'steel': 0.5},\n",
    "            'psychic': {'fighting': 2.0, 'poison': 2.0, 'psychic': 0.5, 'dark': 0.0, 'steel': 0.5},\n",
    "            'bug': {'fire': 0.5, 'grass': 2.0, 'fighting': 0.5, 'poison': 0.5, 'flying': 0.5, 'psychic': 2.0, 'ghost': 0.5, 'dark': 2.0, 'steel': 0.5, 'fairy': 0.5},\n",
    "            'rock': {'fire': 2.0, 'ice': 2.0, 'fighting': 0.5, 'ground': 0.5, 'flying': 2.0, 'bug': 2.0, 'steel': 0.5},\n",
    "            'ghost': {'normal': 0.0, 'psychic': 2.0, 'ghost': 2.0, 'dark': 0.5},\n",
    "            'dragon': {'dragon': 2.0, 'steel': 0.5, 'fairy': 0.0},\n",
    "            'dark': {'fighting': 0.5, 'psychic': 2.0, 'ghost': 2.0, 'dark': 0.5, 'fairy': 0.5},\n",
    "            'steel': {'fire': 0.5, 'water': 0.5, 'electric': 0.5, 'ice': 2.0, 'rock': 2.0, 'steel': 0.5, 'fairy': 2.0},\n",
    "            'fairy': {'fire': 0.5, 'fighting': 2.0, 'poison': 0.5, 'dragon': 2.0, 'dark': 2.0, 'steel': 0.5}\n",
    "        }\n",
    "        return effectiveness\n",
    "\n",
    "    def calculate_team_type_advantage(self, p1_team, p2_lead):\n",
    "        \"\"\"\n",
    "        è®¡ç®—é˜Ÿä¼æ•´ä½“ç±»å‹ä¼˜åŠ¿\n",
    "        \n",
    "        åŠŸèƒ½ï¼š\n",
    "        è®¡ç®—P1é˜Ÿä¼ä¸­æ¯ä¸ªPokemonå¯¹P2é¦–å‘çš„ç±»å‹å…‹åˆ¶ä¼˜åŠ¿ï¼Œå¹¶è¿”å›ç»Ÿè®¡å€¼\n",
    "        \n",
    "        å‚æ•°ï¼š\n",
    "        - p1_team: P1é˜Ÿä¼åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªPokemonå­—å…¸\n",
    "        - p2_lead: P2é¦–å‘Pokemonå­—å…¸\n",
    "        \n",
    "        è¿”å›ï¼š\n",
    "        - type_adv_mean: é˜Ÿä¼å¹³å‡ç±»å‹ä¼˜åŠ¿ï¼ˆæ‰€æœ‰Pokemonç±»å‹ä¼˜åŠ¿çš„å‡å€¼ï¼‰\n",
    "        - type_adv_max: æœ€å¤§ç±»å‹ä¼˜åŠ¿ï¼ˆé˜Ÿä¼ä¸­æœ€å¼ºçš„ç±»å‹ä¼˜åŠ¿ï¼‰\n",
    "        - type_adv_min: æœ€å°ç±»å‹ä¼˜åŠ¿ï¼ˆé˜Ÿä¼ä¸­æœ€å¼±çš„ç±»å‹ä¼˜åŠ¿ï¼‰\n",
    "        - type_adv_std: ç±»å‹ä¼˜åŠ¿æ ‡å‡†å·®ï¼ˆåæ˜ é˜Ÿä¼ç±»å‹ä¼˜åŠ¿çš„ç¦»æ•£ç¨‹åº¦ï¼‰\n",
    "        \n",
    "        è®¡ç®—é€»è¾‘ï¼š\n",
    "        1. å¯¹äºP1é˜Ÿä¼ä¸­çš„æ¯ä¸ªPokemonï¼Œè®¡ç®—å…¶å¯¹P2é¦–å‘çš„ç±»å‹ä¼˜åŠ¿\n",
    "        2. ç±»å‹ä¼˜åŠ¿ = æ‰€æœ‰ç±»å‹å…‹åˆ¶å…³ç³»çš„ä¹˜ç§¯ï¼ˆä¾‹å¦‚ï¼šç«å¯¹è‰2.0 Ã— è‰å¯¹æ°´2.0 = 4.0ï¼‰\n",
    "        3. å¦‚æœPokemonæœ‰å¤šä¸ªç±»å‹ï¼Œæ¯ä¸ªç±»å‹å¯¹P2æ¯ä¸ªç±»å‹çš„å…‹åˆ¶å…³ç³»éƒ½ä¼šç›¸ä¹˜\n",
    "        4. æœ€ç»ˆè¿”å›æ‰€æœ‰Pokemonç±»å‹ä¼˜åŠ¿çš„ç»Ÿè®¡å€¼ï¼ˆå‡å€¼ã€æœ€å¤§å€¼ã€æœ€å°å€¼ã€æ ‡å‡†å·®ï¼‰\n",
    "        \n",
    "        ç¤ºä¾‹ï¼š\n",
    "        - P1æœ‰ç«ç³»Pokemonï¼ŒP2é¦–å‘æ˜¯è‰ç³» â†’ ä¼˜åŠ¿ = 2.0ï¼ˆç«å…‹åˆ¶è‰ï¼‰\n",
    "        - P1æœ‰ç«+é£è¡Œç³»Pokemonï¼ŒP2é¦–å‘æ˜¯è‰+è™«ç³» â†’ ä¼˜åŠ¿ = 2.0 Ã— 2.0 = 4.0ï¼ˆç«å…‹è‰2.0ï¼Œé£è¡Œå…‹è™«2.0ï¼‰\n",
    "        \"\"\"\n",
    "        # è·å–å®Œæ•´çš„ç±»å‹å…‹åˆ¶å…³ç³»è¡¨ï¼ˆGen 1-9ï¼‰\n",
    "        effectiveness = self.get_complete_type_effectiveness()\n",
    "\n",
    "        advantages = []\n",
    "        # è·å–P2é¦–å‘çš„æ‰€æœ‰ç±»å‹\n",
    "        p2_types = p2_lead.get('types', []) if p2_lead else []\n",
    "\n",
    "        # éå†P1é˜Ÿä¼ä¸­çš„æ¯ä¸ªPokemon\n",
    "        for pokemon in p1_team:\n",
    "            if not pokemon:\n",
    "                continue\n",
    "            # è·å–å½“å‰Pokemonçš„æ‰€æœ‰ç±»å‹\n",
    "            p1_types = pokemon.get('types', [])\n",
    "\n",
    "            # åˆå§‹åŒ–ç±»å‹ä¼˜åŠ¿ä¸º1.0ï¼ˆä¸­æ€§ï¼Œæ— å…‹åˆ¶ï¼‰\n",
    "            adv = 1.0\n",
    "            # éå†P1 Pokemonçš„æ¯ä¸ªç±»å‹\n",
    "            for p1_type in p1_types:\n",
    "                if p1_type.lower() in effectiveness:\n",
    "                    # éå†P2é¦–å‘çš„æ¯ä¸ªç±»å‹\n",
    "                    for p2_type in p2_types:\n",
    "                        # å¦‚æœP1ç±»å‹å¯¹P2ç±»å‹æœ‰å…‹åˆ¶å…³ç³»ï¼Œåˆ™ç›¸ä¹˜ç´¯ç§¯\n",
    "                        # ä¾‹å¦‚ï¼šç«å¯¹è‰ = 2.0ï¼Œç«å¯¹è™« = 2.0ï¼Œåˆ™ç«+é£è¡Œå¯¹è‰+è™« = 2.0 Ã— 2.0 = 4.0\n",
    "                        if p2_type.lower() in effectiveness[p1_type.lower()]:\n",
    "                            adv *= effectiveness[p1_type.lower()][p2_type.lower()]\n",
    "            # å°†å½“å‰Pokemonçš„ç±»å‹ä¼˜åŠ¿æ·»åŠ åˆ°åˆ—è¡¨\n",
    "            advantages.append(adv)\n",
    "\n",
    "        # å¦‚æœæ²¡æœ‰æœ‰æ•ˆçš„Pokemonï¼Œè¿”å›é»˜è®¤å€¼ï¼ˆä¸­æ€§ä¼˜åŠ¿ï¼‰\n",
    "        if not advantages:\n",
    "            return {'type_adv_mean': 1.0, 'type_adv_max': 1.0, 'type_adv_min': 1.0}\n",
    "\n",
    "        # è¿”å›ç±»å‹ä¼˜åŠ¿çš„ç»Ÿè®¡å€¼\n",
    "        return {\n",
    "            'type_adv_mean': np.mean(advantages),  # å¹³å‡ç±»å‹ä¼˜åŠ¿\n",
    "            'type_adv_max': max(advantages),       # æœ€å¤§ç±»å‹ä¼˜åŠ¿ï¼ˆé˜Ÿä¼ä¸­æœ€å¼ºçš„ï¼‰\n",
    "            'type_adv_min': min(advantages),       # æœ€å°ç±»å‹ä¼˜åŠ¿ï¼ˆé˜Ÿä¼ä¸­æœ€å¼±çš„ï¼‰\n",
    "            'type_adv_std': np.std(advantages) if len(advantages) > 1 else 0  # æ ‡å‡†å·®ï¼ˆè‡³å°‘2ä¸ªPokemonæ‰è®¡ç®—ï¼‰\n",
    "        }\n",
    "\n",
    "    def calculate_alive_teams_type_advantage(self, p1_alive_team, p2_alive_team):\n",
    "        \"\"\"\n",
    "        è®¡ç®—P1å­˜æ´»ç²¾çµå¯¹P2å­˜æ´»ç²¾çµçš„ç±»å‹ä¼˜åŠ¿\n",
    "        \n",
    "        åŠŸèƒ½ï¼š\n",
    "        è®¡ç®—P1å­˜æ´»ç²¾çµå¯¹P2å­˜æ´»ç²¾çµçš„æ•´ä½“ç±»å‹å…‹åˆ¶ä¼˜åŠ¿ï¼Œå¹¶è¿”å›ç»Ÿè®¡å€¼\n",
    "        \n",
    "        å‚æ•°ï¼š\n",
    "        - p1_alive_team: P1å­˜æ´»ç²¾çµåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªPokemonå­—å…¸\n",
    "        - p2_alive_team: P2å­˜æ´»ç²¾çµåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªPokemonå­—å…¸\n",
    "        \n",
    "        è¿”å›ï¼š\n",
    "        - type_adv_mean: P1å¯¹P2çš„å¹³å‡ç±»å‹ä¼˜åŠ¿ï¼ˆæ‰€æœ‰P2ç²¾çµç±»å‹ä¼˜åŠ¿çš„å‡å€¼ï¼‰\n",
    "        - type_adv_max: æœ€å¤§ç±»å‹ä¼˜åŠ¿ï¼ˆP1å¯¹æŸåªP2ç²¾çµçš„æœ€ä½³å…‹åˆ¶æƒ…å†µï¼‰\n",
    "        - type_adv_min: æœ€å°ç±»å‹ä¼˜åŠ¿ï¼ˆP1å¯¹æŸåªP2ç²¾çµçš„æœ€å·®å…‹åˆ¶æƒ…å†µï¼‰\n",
    "        - type_adv_std: ç±»å‹ä¼˜åŠ¿æ ‡å‡†å·®ï¼ˆåæ˜ P1å¯¹ä¸åŒP2ç²¾çµçš„ç±»å‹ä¼˜åŠ¿å·®å¼‚ï¼‰\n",
    "        \n",
    "        è®¡ç®—é€»è¾‘ï¼š\n",
    "        1. å¯¹äºæ¯ä¸ªP2å­˜æ´»ç²¾çµï¼Œè®¡ç®—P1å­˜æ´»ç²¾çµå¯¹å®ƒçš„ç±»å‹ä¼˜åŠ¿\n",
    "        2. ä½¿ç”¨ calculate_team_type_advantage è®¡ç®—P1é˜Ÿä¼å¯¹å•ä¸ªP2ç²¾çµçš„ä¼˜åŠ¿\n",
    "        3. æ”¶é›†æ‰€æœ‰P2ç²¾çµçš„ç±»å‹ä¼˜åŠ¿å€¼ï¼Œè®¡ç®—ç»Ÿè®¡å€¼\n",
    "        \n",
    "        ç¤ºä¾‹ï¼š\n",
    "        - P1æœ‰3åªå­˜æ´»ç²¾çµï¼ŒP2æœ‰2åªå­˜æ´»ç²¾çµ\n",
    "        - å¯¹P2ç¬¬1åªç²¾çµï¼šP1ä¼˜åŠ¿ = 2.0\n",
    "        - å¯¹P2ç¬¬2åªç²¾çµï¼šP1ä¼˜åŠ¿ = 0.5\n",
    "        - è¿”å›ï¼šmean=1.25, max=2.0, min=0.5, std=0.75\n",
    "        \"\"\"\n",
    "        if not p1_alive_team or not p2_alive_team:\n",
    "            # å¦‚æœæ²¡æœ‰å­˜æ´»ç²¾çµï¼Œè¿”å›é»˜è®¤å€¼ï¼ˆä¸­æ€§ä¼˜åŠ¿ï¼‰\n",
    "            return {\n",
    "                'type_adv_mean': 1.0,\n",
    "                'type_adv_max': 1.0,\n",
    "                'type_adv_min': 1.0,\n",
    "                'type_adv_std': 0.0\n",
    "            }\n",
    "        \n",
    "        # å¯¹äºæ¯ä¸ªP2å­˜æ´»ç²¾çµï¼Œè®¡ç®—P1å­˜æ´»ç²¾çµå¯¹å®ƒçš„ç±»å‹ä¼˜åŠ¿\n",
    "        all_advantages = []\n",
    "        for p2_pokemon in p2_alive_team:\n",
    "            # è®¡ç®—P1å­˜æ´»ç²¾çµå¯¹å½“å‰P2å­˜æ´»ç²¾çµçš„ç±»å‹ä¼˜åŠ¿\n",
    "            type_adv = self.calculate_team_type_advantage(p1_alive_team, p2_pokemon)\n",
    "            # ä½¿ç”¨å‡å€¼ä½œä¸ºè¯¥P2ç²¾çµçš„ç±»å‹ä¼˜åŠ¿\n",
    "            all_advantages.append(type_adv.get('type_adv_mean', 1.0))\n",
    "        \n",
    "        # è®¡ç®—æ‰€æœ‰P2å­˜æ´»ç²¾çµçš„ç±»å‹ä¼˜åŠ¿ç»Ÿè®¡å€¼\n",
    "        if all_advantages:\n",
    "            return {\n",
    "                'type_adv_mean': np.mean(all_advantages),  # å¹³å‡ç±»å‹ä¼˜åŠ¿\n",
    "                'type_adv_max': np.max(all_advantages),    # æœ€å¤§ç±»å‹ä¼˜åŠ¿\n",
    "                'type_adv_min': np.min(all_advantages),    # æœ€å°ç±»å‹ä¼˜åŠ¿\n",
    "                'type_adv_std': np.std(all_advantages) if len(all_advantages) > 1 else 0.0  # æ ‡å‡†å·®\n",
    "            }\n",
    "        else:\n",
    "            # å¦‚æœæ²¡æœ‰æœ‰æ•ˆçš„ä¼˜åŠ¿å€¼ï¼Œè¿”å›é»˜è®¤å€¼\n",
    "            return {\n",
    "                'type_adv_mean': 1.0,\n",
    "                'type_adv_max': 1.0,\n",
    "                'type_adv_min': 1.0,\n",
    "                'type_adv_std': 0.0\n",
    "            }\n",
    "\n",
    "    def calculate_team_diversity(self, team):\n",
    "        \"\"\"\n",
    "        è®¡ç®—é˜Ÿä¼å¤šæ ·æ€§\n",
    "        \n",
    "        å‚æ•°:\n",
    "        - team: Pokemonå¯¹è±¡åˆ—è¡¨ï¼Œæ¯ä¸ªå¯¹è±¡åŒ…å«typeså’Œbaseå±æ€§\n",
    "        \n",
    "        è¿”å›:\n",
    "        - dict: åŒ…å«ä¸¤ä¸ªå¤šæ ·æ€§æŒ‡æ ‡çš„å­—å…¸\n",
    "            - type_diversity: ç±»å‹å¤šæ ·æ€§ï¼ˆ0-1ä¹‹é—´ï¼Œå€¼è¶Šå¤§è¡¨ç¤ºç±»å‹è¶Šå¤šæ ·ï¼‰\n",
    "            - stat_diversity: å±æ€§å¤šæ ·æ€§ï¼ˆå˜å¼‚ç³»æ•°çš„å¹³å‡å€¼ï¼Œå€¼è¶Šå¤§è¡¨ç¤ºå±æ€§åˆ†å¸ƒè¶Šåˆ†æ•£ï¼‰\n",
    "        \n",
    "        è®¡ç®—é€»è¾‘:\n",
    "        1. ç±»å‹å¤šæ ·æ€§ï¼š\n",
    "           - æ”¶é›†é˜Ÿä¼ä¸­æ‰€æœ‰Pokemonçš„ç±»å‹ï¼ˆåŒ…æ‹¬åŒç±»å‹ï¼‰\n",
    "           - è®¡ç®—å”¯ä¸€ç±»å‹æ•° / æ€»ç±»å‹æ•°\n",
    "           - ä¾‹å¦‚ï¼š6åªPokemonï¼Œå…±12ä¸ªç±»å‹ï¼Œä½†åªæœ‰8ç§å”¯ä¸€ç±»å‹ â†’ 8/12 = 0.67\n",
    "           - å€¼è¶Šæ¥è¿‘1.0è¡¨ç¤ºç±»å‹è¶Šå¤šæ ·ï¼Œè¶Šæ¥è¿‘0è¡¨ç¤ºç±»å‹é‡å¤è¶Šå¤š\n",
    "        \n",
    "        2. å±æ€§å¤šæ ·æ€§ï¼š\n",
    "           - æ”¶é›†æ‰€æœ‰Pokemonçš„6ä¸ªåŸºç¡€å±æ€§ï¼ˆhp, atk, def, spa, spd, speï¼‰\n",
    "           - å¯¹æ¯ä¸ªå±æ€§è®¡ç®—å˜å¼‚ç³»æ•°ï¼ˆCV = std / meanï¼‰\n",
    "           - å˜å¼‚ç³»æ•°åæ˜ è¯¥å±æ€§åœ¨é˜Ÿä¼ä¸­çš„åˆ†æ•£ç¨‹åº¦\n",
    "           - å°†6ä¸ªå±æ€§çš„å˜å¼‚ç³»æ•°æ±‚å¹³å‡ï¼Œå¾—åˆ°æ•´ä½“å±æ€§å¤šæ ·æ€§\n",
    "           - å€¼è¶Šå¤§è¡¨ç¤ºé˜Ÿä¼å±æ€§åˆ†å¸ƒè¶Šä¸å‡åŒ€ï¼ˆæœ‰é«˜æœ‰ä½ï¼‰ï¼Œå€¼è¶Šå°è¡¨ç¤ºå±æ€§åˆ†å¸ƒè¶Šå‡åŒ€\n",
    "        \"\"\"\n",
    "        if not team:\n",
    "            return {'type_diversity': 0, 'stat_diversity': 0}\n",
    "\n",
    "        # ç±»å‹å¤šæ ·æ€§ï¼šæ”¶é›†æ‰€æœ‰ç±»å‹ï¼Œè®¡ç®—å”¯ä¸€ç±»å‹å æ¯”\n",
    "        all_types = []\n",
    "        for pokemon in team:\n",
    "            if pokemon and 'types' in pokemon:\n",
    "                all_types.extend(pokemon['types'])  # æ‰©å±•ç±»å‹åˆ—è¡¨ï¼ˆåŒç±»å‹Pokemonä¼šæœ‰2ä¸ªç±»å‹ï¼‰\n",
    "        # å”¯ä¸€ç±»å‹æ•° / æ€»ç±»å‹æ•°ï¼ˆåŒ…æ‹¬é‡å¤ï¼‰\n",
    "        # ä¾‹å¦‚ï¼š[fire, fire, water, grass, fire, water] â†’ å”¯ä¸€ç±»å‹3ç§ï¼Œæ€»æ•°6 â†’ 3/6 = 0.5\n",
    "        type_diversity = len(set(all_types)) / max(len(all_types), 1)\n",
    "\n",
    "        # å±æ€§å¤šæ ·æ€§ï¼šä½¿ç”¨å˜å¼‚ç³»æ•°ï¼ˆCoefficient of Variation, CVï¼‰è¡¡é‡\n",
    "        # æ”¶é›†æ‰€æœ‰Pokemonçš„6ä¸ªåŸºç¡€å±æ€§\n",
    "        stats_matrix = []\n",
    "        for pokemon in team:\n",
    "            if pokemon:\n",
    "                stats = [\n",
    "                    pokemon.get('base_hp', 0),\n",
    "                    pokemon.get('base_atk', 0),\n",
    "                    pokemon.get('base_def', 0),\n",
    "                    pokemon.get('base_spa', 0),\n",
    "                    pokemon.get('base_spd', 0),\n",
    "                    pokemon.get('base_spe', 0)\n",
    "                ]\n",
    "                stats_matrix.append(stats)\n",
    "\n",
    "        stat_diversity = 0\n",
    "        if stats_matrix:\n",
    "            stats_matrix = np.array(stats_matrix)\n",
    "            # å¯¹æ¯ä¸ªå±æ€§ï¼ˆåˆ—ï¼‰è®¡ç®—å˜å¼‚ç³»æ•°ï¼šCV = std / mean\n",
    "            # å˜å¼‚ç³»æ•°åæ˜ è¯¥å±æ€§åœ¨é˜Ÿä¼ä¸­çš„ç›¸å¯¹åˆ†æ•£ç¨‹åº¦\n",
    "            for i in range(6):\n",
    "                col = stats_matrix[:, i]  # ç¬¬iä¸ªå±æ€§çš„æ‰€æœ‰Pokemonçš„å€¼\n",
    "                if np.mean(col) > 0:\n",
    "                    # CV = æ ‡å‡†å·® / å¹³å‡å€¼ï¼Œå€¼è¶Šå¤§è¡¨ç¤ºè¯¥å±æ€§åœ¨é˜Ÿä¼ä¸­å·®å¼‚è¶Šå¤§\n",
    "                    stat_diversity += np.std(col) / np.mean(col)\n",
    "            # å°†6ä¸ªå±æ€§çš„å˜å¼‚ç³»æ•°æ±‚å¹³å‡ï¼Œå¾—åˆ°æ•´ä½“å±æ€§å¤šæ ·æ€§\n",
    "            stat_diversity /= 6\n",
    "\n",
    "        return {'type_diversity': type_diversity, 'stat_diversity': stat_diversity}\n",
    "\n",
    "    def extract_static_features(self):\n",
    "        \"\"\"\n",
    "        æå–é™æ€ç‰¹å¾ï¼ˆé˜Ÿä¼å’ŒPokemonå±æ€§ï¼‰- å¢å¼ºç‰ˆ\n",
    "        \n",
    "        å…±60ä¸ªç‰¹å¾ï¼š\n",
    "        - P1é˜Ÿä¼å±æ€§èšåˆ: 30ä¸ª (6å±æ€§ Ã— 5èšåˆæ–¹å¼)\n",
    "        - P2é¦–å‘å±æ€§: 6ä¸ª\n",
    "        - å±æ€§å¯¹æ¯”: 12ä¸ª (6ä¸ªadvantage + 6ä¸ªratio)\n",
    "        - ç±»å‹ä¼˜åŠ¿: 4ä¸ª (mean, max, min, std)\n",
    "        - é˜Ÿä¼å¤šæ ·æ€§: 2ä¸ª (type_diversity, stat_diversity)\n",
    "        - é˜Ÿä¼å¹³è¡¡æ€§: 3ä¸ª (ç‰©æ”»/ç‰¹æ”»æ¯”, ç‰©é˜²/ç‰¹é˜²æ¯”, æ”»é˜²æ¯”)\n",
    "        - æ€»ä½“å®åŠ›: 3ä¸ª (p1_total, p2_total, advantage)\n",
    "        \"\"\"\n",
    "        print(\"\\n=== æå–é™æ€ç‰¹å¾(å¢å¼ºç‰ˆ) ===\")\n",
    "        \n",
    "        # åŠ è½½å®å¯æ¢¦å±æ€§æ•°æ®åº“ï¼ˆç”¨äºæŸ¥æ‰¾ç²¾çµå±æ€§ï¼‰\n",
    "        pokemon_db = {}\n",
    "        try:\n",
    "            if os.path.exists('pokemon_stats_20.json'):\n",
    "                with open('pokemon_stats_20.json', 'r', encoding='utf-8') as f:\n",
    "                    pokemon_list = json.load(f)\n",
    "                    for pokemon in pokemon_list:\n",
    "                        pokemon_name = pokemon.get('name', '').lower()\n",
    "                        if pokemon_name:\n",
    "                            pokemon_db[pokemon_name] = pokemon\n",
    "                print(f\"âœ“ å·²åŠ è½½ {len(pokemon_db)} ç§å®å¯æ¢¦å±æ€§æ•°æ®\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ åŠ è½½å®å¯æ¢¦å±æ€§æ•°æ®åº“å¤±è´¥: {e}\")\n",
    "            pokemon_db = {}\n",
    "\n",
    "        def extract_pokemon_stats(pokemon):\n",
    "            \"\"\"æå–å•ä¸ªPokemonçš„å±æ€§\"\"\"\n",
    "            if not pokemon:\n",
    "                return [0] * 6\n",
    "\n",
    "            return [\n",
    "                pokemon.get('base_hp', 0),\n",
    "                pokemon.get('base_atk', 0),\n",
    "                pokemon.get('base_def', 0),\n",
    "                pokemon.get('base_spa', 0),\n",
    "                pokemon.get('base_spd', 0),\n",
    "                pokemon.get('base_spe', 0)\n",
    "            ]\n",
    "\n",
    "        def calculate_team_stats(alive_pokemon_names=None):\n",
    "            \"\"\"\n",
    "            è®¡ç®—é˜Ÿä¼æ•´ä½“å±æ€§\n",
    "            \n",
    "            å‚æ•°:\n",
    "            - alive_pokemon_names: å­˜æ´»çš„ç²¾çµåç§°é›†åˆ\n",
    "            \n",
    "            æ³¨æ„ï¼šå‡½æ•°é€šè¿‡é—­åŒ…è®¿é—®pokemon_dbï¼Œä»æ•°æ®åº“ä¸­æŸ¥æ‰¾Pokemonå¯¹è±¡\n",
    "            \"\"\"\n",
    "            if not alive_pokemon_names:\n",
    "                return {'sum': [0]*6, 'mean': [0]*6, 'max': [0]*6, 'min': [0]*6, 'std': [0]*6}\n",
    "\n",
    "            stats_matrix = []\n",
    "            for pokemon_name in alive_pokemon_names:\n",
    "                # ä»pokemon_dbä¸­æŸ¥æ‰¾è¯¥ç²¾çµçš„å±æ€§\n",
    "                pokemon_name_lower = pokemon_name.lower()\n",
    "                if pokemon_name_lower in pokemon_db:\n",
    "                    pokemon = pokemon_db[pokemon_name_lower]\n",
    "                    stats = extract_pokemon_stats(pokemon)\n",
    "                    stats_matrix.append(stats)\n",
    "                # å¦‚æœæ•°æ®åº“ä¸­æ‰¾ä¸åˆ°ï¼Œè·³è¿‡è¯¥ç²¾çµï¼ˆå±æ€§ä¸º0ï¼‰\n",
    "\n",
    "            # å¦‚æœæ²¡æœ‰æœ‰æ•ˆçš„pokemonï¼Œè¿”å›0å€¼\n",
    "            if not stats_matrix:\n",
    "                return {'sum': [0]*6, 'mean': [0]*6, 'max': [0]*6, 'min': [0]*6, 'std': [0]*6}\n",
    "\n",
    "            stats_matrix = np.array(stats_matrix)\n",
    "\n",
    "            return {\n",
    "                'sum': np.sum(stats_matrix, axis=0).tolist(),\n",
    "                'mean': np.mean(stats_matrix, axis=0).tolist(),\n",
    "                'max': np.max(stats_matrix, axis=0).tolist(),\n",
    "                'min': np.min(stats_matrix, axis=0).tolist(),\n",
    "                'std': np.std(stats_matrix, axis=0).tolist()\n",
    "            }\n",
    "\n",
    "        def extract_single_static_features(row):\n",
    "            \"\"\"\n",
    "            æå–å•ä¸ªæ ·æœ¬çš„é™æ€ç‰¹å¾ï¼ˆç»Ÿä¸€å‡½æ•°ï¼Œç”¨äºè®­ç»ƒå’Œæµ‹è¯•æ•°æ®ï¼‰\n",
    "            \n",
    "            å‚æ•°:\n",
    "            - row: å•ä¸ªæ ·æœ¬çš„DataFrameè¡Œ\n",
    "            \n",
    "            è¿”å›:\n",
    "            - features: åŒ…å«æ‰€æœ‰é™æ€ç‰¹å¾çš„å­—å…¸\n",
    "            \"\"\"\n",
    "            features = {}\n",
    "\n",
    "            # ä»p1_team_detailsä¸­è·å–æ‰€æœ‰P1ç²¾çµåç§°ï¼ˆåˆå§‹ä¸ºå…¨éƒ¨å­˜æ´»ï¼‰\n",
    "            p1_team = row.get('p1_team_details', [])\n",
    "            \n",
    "            \n",
    "            timeline = row.get('battle_timeline', [])\n",
    "            (\n",
    "                p1_alive_pokemon_names,\n",
    "                p1_fnt_pokemon_names,\n",
    "                p2_alive_pokemon_names,\n",
    "            ) = extract_final_pokemon_status(timeline)\n",
    "            \n",
    "            \n",
    "            \n",
    "            # ä»p1_teamä¸­æå–æœªæ­»äº¡çš„ç²¾çµåç§°ï¼Œç„¶åä¸p1_alive_pokemon_namesåˆå¹¶\n",
    "            # è¿™æ ·æ—¢åŒ…å«æœªå‡ºåœºçš„å­˜æ´»ç²¾çµï¼Œä¹ŸåŒ…å«æ—¶é—´çº¿ä¸­å‡ºç°çš„å­˜æ´»ç²¾çµ\n",
    "            p1_team_names = {pokemon.get('name', '') for pokemon in p1_team \n",
    "                           if pokemon and pokemon.get('name', '') not in p1_fnt_pokemon_names}\n",
    "            p1_alive_pokemon_names = p1_team_names | p1_alive_pokemon_names\n",
    "\n",
    "            # Player 1 é˜Ÿä¼ç‰¹å¾ï¼ˆåªè®¡ç®—å­˜æ´»çš„ç²¾çµï¼‰\n",
    "            # ä½¿ç”¨å®Œæ•´çš„p1_teamå’Œåˆå¹¶åçš„p1_alive_pokemon_namesï¼ˆåŒ…å«æ‰€æœ‰å­˜æ´»çš„ç²¾çµï¼ŒåŒ…æ‹¬æœªå‡ºåœºçš„ï¼‰\n",
    "            p1_team_stats = calculate_team_stats(alive_pokemon_names=p1_alive_pokemon_names)\n",
    "\n",
    "            # Player 2 é˜Ÿä¼ç‰¹å¾ï¼ˆåªè®¡ç®—å­˜æ´»çš„ç²¾çµï¼‰\n",
    "            # p2_team = row.get('p2_team_details', []) # æ²¡æœ‰p2_team_detailsè¿™ä¸ªé”®\n",
    "            p2_team_stats = calculate_team_stats(alive_pokemon_names=p2_alive_pokemon_names)\n",
    "\n",
    "            # P1é˜Ÿä¼å±æ€§èšåˆç‰¹å¾ï¼ˆ30ä¸ªç‰¹å¾ï¼š6ä¸ªå±æ€§ Ã— 5ç§èšåˆæ–¹å¼ï¼‰\n",
    "            # ç”Ÿæˆç‰¹å¾ï¼šp1_team_hp_sum, p1_team_hp_mean, p1_team_hp_max, p1_team_hp_min, p1_team_hp_std ç­‰\n",
    "            # for agg_type in ['sum', 'mean', 'max', 'min', 'std']:\n",
    "            #     for i, stat_name in enumerate(['hp', 'atk', 'def', 'spa', 'spd', 'spe']):\n",
    "            #         features[f'p1_team_{stat_name}_{agg_type}'] = p1_team_stats[agg_type][i]\n",
    "\n",
    "            # P2é¦–å‘PokemonåŸºç¡€å±æ€§ç‰¹å¾ï¼ˆ6ä¸ªç‰¹å¾ï¼‰\n",
    "            # ç”Ÿæˆç‰¹å¾ï¼šp2_lead_hp, p2_lead_atk, p2_lead_def, p2_lead_spa, p2_lead_spd, p2_lead_spe\n",
    "            # for i, stat_name in enumerate(['hp', 'atk', 'def', 'spa', 'spd', 'spe']):\n",
    "            #     features[f'p2_lead_{stat_name}'] = p2_stats[i]\n",
    "\n",
    "            # å±æ€§å¯¹æ¯”ç‰¹å¾ï¼ˆ12ä¸ªç‰¹å¾ï¼š6ä¸ªadvantage + 6ä¸ªratioï¼‰\n",
    "            # advantage: P1é˜Ÿä¼å¹³å‡å±æ€§å€¼ - P2é˜Ÿä¼å¹³å‡å±æ€§å€¼ï¼ˆå·®å€¼ç‰¹å¾ï¼‰\n",
    "            # ratio: P1é˜Ÿä¼å¹³å‡å±æ€§å€¼ / (P2é˜Ÿä¼å¹³å‡å±æ€§å€¼ + 1)ï¼ˆæ¯”å€¼ç‰¹å¾ï¼Œ+1é¿å…é™¤ä»¥0ï¼‰\n",
    "            for i, stat_name in enumerate(['hp', 'atk', 'def', 'spa', 'spd', 'spe']):\n",
    "                features[f'{stat_name}_advantage'] = p1_team_stats['mean'][i] - p2_team_stats['mean'][i]\n",
    "                features[f'{stat_name}_ratio'] = p1_team_stats['mean'][i] / (p2_team_stats['mean'][i] + 1)\n",
    "\n",
    "            # ç±»å‹ä¼˜åŠ¿ç‰¹å¾(å¢å¼ºç‰ˆ)\n",
    "            # ä½¿ç”¨P1å­˜æ´»ç²¾çµå’ŒP2å­˜æ´»ç²¾çµè®¡ç®—ç±»å‹ä¼˜åŠ¿\n",
    "            # ä»pokemon_dbä¸­æŸ¥æ‰¾P1å­˜æ´»çš„ç²¾çµå¯¹è±¡\n",
    "            p1_alive_team = []\n",
    "            for pokemon_name in p1_alive_pokemon_names:\n",
    "                pokemon_name_lower = pokemon_name.lower()\n",
    "                if pokemon_name_lower in pokemon_db:\n",
    "                    p1_alive_team.append(pokemon_db[pokemon_name_lower])\n",
    "            \n",
    "            # ä»pokemon_dbä¸­æŸ¥æ‰¾P2å­˜æ´»çš„ç²¾çµå¯¹è±¡\n",
    "            p2_alive_team = []\n",
    "            for pokemon_name in p2_alive_pokemon_names:\n",
    "                pokemon_name_lower = pokemon_name.lower()\n",
    "                if pokemon_name_lower in pokemon_db:\n",
    "                    p2_alive_team.append(pokemon_db[pokemon_name_lower])\n",
    "            \n",
    "            # ä½¿ç”¨æ–°å‡½æ•°è®¡ç®—P1å­˜æ´»ç²¾çµå¯¹P2å­˜æ´»ç²¾çµçš„ç±»å‹ä¼˜åŠ¿\n",
    "            type_adv = self.calculate_alive_teams_type_advantage(p1_alive_team, p2_alive_team)\n",
    "            \n",
    "            # ç±»å‹ä¼˜åŠ¿ç‰¹å¾è¯´æ˜ï¼š\n",
    "            # è¿™äº›ç‰¹å¾åæ˜ P1å­˜æ´»ç²¾çµå¯¹P2å­˜æ´»ç²¾çµçš„æ•´ä½“ç±»å‹å…‹åˆ¶å…³ç³»\n",
    "            # type_adv_mean: P1å­˜æ´»ç²¾çµå¯¹P2å­˜æ´»ç²¾çµçš„å¹³å‡ç±»å‹ä¼˜åŠ¿\n",
    "            #   å€¼è¶Šå¤§è¡¨ç¤ºP1æ•´ä½“ç±»å‹ä¼˜åŠ¿è¶Šå¼ºï¼Œ>1.0è¡¨ç¤ºP1å ä¼˜ï¼Œ<1.0è¡¨ç¤ºP2å ä¼˜\n",
    "            #   ä¾‹å¦‚ï¼šå¦‚æœP1å¯¹P2çš„3åªç²¾çµä¼˜åŠ¿åˆ†åˆ«ä¸º[2.0, 1.5, 0.5]ï¼Œåˆ™mean = 1.33ï¼ˆP1ç•¥å ä¼˜ï¼‰\n",
    "            features['type_adv_mean'] = type_adv['type_adv_mean']\n",
    "            \n",
    "            # type_adv_max: P1å­˜æ´»ç²¾çµå¯¹P2å­˜æ´»ç²¾çµçš„æœ€å¤§ç±»å‹ä¼˜åŠ¿\n",
    "            #   åæ˜ P1å¯¹P2æŸåªç²¾çµçš„æœ€ä½³å…‹åˆ¶æƒ…å†µï¼Œå€¼è¶Šå¤§è¡¨ç¤ºå­˜åœ¨æ˜æ˜¾çš„ç±»å‹å…‹åˆ¶\n",
    "            #   ä¾‹å¦‚ï¼š[2.0, 1.5, 0.5] â†’ max = 2.0ï¼ˆP1å¯¹æŸåªP2ç²¾çµæœ‰2å€ä¼˜åŠ¿ï¼‰\n",
    "            features['type_adv_max'] = type_adv['type_adv_max']\n",
    "            \n",
    "            # type_adv_min: P1å­˜æ´»ç²¾çµå¯¹P2å­˜æ´»ç²¾çµçš„æœ€å°ç±»å‹ä¼˜åŠ¿\n",
    "            #   åæ˜ P1å¯¹P2æŸåªç²¾çµçš„æœ€å·®å…‹åˆ¶æƒ…å†µï¼Œå€¼è¶Šå°è¡¨ç¤ºå­˜åœ¨æ˜æ˜¾çš„è¢«å…‹åˆ¶\n",
    "            #   ä¾‹å¦‚ï¼š[2.0, 1.5, 0.5] â†’ min = 0.5ï¼ˆP1å¯¹æŸåªP2ç²¾çµè¢«å…‹åˆ¶ï¼Œåªæœ‰0.5å€ï¼‰\n",
    "            features['type_adv_min'] = type_adv['type_adv_min']\n",
    "            \n",
    "            # type_adv_std: P1å­˜æ´»ç²¾çµå¯¹P2å­˜æ´»ç²¾çµçš„ç±»å‹ä¼˜åŠ¿æ ‡å‡†å·®\n",
    "            #   åæ˜ ç±»å‹ä¼˜åŠ¿çš„ç¦»æ•£ç¨‹åº¦ï¼Œå€¼è¶Šå¤§è¡¨ç¤ºP1å¯¹ä¸åŒP2ç²¾çµçš„ç±»å‹ä¼˜åŠ¿å·®å¼‚è¾ƒå¤§\n",
    "            #   ä¾‹å¦‚ï¼š[2.0, 1.5, 0.5] â†’ stdè¾ƒå¤§ï¼Œè¯´æ˜ä¼˜åŠ¿åˆ†å¸ƒä¸å‡åŒ€\n",
    "            #   ä¾‹å¦‚ï¼š[1.2, 1.1, 1.0] â†’ stdè¾ƒå°ï¼Œè¯´æ˜ä¼˜åŠ¿åˆ†å¸ƒè¾ƒå‡åŒ€\n",
    "            features['type_adv_std'] = type_adv['type_adv_std']\n",
    "\n",
    "            # é˜Ÿä¼å¤šæ ·æ€§\n",
    "            # ä»pokemon_dbä¸­æŸ¥æ‰¾P1å­˜æ´»çš„ç²¾çµå¯¹è±¡\n",
    "            p1_team_for_diversity = []\n",
    "            for pokemon_name in p1_alive_pokemon_names:\n",
    "                pokemon_name_lower = pokemon_name.lower()\n",
    "                if pokemon_name_lower in pokemon_db:\n",
    "                    p1_team_for_diversity.append(pokemon_db[pokemon_name_lower])\n",
    "            p1_diversity = self.calculate_team_diversity(p1_team_for_diversity)\n",
    "            features.update(p1_diversity)  # ä¿æŒåŸæœ‰ç‰¹å¾åï¼štype_diversity, stat_diversity\n",
    "            \n",
    "            # ä»pokemon_dbä¸­æŸ¥æ‰¾P2å­˜æ´»çš„ç²¾çµå¯¹è±¡\n",
    "            p2_team_for_diversity = []\n",
    "            for pokemon_name in p2_alive_pokemon_names:\n",
    "                pokemon_name_lower = pokemon_name.lower()\n",
    "                if pokemon_name_lower in pokemon_db:\n",
    "                    p2_team_for_diversity.append(pokemon_db[pokemon_name_lower])\n",
    "            p2_diversity = self.calculate_team_diversity(p2_team_for_diversity)\n",
    "            features.update({f'p2_{k}': v for k, v in p2_diversity.items()})  # p2_type_diversity, p2_stat_diversity\n",
    "            \n",
    "            # P1å’ŒP2å¤šæ ·æ€§æ¯”å€¼\n",
    "            p1_type_div = p1_diversity.get('type_diversity', 0)\n",
    "            p2_type_div = p2_diversity.get('type_diversity', 0)\n",
    "            p1_stat_div = p1_diversity.get('stat_diversity', 0)\n",
    "            p2_stat_div = p2_diversity.get('stat_diversity', 0)\n",
    "            \n",
    "            # æ¯”å€¼ï¼šP1 / P2ï¼ˆ+1e-6é¿å…é™¤ä»¥0ï¼‰\n",
    "            features['type_diversity_ratio'] = p1_type_div / (p2_type_div + 1e-6)\n",
    "            features['stat_diversity_ratio'] = p1_stat_div / (p2_stat_div + 1e-6)\n",
    "\n",
    "            # é˜Ÿä¼å¹³è¡¡æ€§ç‰¹å¾\n",
    "            # P1 é˜Ÿä¼å¹³è¡¡æ€§\n",
    "            p1_physical_atk = p1_team_stats['mean'][1]\n",
    "            p1_special_atk = p1_team_stats['mean'][3]\n",
    "            p1_physical_def = p1_team_stats['mean'][2]\n",
    "            p1_special_def = p1_team_stats['mean'][4]\n",
    "\n",
    "            features['physical_special_atk_ratio'] = p1_physical_atk / (p1_special_atk + 1)\n",
    "            features['physical_special_def_ratio'] = p1_physical_def / (p1_special_def + 1)\n",
    "            features['offense_defense_ratio'] = (p1_physical_atk + p1_special_atk) / (p1_physical_def + p1_special_def + 1)\n",
    "            \n",
    "            # P2 é˜Ÿä¼å¹³è¡¡æ€§\n",
    "            p2_physical_atk = p2_team_stats['mean'][1]\n",
    "            p2_special_atk = p2_team_stats['mean'][3]\n",
    "            p2_physical_def = p2_team_stats['mean'][2]\n",
    "            p2_special_def = p2_team_stats['mean'][4]\n",
    "\n",
    "            features['p2_physical_special_atk_ratio'] = p2_physical_atk / (p2_special_atk + 1)\n",
    "            features['p2_physical_special_def_ratio'] = p2_physical_def / (p2_special_def + 1)\n",
    "            features['p2_offense_defense_ratio'] = (p2_physical_atk + p2_special_atk) / (p2_physical_def + p2_special_def + 1)\n",
    "            \n",
    "            # P1 å’Œ P2 å¹³è¡¡æ€§æ¯”å€¼\n",
    "            features['physical_special_atk_ratio_p1_p2'] = features['physical_special_atk_ratio'] / (features['p2_physical_special_atk_ratio'] + 1e-6)\n",
    "            features['physical_special_def_ratio_p1_p2'] = features['physical_special_def_ratio'] / (features['p2_physical_special_def_ratio'] + 1e-6)\n",
    "            features['offense_defense_ratio_p1_p2'] = features['offense_defense_ratio'] / (features['p2_offense_defense_ratio'] + 1e-6)\n",
    "\n",
    "            # æ€»ä½“å®åŠ›æŒ‡æ ‡\n",
    "            # ä½¿ç”¨å¹³å‡å€¼è¿›è¡Œæ¯”è¾ƒï¼Œå› ä¸ºP1å’ŒP2å­˜æ´»æ•°é‡å¯èƒ½ä¸åŒ\n",
    "            # å¹³å‡å€¼å¯ä»¥å…¬å¹³åœ°æ¯”è¾ƒåŒæ–¹çš„å®åŠ›æ°´å¹³\n",
    "            # p1_team_stats['mean'] æ˜¯ä¸€ä¸ªåŒ…å«6ä¸ªå±æ€§å¹³å‡å€¼çš„åˆ—è¡¨ï¼š[hp_mean, atk_mean, def_mean, spa_mean, spd_mean, spe_mean]\n",
    "            # sum(p1_team_stats['mean']) å°†è¿™6ä¸ªå±æ€§çš„å¹³å‡å€¼ç›¸åŠ ï¼Œå¾—åˆ°P1é˜Ÿä¼çš„å¹³å‡æ€»å®åŠ›æŒ‡æ ‡\n",
    "            # è¿™æ ·å³ä½¿P1æœ‰6åªå­˜æ´»ã€P2åªæœ‰3åªå­˜æ´»ï¼Œä¹Ÿèƒ½å…¬å¹³æ¯”è¾ƒåŒæ–¹çš„å¹³å‡å®åŠ›æ°´å¹³\n",
    "            p1_total_stats_mean = sum(p1_team_stats['mean'])\n",
    "            p2_total_stats_mean = sum(p2_team_stats['mean'])\n",
    "            features['p1_total_stats_mean'] = p1_total_stats_mean\n",
    "            features['p2_total_stats_mean'] = p2_total_stats_mean\n",
    "            features['total_stats_advantage'] = p1_total_stats_mean - p2_total_stats_mean\n",
    "            \n",
    "            # å¯é€‰ï¼šå¦‚æœä»éœ€è¦æ€»å’Œç‰¹å¾ï¼ˆç”¨äºå…¶ä»–åˆ†æï¼‰ï¼Œä½†è¦æ³¨æ„å­˜æ´»æ•°é‡å·®å¼‚\n",
    "            # features['p1_total_stats_sum'] = sum(p1_team_stats['sum'])\n",
    "            # features['p2_total_stats_sum'] = sum(p2_team_stats['sum'])\n",
    "            # features['p1_alive_count'] = len(p1_alive_pokemon_names)\n",
    "            # features['p2_alive_count'] = len(p2_alive_pokemon_names)\n",
    "\n",
    "            return features\n",
    "\n",
    "        # ä¸ºè®­ç»ƒæ•°æ®æå–ç‰¹å¾\n",
    "        train_features = [extract_single_static_features(row) for _, row in self.train_data.iterrows()]\n",
    "\n",
    "        # ä¸ºæµ‹è¯•æ•°æ®æå–ç›¸åŒç‰¹å¾\n",
    "        test_features = [extract_single_static_features(row) for _, row in self.test_data.iterrows()]\n",
    "\n",
    "        self.train_static_features = pd.DataFrame(train_features)\n",
    "        self.test_static_features = pd.DataFrame(test_features)\n",
    "\n",
    "        print(f\"é™æ€ç‰¹å¾æå–å®Œæˆ: {self.train_static_features.shape[1]} ä¸ªç‰¹å¾\")\n",
    "        return self.train_static_features, self.test_static_features\n",
    "\n",
    "    def extract_dynamic_features(self):\n",
    "        \"\"\"\n",
    "        æå–åŠ¨æ€ç‰¹å¾ï¼ˆæˆ˜æ–—æ—¶é—´çº¿ï¼‰- å¢å¼ºç‰ˆ\n",
    "        \n",
    "        å…±175ä¸ªç‰¹å¾ï¼š\n",
    "        - å›åˆæ•°: 1ä¸ª\n",
    "        - æ•´ä½“HPç»Ÿè®¡: 14ä¸ª (æ¯ä¸ªç©å®¶7ä¸ª: start/end/min/max/avg/std/trend)\n",
    "        - åˆ†æ®µHPç»Ÿè®¡: 12ä¸ª (æ—©ä¸­æ™šæœŸ Ã— æ¯ä¸ªç©å®¶2ä¸ª)\n",
    "        - HPæŸå¤±é€Ÿç‡: 4ä¸ª (æ¯ä¸ªç©å®¶2ä¸ª: avg/max)\n",
    "        - HPä¼˜åŠ¿: 3ä¸ª (start/end/avg)\n",
    "        - æ‹›å¼å¤šæ ·æ€§: 2ä¸ª\n",
    "        - çŠ¶æ€å¼‚å¸¸æ€»è®¡: 2ä¸ª\n",
    "        - å¼‚å¸¸çŠ¶æ€ç»Ÿè®¡: 1ä¸ª (abnormal_status_count_ratio) â­æ–°å¢\n",
    "          * P1å‰30å›åˆå‡ºç°çš„ç²¾çµä¸­æœ‰å¼‚å¸¸çŠ¶æ€çš„ç²¾çµæ•°é‡ / (P2å‰30å›åˆå‡ºç°çš„ç²¾çµä¸­æœ‰å¼‚å¸¸çŠ¶æ€çš„ç²¾çµæ•°é‡ + 1)\n",
    "          * ä½¿ç”¨å¹³æ»‘å¤„ç†é¿å…é™¤ä»¥0\n",
    "        - CounteræŠ€èƒ½ç»Ÿè®¡: 2ä¸ª (Counteræ— æ•ˆæ¬¡æ•°Ã—2) â­æ–°å¢\n",
    "        - æ‹›å¼å¨åŠ›: 6ä¸ª (æ¯ä¸ªç©å®¶3ä¸ª: avg/max/min)\n",
    "        - å‘½ä¸­ç‡: 2ä¸ª\n",
    "        - æ‹›å¼ç±»åˆ«æ¯”ä¾‹: 6ä¸ª (æ¯ä¸ªç©å®¶3ä¸ª: physical/special/status)\n",
    "        - æ¢ç²¾çµ: 10ä¸ª (countÃ—2 + early_ratioÃ—2 + move_null_countÃ—2 + move_null_switchÃ—2 + move_null_statusÃ—2) â­å¢å¼º\n",
    "        - æŠ€èƒ½ä½¿ç”¨æ¬¡æ•°: 80ä¸ª (æ¯ä¸ªæŠ€èƒ½Ã—2ç©å®¶) â­æ–°å¢\n",
    "        - è¿ç»­æ”»å‡»: 2ä¸ª\n",
    "        - å±æ€§æå‡: 13ä¸ª (æ¯ä¸ªç©å®¶6ä¸ª + advantage)\n",
    "        - åœºåœ°æ•ˆæœ: 2ä¸ª\n",
    "        - å‰30å›åˆç²¾çµä¸ªæ•°: 2ä¸ª (p1_unique_pokemon_count_30turns, p2_unique_pokemon_count_30turns) â­æ–°å¢\n",
    "        - å‰30å›åˆ6åªç²¾çµæ€»HP: 3ä¸ª (p1_total_pokemon_hp_pct_30turns, p2_total_pokemon_hp_pct_30turns, total_pokemon_hp_pct_ratio_30turns) â­æ–°å¢\n",
    "          * å¯¹äºå‡ºç°çš„ç²¾çµï¼Œå–æœ€åä¸€æ¬¡å‡ºç°çš„hp_pct\n",
    "          * ä¸è¶³6åªæ—¶ï¼Œå…¶ä½™æŒ‰æ»¡è¡€1.0è®¡ç®—\n",
    "          * total_pokemon_hp_pct_ratio_30turns = p1_total / p2_total (æ¯”å€¼ç‰¹å¾)\n",
    "        - æ­»äº¡ç²¾çµæ•°é‡ç»Ÿè®¡: 2ä¸ª (fnt_count_ratio, fnt_count_diff) â­æ–°å¢\n",
    "          * fnt_count_ratio: P1æ­»äº¡æ•°é‡ / (P2æ­»äº¡æ•°é‡ + 1) [å¹³æ»‘å¤„ç†é¿å…é™¤ä»¥0]\n",
    "          * fnt_count_diff: P1æ­»äº¡æ•°é‡ - P2æ­»äº¡æ•°é‡ [åæ˜ ç»å¯¹ä¼˜åŠ¿]\n",
    "        # - ç¬¬30å›åˆç»„åˆèƒœç‡: 1ä¸ª (turn30_combination_winrate) â­æ–°å¢\n",
    "        #   * åŸºäºç¬¬30å›åˆæ—¶åŒæ–¹å­˜æ´»å®å¯æ¢¦ç»„åˆçš„å†å²èƒœç‡\n",
    "        #   * å®Œå…¨åŒ¹é…æ—¶ä½¿ç”¨å†å²èƒœç‡æ¯”å€¼ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤å€¼1.0ï¼ˆä¸­æ€§ï¼‰\n",
    "        #   * åæ˜ è¯¥ç»„åˆåœ¨å†å²æ•°æ®ä¸­çš„è¡¨ç°\n",
    "        - ç±»å‹å…‹åˆ¶æ•ˆæœå€æ•°: 2ä¸ª (p1_avg, p2_avg) â­æ–°å¢\n",
    "          * p1_avg: ç©å®¶1é˜Ÿä¼å¯¹ç©å®¶2é˜Ÿä¼çš„å¹³å‡ç±»å‹æ•ˆæœå€æ•°\n",
    "          * p2_avg: ç©å®¶2é˜Ÿä¼å¯¹ç©å®¶1é˜Ÿä¼çš„å¹³å‡ç±»å‹æ•ˆæœå€æ•°\n",
    "          * åŸºäºæˆ˜æ–—è¿‡ç¨‹ä¸­ä½¿ç”¨çš„æŠ€èƒ½ç±»å‹ï¼Œè®¡ç®—ç±»å‹å…‹åˆ¶æ•ˆæœ\n",
    "          * è€ƒè™‘æŠ€èƒ½å¨åŠ›å’Œç±»å‹å…‹åˆ¶å…³ç³»ï¼ˆè¶…æœ‰æ•ˆ2å€ã€æ•ˆæœä¸ä½³0.5å€ã€æ— æ•ˆ0å€ï¼‰\n",
    "          * åæ˜ åŒæ–¹é˜Ÿä¼åœ¨ç±»å‹ä¸Šçš„ç›¸å¯¹ä¼˜åŠ¿\n",
    "        - å…ˆåˆ¶æŠ€èƒ½ä¼˜å…ˆçº§æ€»å’Œ: 2ä¸ª (p1_num_priority_moves, p2_num_priority_moves) â­æ–°å¢\n",
    "          * p1_num_priority_moves: ç©å®¶1å…ˆåˆ¶æŠ€èƒ½çš„ä¼˜å…ˆçº§æ€»å’Œ\n",
    "          * p2_num_priority_moves: ç©å®¶2å…ˆåˆ¶æŠ€èƒ½çš„ä¼˜å…ˆçº§æ€»å’Œ\n",
    "          * ç»Ÿè®¡æ‰€æœ‰å…ˆåˆ¶æŠ€èƒ½çš„ä¼˜å…ˆçº§å€¼æ€»å’Œï¼Œç”¨äºè¯„ä¼°é˜Ÿä¼çš„å…ˆåˆ¶æ”»å‡»èƒ½åŠ›\n",
    "          * ä¼˜å…ˆçº§å€¼è¶Šé«˜ï¼Œè¡ŒåŠ¨é¡ºåºè¶Šé å‰ï¼Œåœ¨æˆ˜æ–—ä¸­å…·æœ‰é€Ÿåº¦ä¼˜åŠ¿\n",
    "        \"\"\"\n",
    "        print(\"\\n=== æå–åŠ¨æ€ç‰¹å¾(å¢å¼ºç‰ˆ) ===\")\n",
    "        \n",
    "        # åŠ è½½ç¬¬30å›åˆç»„åˆèƒœç‡æ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰\n",
    "        # if self.turn30_winrates is None:\n",
    "        #     self.load_turn30_winrates()\n",
    "        \n",
    "        # è·å–æ‰€æœ‰æŠ€èƒ½åˆ—è¡¨\n",
    "        # all_moves_list = self.get_all_moves_list()\n",
    "        \n",
    "        # åŠ è½½å®å¯æ¢¦å±æ€§æ•°æ®åº“ï¼ˆç”¨äºæŸ¥æ‰¾P2å…¶ä»–ç²¾çµçš„å±æ€§ï¼‰\n",
    "        pokemon_db = {}\n",
    "        try:\n",
    "            if os.path.exists('pokemon_stats_20.json'):\n",
    "                with open('pokemon_stats_20.json', 'r', encoding='utf-8') as f:\n",
    "                    pokemon_list = json.load(f)\n",
    "                    for pokemon in pokemon_list:\n",
    "                        pokemon_name = pokemon.get('name', '').lower()\n",
    "                        if pokemon_name:\n",
    "                            pokemon_db[pokemon_name] = pokemon\n",
    "                print(f\"âœ“ å·²åŠ è½½ {len(pokemon_db)} ç§å®å¯æ¢¦å±æ€§æ•°æ®\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ åŠ è½½å®å¯æ¢¦å±æ€§æ•°æ®åº“å¤±è´¥: {e}\")\n",
    "            pokemon_db = {}\n",
    "        \n",
    "        # åˆ›å»ºæŠ€èƒ½åç§°åˆ°ç‰¹å¾åçš„æ˜ å°„ï¼ˆå¤„ç†ç‰¹æ®Šå­—ç¬¦ï¼‰\n",
    "        def sanitize_move_name(move_name):\n",
    "            \"\"\"å°†æŠ€èƒ½åç§°è½¬æ¢ä¸ºæœ‰æ•ˆçš„ç‰¹å¾å\"\"\"\n",
    "            # æ›¿æ¢ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦ä¸ºä¸‹åˆ’çº¿\n",
    "            sanitized = move_name.replace(' ', '_').replace('-', '_').replace(\"'\", '').replace('.', '')\n",
    "            # ç§»é™¤å…¶ä»–ç‰¹æ®Šå­—ç¬¦\n",
    "            sanitized = ''.join(c if c.isalnum() or c == '_' else '_' for c in sanitized)\n",
    "            return sanitized.lower()\n",
    "        \n",
    "        # move_to_feature = {move: sanitize_move_name(move) for move in all_moves_list}\n",
    "\n",
    "        # å®šä¹‰å¼ºåº¦å€¼è®¡ç®—æƒé‡\n",
    "        WEIGHT_HP = 1.0\n",
    "        WEIGHT_ATTACK = 1.5  # ç‰©ç†æ”»å‡»å’Œç‰¹æ®Šæ”»å‡»çš„å¹³å‡æƒé‡\n",
    "        WEIGHT_DEFENSE = 1.0  # ç‰©ç†é˜²å¾¡å’Œç‰¹æ®Šé˜²å¾¡çš„å¹³å‡æƒé‡\n",
    "        WEIGHT_SPEED = 1.75  # é€Ÿåº¦é€šå¸¸éå¸¸å…³é”®\n",
    "        \n",
    "        # ç‰¹æ®Šå®å¯æ¢¦ä¿®æ­£å€¼\n",
    "        SPECIAL_POKEMON_MODIFIERS = {\n",
    "            \"chansey\": 1.2,\n",
    "            \"alakazam\": 1.25,\n",
    "            \"snorlax\": 1.15,\n",
    "            \"dragonite\": 1.2,\n",
    "            \"zapdos\": 1.1,\n",
    "            \"starmie\": 1.05,\n",
    "            \"exeggutor\": 1.05,\n",
    "            \"gengar\": 1.1,\n",
    "            \"rhydon\": 1.05,\n",
    "            \"cloyster\": 1.05,\n",
    "            \"golem\": 1.05,\n",
    "            \"jolteon\": 1.05,\n",
    "            \"articuno\": 1.05,\n",
    "            \"persian\": 1.0,\n",
    "            \"lapras\": 1.05,\n",
    "            \"charizard\": 1.0,\n",
    "            \"victreebel\": 1.0,\n",
    "            \"jynx\": 1.0,\n",
    "            \"slowbro\": 1.05,\n",
    "            \"tauros\": 1.05\n",
    "        }\n",
    "        \n",
    "        def calculate_pokemon_strength(pokemon_data):\n",
    "            \"\"\"\n",
    "            è®¡ç®—Pokemonçš„å¼ºåº¦å€¼\n",
    "            \n",
    "            å‚æ•°:\n",
    "            - pokemon_data: Pokemonæ•°æ®å­—å…¸ï¼ŒåŒ…å«base_hp, base_atk, base_def, base_spa, base_spd, base_spe\n",
    "            \n",
    "            è¿”å›:\n",
    "            - å¼ºåº¦å€¼ï¼ˆæµ®ç‚¹æ•°ï¼‰\n",
    "            \"\"\"\n",
    "            if not pokemon_data:\n",
    "                return 0.0\n",
    "            \n",
    "            base_hp = pokemon_data.get('base_hp', 0)\n",
    "            base_atk = pokemon_data.get('base_atk', 0)\n",
    "            base_def = pokemon_data.get('base_def', 0)\n",
    "            base_spa = pokemon_data.get('base_spa', 0)\n",
    "            base_spd = pokemon_data.get('base_spd', 0)\n",
    "            base_spe = pokemon_data.get('base_spe', 0)\n",
    "            \n",
    "            # è®¡ç®—åŸºç¡€å¼ºåº¦å€¼\n",
    "            hp_score = base_hp * WEIGHT_HP\n",
    "            atk_score = base_atk * WEIGHT_ATTACK\n",
    "            def_score = base_def * WEIGHT_DEFENSE\n",
    "            spa_score = base_spa * WEIGHT_ATTACK  # ç‰¹æ”»ä½¿ç”¨ä¸ç‰©æ”»ç›¸åŒçš„æƒé‡\n",
    "            spd_score = base_spd * WEIGHT_DEFENSE  # ç‰¹é˜²ä½¿ç”¨ä¸ç‰©é˜²ç›¸åŒçš„æƒé‡\n",
    "            spe_score = base_spe * WEIGHT_SPEED\n",
    "            \n",
    "            strength = hp_score + atk_score + def_score + spa_score + spd_score + spe_score\n",
    "            \n",
    "            # åº”ç”¨ç‰¹æ®Šå®å¯æ¢¦ä¿®æ­£å€¼\n",
    "            pokemon_name = pokemon_data.get('name', '').lower()\n",
    "            if pokemon_name in SPECIAL_POKEMON_MODIFIERS:\n",
    "                strength *= SPECIAL_POKEMON_MODIFIERS[pokemon_name]\n",
    "            \n",
    "            return strength\n",
    "\n",
    "        def analyze_battle_timeline(row, timeline, pokemon_db=None, turn30_winrates=None):\n",
    "            \"\"\"åˆ†ææˆ˜æ–—æ—¶é—´çº¿ - åŒ…å«æ—©ä¸­æ™šæœŸåˆ†æ®µåˆ†æ\"\"\"\n",
    "            if not timeline:\n",
    "                return {}\n",
    "            \n",
    "            if pokemon_db is None:\n",
    "                pokemon_db = {}\n",
    "            \n",
    "            if turn30_winrates is None:\n",
    "                turn30_winrates = {}\n",
    "\n",
    "            features = {}\n",
    "            total_turns = len(timeline)\n",
    "            # features['total_turns'] = total_turns\n",
    "\n",
    "            # åˆå§‹åŒ–æ‰€æœ‰åˆ—è¡¨\n",
    "            p1_hp_changes = []\n",
    "            p2_hp_changes = []\n",
    "            p1_moves = []\n",
    "            p2_moves = []\n",
    "            # ä½¿ç”¨å­—å…¸å­˜å‚¨æ¯ä¸ªç²¾çµçš„æœ€åçŠ¶æ€ï¼š{pokemon_name: status}\n",
    "            p1_pokemon_status_dict = {}  # P1æ¯ä¸ªç²¾çµçš„æœ€åçŠ¶æ€\n",
    "            p2_pokemon_status_dict = {}  # P2æ¯ä¸ªç²¾çµçš„æœ€åçŠ¶æ€\n",
    "            p1_counter_invalid = 0  # Counteræ— æ•ˆæ¬¡æ•°\n",
    "            p2_counter_invalid = 0\n",
    "            p1_move_powers = []\n",
    "            p2_move_powers = []\n",
    "            p1_move_accuracies = []\n",
    "            p2_move_accuracies = []\n",
    "            # æ‹›å¼ç±»åˆ«ç»Ÿè®¡ï¼ˆå·²æ³¨é‡Šï¼‰\n",
    "            # p1_physical_moves = 0\n",
    "            # p2_physical_moves = 0\n",
    "            # p1_special_moves = 0\n",
    "            # p2_special_moves = 0\n",
    "            # p1_status_moves = 0\n",
    "            # p2_status_moves = 0\n",
    "            p1_switch_count = 0\n",
    "            p2_switch_count = 0\n",
    "            # p1_move_null_count = 0  # P1 move_detailsä¸ºnullçš„æ¬¡æ•°ï¼ˆä¿ç•™ç”¨äºå…¼å®¹ï¼‰\n",
    "            # p2_move_null_count = 0  # P2 move_detailsä¸ºnullçš„æ¬¡æ•°ï¼ˆä¿ç•™ç”¨äºå…¼å®¹ï¼‰\n",
    "            p1_move_null_switch = 0  # P1å› æ¢äººå¯¼è‡´çš„move_detailsä¸ºnullçš„æ¬¡æ•°\n",
    "            p2_move_null_switch = 0  # P2å› æ¢äººå¯¼è‡´çš„move_detailsä¸ºnullçš„æ¬¡æ•°\n",
    "            p1_move_null_status = 0  # P1å› çŠ¶æ€å¼‚å¸¸å¯¼è‡´çš„move_detailsä¸ºnullçš„æ¬¡æ•°\n",
    "            p2_move_null_status = 0  # P2å› çŠ¶æ€å¼‚å¸¸å¯¼è‡´çš„move_detailsä¸ºnullçš„æ¬¡æ•°\n",
    "            \n",
    "            # åˆå§‹åŒ–æ¯ä¸ªæŠ€èƒ½çš„ä½¿ç”¨æ¬¡æ•°è®¡æ•°å™¨\n",
    "            # p1_move_counts = {move: 0 for move in all_moves_list}\n",
    "            # p2_move_counts = {move: 0 for move in all_moves_list}\n",
    "            \n",
    "            p1_boost_changes = []\n",
    "            p2_boost_changes = []\n",
    "            p1_final_boosts = {'atk': 0, 'def': 0, 'spa': 0, 'spd': 0, 'spe': 0}\n",
    "            p2_final_boosts = {'atk': 0, 'def': 0, 'spa': 0, 'spd': 0, 'spe': 0}\n",
    "            # effect_turnsç»Ÿè®¡ï¼ˆå·²æ³¨é‡Šï¼‰\n",
    "            # p1_effect_turns = 0\n",
    "            # p2_effect_turns = 0\n",
    "            # HPæŸå¤±ç‰¹å¾ï¼ˆå·²æ³¨é‡Šï¼‰\n",
    "            p1_hp_losses = []\n",
    "            p2_hp_losses = []\n",
    "\n",
    "            # åˆ†æ®µç»Ÿè®¡\n",
    "            early_end = total_turns // 3\n",
    "            mid_end = 2 * total_turns // 3\n",
    "\n",
    "            # åˆ†æ®µHPç‰¹å¾ï¼ˆå·²æ³¨é‡Šï¼‰\n",
    "            # p1_early_hp = []\n",
    "            # p2_early_hp = []\n",
    "            # p1_mid_hp = []\n",
    "            # p2_mid_hp = []\n",
    "            # p1_late_hp = []\n",
    "            # p2_late_hp = []\n",
    "\n",
    "            # è¿ç»­æ”»å‡»ç»Ÿè®¡ï¼ˆå·²æ³¨é‡Šï¼‰\n",
    "            # p1_consecutive_attacks = 0\n",
    "            # p2_consecutive_attacks = 0\n",
    "            # p1_max_consecutive = 0\n",
    "            # p2_max_consecutive = 0\n",
    "            # p1_last_was_attack = False\n",
    "            # p2_last_was_attack = False\n",
    "\n",
    "            # æ¢ç²¾çµæ—¶æœº\n",
    "            p1_switch_turns = []\n",
    "            p2_switch_turns = []\n",
    "            \n",
    "            # å‰30å›åˆå‡ºç°çš„ç²¾çµç»Ÿè®¡\n",
    "            p1_pokemon_appeared_30turns = set()  # P1åœ¨å‰30å›åˆå†…å‡ºç°çš„ç²¾çµé›†åˆ\n",
    "            p2_pokemon_appeared_30turns = set()  # P2åœ¨å‰30å›åˆå†…å‡ºç°çš„ç²¾çµé›†åˆ\n",
    "            \n",
    "            # å­˜å‚¨æ¯åªç²¾çµçš„hp_pctï¼ˆå‰30å›åˆï¼‰\n",
    "            # ä½¿ç”¨å­—å…¸å­˜å‚¨ï¼š{pokemon_name: [hp_pct_values]}\n",
    "            p1_pokemon_hp_dict = {}  # P1æ¯åªç²¾çµçš„hp_pctåˆ—è¡¨\n",
    "            p2_pokemon_hp_dict = {}  # P2æ¯åªç²¾çµçš„hp_pctåˆ—è¡¨\n",
    "\n",
    "            # ç”¨äºè·Ÿè¸ªå‰ä¸€è½®çš„pokemon nameï¼Œä»¥åˆ¤æ–­æ¢äºº\n",
    "            p1_prev_pokemon_name = None\n",
    "            p2_prev_pokemon_name = None\n",
    "            # ç”¨äºHPæŸå¤±ç‰¹å¾ï¼šä¿å­˜å‰ä¸€ä¸ªå›åˆçš„HPå€¼\n",
    "            p1_prev_hp = None\n",
    "            p2_prev_hp = None\n",
    "\n",
    "            for i, turn in enumerate(timeline):\n",
    "                # HPæ•°æ®ï¼ˆå·²æ³¨é‡Š - æ•´ä½“HPç‰¹å¾ç›¸å…³ï¼‰\n",
    "                # p1_hp = turn.get('p1_pokemon_state', {}).get('hp_pct', 0)\n",
    "                # p2_hp = turn.get('p2_pokemon_state', {}).get('hp_pct', 0)\n",
    "                # p1_hp_changes.append(p1_hp)\n",
    "                # p2_hp_changes.append(p2_hp)\n",
    "                \n",
    "                # ä¸ºäº†HPæŸå¤±ç‰¹å¾ï¼Œä»éœ€è¦è·å–HPå€¼\n",
    "                p1_hp = turn.get('p1_pokemon_state', {}).get('hp_pct', 0)\n",
    "                p2_hp = turn.get('p2_pokemon_state', {}).get('hp_pct', 0)\n",
    "                \n",
    "                # ç»Ÿè®¡å‰30å›åˆå‡ºç°çš„ç²¾çµå’ŒHP\n",
    "                if i < 30:\n",
    "                    p1_pokemon_name = turn.get('p1_pokemon_state', {}).get('name', '')\n",
    "                    p2_pokemon_name = turn.get('p2_pokemon_state', {}).get('name', '')\n",
    "                    \n",
    "                    # è®°å½•P1ç²¾çµå‡ºç°å’ŒHP\n",
    "                    if p1_pokemon_name:\n",
    "                        p1_pokemon_appeared_30turns.add(p1_pokemon_name)\n",
    "                        # å­˜å‚¨è¯¥ç²¾çµçš„hp_pct\n",
    "                        if p1_pokemon_name not in p1_pokemon_hp_dict:\n",
    "                            p1_pokemon_hp_dict[p1_pokemon_name] = []\n",
    "                        p1_pokemon_hp_dict[p1_pokemon_name].append(p1_hp)\n",
    "                    \n",
    "                    # è®°å½•P2ç²¾çµå‡ºç°å’ŒHP\n",
    "                    if p2_pokemon_name:\n",
    "                        p2_pokemon_appeared_30turns.add(p2_pokemon_name)\n",
    "                        # å­˜å‚¨è¯¥ç²¾çµçš„hp_pct\n",
    "                        if p2_pokemon_name not in p2_pokemon_hp_dict:\n",
    "                            p2_pokemon_hp_dict[p2_pokemon_name] = []\n",
    "                        p2_pokemon_hp_dict[p2_pokemon_name].append(p2_hp)\n",
    "\n",
    "                # åˆ†æ®µHPç‰¹å¾ï¼ˆå·²æ³¨é‡Šï¼‰\n",
    "                # if i < early_end:\n",
    "                #     p1_early_hp.append(p1_hp)\n",
    "                #     p2_early_hp.append(p2_hp)\n",
    "                # elif i < mid_end:\n",
    "                #     p1_mid_hp.append(p1_hp)\n",
    "                #     p2_mid_hp.append(p2_hp)\n",
    "                # else:\n",
    "                #     p1_late_hp.append(p1_hp)\n",
    "                #     p2_late_hp.append(p2_hp)\n",
    "\n",
    "                # HPæŸå¤±\n",
    "                if p1_prev_hp is not None:\n",
    "                    p1_hp_loss = p1_prev_hp - p1_hp\n",
    "                    p1_hp_losses.append(p1_hp_loss)\n",
    "                if p2_prev_hp is not None:\n",
    "                    p2_hp_loss = p2_prev_hp - p2_hp\n",
    "                    p2_hp_losses.append(p2_hp_loss)\n",
    "                \n",
    "                # æ›´æ–°å‰ä¸€ä¸ªå›åˆçš„HPå€¼\n",
    "                p1_prev_hp = p1_hp\n",
    "                p2_prev_hp = p2_hp\n",
    "\n",
    "                # æ‹›å¼åˆ†æ\n",
    "                p1_move = turn.get('p1_move_details')\n",
    "                p2_move = turn.get('p2_move_details')\n",
    "                \n",
    "                # è·å–å½“å‰å›åˆçš„pokemon name\n",
    "                p1_current_pokemon_name = turn.get('p1_pokemon_state', {}).get('name', '')\n",
    "                p2_current_pokemon_name = turn.get('p2_pokemon_state', {}).get('name', '')\n",
    "                \n",
    "                # ç»Ÿè®¡move_detailsä¸ºnullçš„æ¬¡æ•°ï¼Œå¹¶åŒºåˆ†æ¢äººå’ŒçŠ¶æ€å¼‚å¸¸\n",
    "                # P1çš„nullåˆ¤æ–­\n",
    "                if p1_move is None:\n",
    "                    # p1_move_null_count += 1  # ä¿ç•™æ€»æ•°ç»Ÿè®¡\n",
    "                    # åˆ¤æ–­æ˜¯æ¢äººè¿˜æ˜¯çŠ¶æ€å¼‚å¸¸\n",
    "                    if i > 0 and p1_prev_pokemon_name is not None and p1_current_pokemon_name != p1_prev_pokemon_name:\n",
    "                        # å‰ä¸€è½®pokemon nameå’Œå½“å‰ä¸ä¸€æ ·ï¼Œè¯´æ˜æ˜¯æ¢äºº\n",
    "                        p1_move_null_switch += 1\n",
    "                    else:\n",
    "                        # pokemon nameä¸€æ ·æˆ–ç¬¬ä¸€è½®ï¼Œè¯´æ˜æ˜¯çŠ¶æ€å¼‚å¸¸ï¼ˆå¦‚ç¡çœ ã€éº»ç—¹ç­‰ï¼‰\n",
    "                        p1_move_null_status += 1\n",
    "                \n",
    "                # P2çš„nullåˆ¤æ–­\n",
    "                if p2_move is None:\n",
    "                    # p2_move_null_count += 1  # ä¿ç•™æ€»æ•°ç»Ÿè®¡\n",
    "                    # åˆ¤æ–­æ˜¯æ¢äººè¿˜æ˜¯çŠ¶æ€å¼‚å¸¸\n",
    "                    if i > 0 and p2_prev_pokemon_name is not None and p2_current_pokemon_name != p2_prev_pokemon_name:\n",
    "                        # å‰ä¸€è½®pokemon nameå’Œå½“å‰ä¸ä¸€æ ·ï¼Œè¯´æ˜æ˜¯æ¢äºº\n",
    "                        p2_move_null_switch += 1\n",
    "                    else:\n",
    "                        # pokemon nameä¸€æ ·æˆ–ç¬¬ä¸€è½®ï¼Œè¯´æ˜æ˜¯çŠ¶æ€å¼‚å¸¸ï¼ˆå¦‚ç¡çœ ã€éº»ç—¹ç­‰ï¼‰\n",
    "                        p2_move_null_status += 1\n",
    "                \n",
    "                # æ›´æ–°å‰ä¸€è½®çš„pokemon nameï¼ˆç”¨äºä¸‹ä¸€è½®åˆ¤æ–­ï¼‰\n",
    "                p1_prev_pokemon_name = p1_current_pokemon_name\n",
    "                p2_prev_pokemon_name = p2_current_pokemon_name\n",
    "                \n",
    "                # CounteræŠ€èƒ½åˆ†æ - æ£€æµ‹Counteræ˜¯å¦æ— æ•ˆ\n",
    "                # P1ä½¿ç”¨Counteræ—¶ï¼Œæ£€æŸ¥P2çš„æ‹›å¼\n",
    "                if p1_move and p1_move.get('name', '').lower() == 'counter':\n",
    "                    # å¦‚æœP2æ²¡æ”»å‡»ï¼ˆæ¢äººï¼‰æˆ–ä¸æ˜¯ç‰©ç†æ”»å‡»ï¼ŒCounteræ— æ•ˆ\n",
    "                    if not p2_move:  # P2æ¢äºº\n",
    "                        p1_counter_invalid += 1\n",
    "                    elif p2_move.get('category', 'STATUS') != 'PHYSICAL':  # ä¸æ˜¯ç‰©ç†æ”»å‡»\n",
    "                        p1_counter_invalid += 1\n",
    "                \n",
    "                # P2ä½¿ç”¨Counteræ—¶ï¼Œæ£€æŸ¥P1çš„æ‹›å¼\n",
    "                if p2_move and p2_move.get('name', '').lower() == 'counter':\n",
    "                    # å¦‚æœP1æ²¡æ”»å‡»ï¼ˆæ¢äººï¼‰æˆ–ä¸æ˜¯ç‰©ç†æ”»å‡»ï¼ŒCounteræ— æ•ˆ\n",
    "                    if not p1_move:  # P1æ¢äºº\n",
    "                        p2_counter_invalid += 1\n",
    "                    elif p1_move.get('category', 'STATUS') != 'PHYSICAL':  # ä¸æ˜¯ç‰©ç†æ”»å‡»\n",
    "                        p2_counter_invalid += 1\n",
    "\n",
    "                # P1æ‹›å¼\n",
    "                if p1_move:\n",
    "                    move_name = p1_move.get('name', '')\n",
    "                    p1_moves.append(move_name)\n",
    "                    \n",
    "                    # # ç»Ÿè®¡è¯¥æŠ€èƒ½çš„ä½¿ç”¨æ¬¡æ•°\n",
    "                    # if move_name in p1_move_counts:\n",
    "                    #     p1_move_counts[move_name] += 1\n",
    "                    \n",
    "                    power = p1_move.get('base_power', 0)\n",
    "                    accuracy = p1_move.get('accuracy', 1.0)\n",
    "                    category = p1_move.get('category', 'STATUS')\n",
    "\n",
    "                    # ç»Ÿè®¡æ‹›å¼å¨åŠ›ï¼ˆè¿ç»­æ”»å‡»ç‰¹å¾å·²æ³¨é‡Šï¼‰\n",
    "                    # power > 0 è¡¨ç¤ºè¿™æ˜¯ä¸€ä¸ªæ”»å‡»æ‹›å¼ï¼ˆç‰©ç†æˆ–ç‰¹æ®Šï¼‰ï¼Œpower = 0 è¡¨ç¤ºçŠ¶æ€æ‹›å¼\n",
    "                    if power > 0:\n",
    "                        # å½“å‰æ˜¯æ”»å‡»æ‹›å¼\n",
    "                        p1_move_powers.append(power)  # è®°å½•æ‹›å¼å¨åŠ›ï¼Œç”¨äºåç»­è®¡ç®—å¹³å‡/æœ€å¤§/æœ€å°å¨åŠ›\n",
    "                        # è¿ç»­æ”»å‡»ç»Ÿè®¡ï¼ˆå·²æ³¨é‡Šï¼‰\n",
    "                        # p1_consecutive_attacks += 1   # è¿ç»­æ”»å‡»è®¡æ•°+1\n",
    "                        # p1_last_was_attack = True      # æ ‡è®°å½“å‰å›åˆæ˜¯æ”»å‡»\n",
    "                    # else:\n",
    "                        # å½“å‰æ˜¯çŠ¶æ€æ‹›å¼ï¼ˆpower = 0ï¼‰\n",
    "                        # è¿ç»­æ”»å‡»ç»Ÿè®¡ï¼ˆå·²æ³¨é‡Šï¼‰\n",
    "                        # if p1_last_was_attack:\n",
    "                        #     # å¦‚æœä¸Šä¸€å›åˆæ˜¯æ”»å‡»ï¼Œè¯´æ˜è¿ç»­æ”»å‡»åˆšåˆšç»“æŸ\n",
    "                        #     # æ›´æ–°æœ€å¤§è¿ç»­æ”»å‡»æ¬¡æ•°ï¼ˆè®°å½•åˆ°ç›®å‰ä¸ºæ­¢æœ€é•¿çš„è¿ç»­æ”»å‡»åºåˆ—ï¼‰\n",
    "                        #     p1_max_consecutive = max(p1_max_consecutive, p1_consecutive_attacks)\n",
    "                        #     p1_consecutive_attacks = 0  # é‡ç½®è¿ç»­æ”»å‡»è®¡æ•°å™¨\n",
    "                        # p1_last_was_attack = False     # æ ‡è®°å½“å‰å›åˆä¸æ˜¯æ”»å‡»\n",
    "\n",
    "                    p1_move_accuracies.append(accuracy)\n",
    "\n",
    "                    # æ‹›å¼ç±»åˆ«ç»Ÿè®¡ï¼ˆå·²æ³¨é‡Šï¼‰\n",
    "                    # if category == 'PHYSICAL':\n",
    "                    #     p1_physical_moves += 1\n",
    "                    # elif category == 'SPECIAL':\n",
    "                    #     p1_special_moves += 1\n",
    "                    # elif category == 'STATUS':\n",
    "                    #     p1_status_moves += 1\n",
    "                else:\n",
    "                    p1_switch_count += 1\n",
    "                    p1_switch_turns.append(i)\n",
    "                    # è¿ç»­æ”»å‡»ç»Ÿè®¡ï¼ˆå·²æ³¨é‡Šï¼‰\n",
    "                    # if p1_last_was_attack:\n",
    "                    #     p1_max_consecutive = max(p1_max_consecutive, p1_consecutive_attacks)\n",
    "                    #     p1_consecutive_attacks = 0\n",
    "                    # p1_last_was_attack = False\n",
    "\n",
    "                # P2æ‹›å¼\n",
    "                if p2_move:\n",
    "                    move_name = p2_move.get('name', '')\n",
    "                    p2_moves.append(move_name)\n",
    "                    \n",
    "                    # # ç»Ÿè®¡è¯¥æŠ€èƒ½çš„ä½¿ç”¨æ¬¡æ•°\n",
    "                    # if move_name in p2_move_counts:\n",
    "                    #     p2_move_counts[move_name] += 1\n",
    "                    \n",
    "                    power = p2_move.get('base_power', 0)\n",
    "                    accuracy = p2_move.get('accuracy', 1.0)\n",
    "                    category = p2_move.get('category', 'STATUS')\n",
    "\n",
    "                    if power > 0:\n",
    "                        p2_move_powers.append(power)\n",
    "                        # è¿ç»­æ”»å‡»ç»Ÿè®¡ï¼ˆå·²æ³¨é‡Šï¼‰\n",
    "                        # p2_consecutive_attacks += 1\n",
    "                        # p2_last_was_attack = True\n",
    "                    # else:\n",
    "                        # è¿ç»­æ”»å‡»ç»Ÿè®¡ï¼ˆå·²æ³¨é‡Šï¼‰\n",
    "                        # if p2_last_was_attack:\n",
    "                        #     p2_max_consecutive = max(p2_max_consecutive, p2_consecutive_attacks)\n",
    "                        #     p2_consecutive_attacks = 0\n",
    "                        # p2_last_was_attack = False\n",
    "\n",
    "                    p2_move_accuracies.append(accuracy)\n",
    "\n",
    "                    # æ‹›å¼ç±»åˆ«ç»Ÿè®¡ï¼ˆå·²æ³¨é‡Šï¼‰\n",
    "                    # if category == 'PHYSICAL':\n",
    "                    #     p2_physical_moves += 1\n",
    "                    # elif category == 'SPECIAL':\n",
    "                    #     p2_special_moves += 1\n",
    "                    # elif category == 'STATUS':\n",
    "                    #     p2_status_moves += 1\n",
    "                else:\n",
    "                    p2_switch_count += 1\n",
    "                    p2_switch_turns.append(i)\n",
    "                    # è¿ç»­æ”»å‡»ç»Ÿè®¡ï¼ˆå·²æ³¨é‡Šï¼‰\n",
    "                    # if p2_last_was_attack:\n",
    "                    #     p2_max_consecutive = max(p2_max_consecutive, p2_consecutive_attacks)\n",
    "                    #     p2_consecutive_attacks = 0\n",
    "                    # p2_last_was_attack = False\n",
    "\n",
    "                # çŠ¶æ€å˜åŒ– - å­˜å‚¨æ¯ä¸ªç²¾çµçš„æœ€åçŠ¶æ€\n",
    "                p1_pokemon_name = turn.get('p1_pokemon_state', {}).get('name', '')\n",
    "                p1_status = turn.get('p1_pokemon_state', {}).get('status', 'nostatus')\n",
    "                if p1_pokemon_name:\n",
    "                    # åªä¿å­˜æŸä¸ªç²¾çµçš„æœ€åä¸€æ¬¡å‡ºç°çš„çŠ¶æ€\n",
    "                    p1_pokemon_status_dict[p1_pokemon_name] = p1_status\n",
    "\n",
    "                p2_pokemon_name = turn.get('p2_pokemon_state', {}).get('name', '')\n",
    "                p2_status = turn.get('p2_pokemon_state', {}).get('status', 'nostatus')\n",
    "                if p2_pokemon_name:\n",
    "                    # åªä¿å­˜æŸä¸ªç²¾çµçš„æœ€åä¸€æ¬¡å‡ºç°çš„çŠ¶æ€\n",
    "                    p2_pokemon_status_dict[p2_pokemon_name] = p2_status\n",
    "\n",
    "                # å±æ€§æå‡\n",
    "                p1_boosts = turn.get('p1_pokemon_state', {}).get('boosts', {})\n",
    "                p2_boosts = turn.get('p2_pokemon_state', {}).get('boosts', {})\n",
    "\n",
    "                if p1_boosts:\n",
    "                    p1_final_boosts = p1_boosts\n",
    "                    boost_sum = sum(p1_boosts.values())\n",
    "                    p1_boost_changes.append(boost_sum)\n",
    "\n",
    "                if p2_boosts:\n",
    "                    p2_final_boosts = p2_boosts\n",
    "                    boost_sum = sum(p2_boosts.values())\n",
    "                    p2_boost_changes.append(boost_sum)\n",
    "\n",
    "\n",
    "            # HPæŸå¤±ç‰¹å¾ å¥½åƒè¿˜ç¡®å®æœ‰ç”¨\n",
    "            if p1_hp_losses:\n",
    "                features['p1_avg_hp_loss'] = np.mean(p1_hp_losses)\n",
    "                features['p1_max_hp_loss'] = max(p1_hp_losses)\n",
    "            else:\n",
    "                features['p1_avg_hp_loss'] = 0\n",
    "                features['p1_max_hp_loss'] = 0\n",
    "\n",
    "            if p2_hp_losses:\n",
    "                features['p2_avg_hp_loss'] = np.mean(p2_hp_losses)\n",
    "                features['p2_max_hp_loss'] = max(p2_hp_losses)\n",
    "            else:\n",
    "                features['p2_avg_hp_loss'] = 0\n",
    "                features['p2_max_hp_loss'] = 0\n",
    "\n",
    "            # ç»Ÿè®¡å‰30å›åˆå‡ºç°çš„ç²¾çµä¸­æœ‰å¼‚å¸¸çŠ¶æ€ï¼ˆénostatusï¼‰çš„ç²¾çµæ•°é‡\n",
    "            # è·å–å‰30å›åˆå‡ºç°çš„æ‰€æœ‰ç²¾çµï¼ˆæœ€å¤š6åªï¼Œä¹Ÿå¯èƒ½ä¸è¶³6åªï¼‰\n",
    "            p1_abnormal_status_count = 0\n",
    "            for pokemon_name in p1_pokemon_appeared_30turns:\n",
    "                # è·å–è¯¥ç²¾çµçš„æœ€åçŠ¶æ€\n",
    "                status = p1_pokemon_status_dict.get(pokemon_name, 'nostatus')\n",
    "                if status != 'nostatus' and status != 'fnt':\n",
    "                    p1_abnormal_status_count += 1\n",
    "            \n",
    "            p2_abnormal_status_count = 0\n",
    "            for pokemon_name in p2_pokemon_appeared_30turns:\n",
    "                # è·å–è¯¥ç²¾çµçš„æœ€åçŠ¶æ€\n",
    "                status = p2_pokemon_status_dict.get(pokemon_name, 'nostatus')\n",
    "                if status != 'nostatus' and status != 'fnt':\n",
    "                    p2_abnormal_status_count += 1\n",
    "            \n",
    "            # è®¡ç®—å¼‚å¸¸çŠ¶æ€æ•°é‡æ¯”å€¼ï¼ˆP1 / P2ï¼Œä½¿ç”¨å¹³æ»‘å¤„ç†é¿å…é™¤ä»¥0ï¼‰\n",
    "            features['p1_abnormal_status_count'] = p1_abnormal_status_count\n",
    "            features['p2_abnormal_status_count'] = p2_abnormal_status_count\n",
    "            features['abnormal_status_count_ratio'] = p1_abnormal_status_count / (p2_abnormal_status_count + 1.0)\n",
    "            \n",
    "            # CounteræŠ€èƒ½æ— æ•ˆæ¬¡æ•°ï¼ˆç¬¬ä¸€ä¸–ä»£æœºåˆ¶ï¼‰\n",
    "            features['p1_counter_invalid'] = p1_counter_invalid  # P1ä½¿ç”¨Counterä½†æ— æ•ˆçš„æ¬¡æ•°\n",
    "            features['p2_counter_invalid'] = p2_counter_invalid  # P2ä½¿ç”¨Counterä½†æ— æ•ˆçš„æ¬¡æ•°\n",
    "\n",
    "            # å‘½ä¸­ç‡\n",
    "            if p1_move_accuracies:\n",
    "                features['p1_avg_accuracy'] = np.mean(p1_move_accuracies)\n",
    "            else:\n",
    "                features['p1_avg_accuracy'] = 1.0\n",
    "\n",
    "            if p2_move_accuracies:\n",
    "                features['p2_avg_accuracy'] = np.mean(p2_move_accuracies)\n",
    "            else:\n",
    "                features['p2_avg_accuracy'] = 1.0\n",
    "\n",
    "\n",
    "            # æ¢ç²¾çµç‰¹å¾\n",
    "            features['p1_switch_count'] = p1_switch_count\n",
    "            features['p2_switch_count'] = p2_switch_count\n",
    "            \n",
    "            # move_detailsä¸ºnullçš„æ¬¡æ•°ï¼ˆæ¢äººæˆ–æœªä½¿ç”¨æ‹›å¼ï¼‰\n",
    "            # features['p1_move_null_count'] = p1_move_null_count  # P1 move_detailsä¸ºnullçš„æ€»æ¬¡æ•°ï¼ˆä¿ç•™ç”¨äºå…¼å®¹ï¼‰\n",
    "            # features['p2_move_null_count'] = p2_move_null_count  # P2 move_detailsä¸ºnullçš„æ€»æ¬¡æ•°ï¼ˆä¿ç•™ç”¨äºå…¼å®¹ï¼‰\n",
    "            # åŒºåˆ†æ¢äººå’ŒçŠ¶æ€å¼‚å¸¸å¯¼è‡´çš„null\n",
    "            features['p1_move_null_switch'] = p1_move_null_switch  # P1å› æ¢äººå¯¼è‡´çš„move_detailsä¸ºnullçš„æ¬¡æ•°\n",
    "            features['p2_move_null_switch'] = p2_move_null_switch  # P2å› æ¢äººå¯¼è‡´çš„move_detailsä¸ºnullçš„æ¬¡æ•°\n",
    "            features['p1_move_null_status'] = p1_move_null_status  # P1å› çŠ¶æ€å¼‚å¸¸å¯¼è‡´çš„move_detailsä¸ºnullçš„æ¬¡æ•°\n",
    "            features['p2_move_null_status'] = p2_move_null_status  # P2å› çŠ¶æ€å¼‚å¸¸å¯¼è‡´çš„move_detailsä¸ºnullçš„æ¬¡æ•°\n",
    "            \n",
    "            # æ¯ä¸ªæŠ€èƒ½çš„ä½¿ç”¨æ¬¡æ•°ç»Ÿè®¡ï¼ˆP1å’ŒP2å„40ä¸ªæŠ€èƒ½ï¼‰\n",
    "            # for move_name in all_moves_list:\n",
    "            #     feature_name_p1 = f'p1_move_{move_to_feature[move_name]}_count'\n",
    "            #     feature_name_p2 = f'p2_move_{move_to_feature[move_name]}_count'\n",
    "            #     features[feature_name_p1] = p1_move_counts.get(move_name, 0)\n",
    "            #     features[feature_name_p2] = p2_move_counts.get(move_name, 0)\n",
    "\n",
    "            # æ¢ç²¾çµæ—¶æœº(æ—©ä¸­æ™šæœŸå æ¯”)\n",
    "            if p1_switch_turns:\n",
    "                early_switches = sum(1 for t in p1_switch_turns if t < early_end)\n",
    "                features['p1_early_switch_ratio'] = early_switches / max(p1_switch_count, 1)\n",
    "            else:\n",
    "                features['p1_early_switch_ratio'] = 0\n",
    "\n",
    "            if p2_switch_turns:\n",
    "                early_switches = sum(1 for t in p2_switch_turns if t < early_end)\n",
    "                features['p2_early_switch_ratio'] = early_switches / max(p2_switch_count, 1)\n",
    "            else:\n",
    "                features['p2_early_switch_ratio'] = 0\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "            # å‰30å›åˆå‡ºç°çš„ç²¾çµä¸ªæ•°ç»Ÿè®¡\n",
    "            features['p1_unique_pokemon_count_30turns'] = len(p1_pokemon_appeared_30turns)\n",
    "            features['p2_unique_pokemon_count_30turns'] = len(p2_pokemon_appeared_30turns)\n",
    "            \n",
    "            # è®¡ç®—P1å’ŒP2å‰30å›åˆåŠ æƒå¼ºåº¦å€¼ï¼ˆhp_pct * å¼ºåº¦å€¼ï¼‰\n",
    "            # å¯¹äºå·²å‡ºç°çš„ç²¾çµï¼šä½¿ç”¨å®é™…çš„hp_pctå’Œstrength\n",
    "            # å¯¹äºæœªå‡ºç°çš„ç²¾çµï¼ˆä¸è¶³6åªæ—¶ï¼‰ï¼šhp_pctæŒ‰1.0è®¡ç®—ï¼ŒstrengthæŒ‰å·²å‡ºç°ç²¾çµçš„å‡å€¼è®¡ç®—\n",
    "            # ç»Ÿä¸€ä»pokemon_dbä¸­æŸ¥æ‰¾æ‰€æœ‰ç²¾çµçš„å±æ€§æ•°æ®\n",
    "            \n",
    "            # P1åŠ æƒå¼ºåº¦å€¼è®¡ç®—\n",
    "            p1_weighted_strength_sum = 0.0\n",
    "            p1_strength_list = []  # æ”¶é›†å·²å‡ºç°ç²¾çµçš„å¼ºåº¦å€¼ï¼Œç”¨äºè®¡ç®—å‡å€¼\n",
    "            for pokemon_name, hp_list in p1_pokemon_hp_dict.items():\n",
    "                if hp_list:  # å¦‚æœè¯¥ç²¾çµæœ‰hpè®°å½•\n",
    "                    # å–æœ€åä¸€æ¬¡å‡ºç°çš„hp_pct\n",
    "                    last_hp = hp_list[-1]\n",
    "                    # åªè®¡ç®—hp_pct > 0çš„ç²¾çµ\n",
    "                    if last_hp > 0:\n",
    "                        # ä»pokemon_dbä¸­æŸ¥æ‰¾è¯¥ç²¾çµçš„å±æ€§æ•°æ®\n",
    "                        pokemon_name_lower = pokemon_name.lower()\n",
    "                        if pokemon_name_lower in pokemon_db:\n",
    "                            pokemon_data = pokemon_db[pokemon_name_lower]\n",
    "                            # è®¡ç®—å¼ºåº¦å€¼\n",
    "                            strength = calculate_pokemon_strength(pokemon_data)\n",
    "                            # åŠ æƒå¼ºåº¦å€¼ = hp_pct * å¼ºåº¦å€¼\n",
    "                            p1_weighted_strength_sum += last_hp * strength\n",
    "                            # æ”¶é›†å¼ºåº¦å€¼ç”¨äºè®¡ç®—å‡å€¼\n",
    "                            p1_strength_list.append(strength)\n",
    "                        # å¦‚æœæ‰¾ä¸åˆ°å±æ€§æ•°æ®ï¼Œè·³è¿‡è¯¥ç²¾çµï¼ˆæ— æ³•è®¡ç®—å¼ºåº¦å€¼ï¼‰\n",
    "            \n",
    "            # å¦‚æœä¸è¶³6åªç²¾çµï¼Œå‰©ä½™ç²¾çµæŒ‰hp_pct=1.0ï¼Œstrength=å·²å‡ºç°ç²¾çµçš„å‡å€¼è®¡ç®—\n",
    "            p1_appeared_count = len(p1_pokemon_hp_dict)\n",
    "            p1_missing_count = 6 - p1_appeared_count\n",
    "            if p1_missing_count > 0 and len(p1_strength_list) > 0:\n",
    "                # è®¡ç®—å·²å‡ºç°ç²¾çµçš„å¼ºåº¦å€¼å‡å€¼\n",
    "                p1_avg_strength = np.mean(p1_strength_list)\n",
    "                # æœªå‡ºç°ç²¾çµçš„è´¡çŒ®ï¼šhp_pct=1.0 * å¹³å‡å¼ºåº¦å€¼\n",
    "                p1_weighted_strength_sum += p1_missing_count * 1.0 * p1_avg_strength\n",
    "            \n",
    "            # P2åŠ æƒå¼ºåº¦å€¼è®¡ç®—\n",
    "            p2_weighted_strength_sum = 0.0\n",
    "            p2_strength_list = []  # æ”¶é›†å·²å‡ºç°ç²¾çµçš„å¼ºåº¦å€¼ï¼Œç”¨äºè®¡ç®—å‡å€¼\n",
    "            for pokemon_name, hp_list in p2_pokemon_hp_dict.items():\n",
    "                if hp_list:  # å¦‚æœè¯¥ç²¾çµæœ‰hpè®°å½•\n",
    "                    # å–æœ€åä¸€æ¬¡å‡ºç°çš„hp_pct\n",
    "                    last_hp = hp_list[-1]\n",
    "                    # åªè®¡ç®—hp_pct > 0çš„ç²¾çµ\n",
    "                    if last_hp > 0:\n",
    "                        # ä»pokemon_dbä¸­æŸ¥æ‰¾è¯¥ç²¾çµçš„å±æ€§æ•°æ®\n",
    "                        pokemon_name_lower = pokemon_name.lower()\n",
    "                        if pokemon_name_lower in pokemon_db:\n",
    "                            pokemon_data = pokemon_db[pokemon_name_lower]\n",
    "                            # è®¡ç®—å¼ºåº¦å€¼\n",
    "                            strength = calculate_pokemon_strength(pokemon_data)\n",
    "                            # åŠ æƒå¼ºåº¦å€¼ = hp_pct * å¼ºåº¦å€¼\n",
    "                            p2_weighted_strength_sum += last_hp * strength\n",
    "                            # æ”¶é›†å¼ºåº¦å€¼ç”¨äºè®¡ç®—å‡å€¼\n",
    "                            p2_strength_list.append(strength)\n",
    "                        # å¦‚æœæ‰¾ä¸åˆ°å±æ€§æ•°æ®ï¼Œè·³è¿‡è¯¥ç²¾çµï¼ˆæ— æ³•è®¡ç®—å¼ºåº¦å€¼ï¼‰\n",
    "            \n",
    "            # å¦‚æœä¸è¶³6åªç²¾çµï¼Œå‰©ä½™ç²¾çµæŒ‰hp_pct=1.0ï¼Œstrength=å·²å‡ºç°ç²¾çµçš„å‡å€¼è®¡ç®—\n",
    "            p2_appeared_count = len(p2_pokemon_hp_dict)\n",
    "            p2_missing_count = 6 - p2_appeared_count\n",
    "            if p2_missing_count > 0 and len(p2_strength_list) > 0:\n",
    "                # è®¡ç®—å·²å‡ºç°ç²¾çµçš„å¼ºåº¦å€¼å‡å€¼\n",
    "                p2_avg_strength = np.mean(p2_strength_list)\n",
    "                # æœªå‡ºç°ç²¾çµçš„è´¡çŒ®ï¼šhp_pct=1.0 * å¹³å‡å¼ºåº¦å€¼\n",
    "                p2_weighted_strength_sum += p2_missing_count * 1.0 * p2_avg_strength\n",
    "            \n",
    "            features['p1_weighted_strength_sum'] = p1_weighted_strength_sum\n",
    "            features['p2_weighted_strength_sum'] = p2_weighted_strength_sum\n",
    "            # è®¡ç®—P1å’ŒP2åŠ æƒå¼ºåº¦å€¼çš„æ¯”å€¼\n",
    "            if p2_weighted_strength_sum > 0:\n",
    "                features['weighted_strength_ratio_30turns'] = p1_weighted_strength_sum / p2_weighted_strength_sum\n",
    "            else:\n",
    "                features['weighted_strength_ratio_30turns'] = 0.0  # é¿å…é™¤ä»¥0\n",
    "            \n",
    "            # ç»Ÿè®¡P1å’ŒP2çš„fntï¼ˆæ­»äº¡ï¼‰æ•°é‡\n",
    "            # ç»Ÿè®¡æ‰€æœ‰åœ¨æ—¶é—´çº¿ä¸­å‡ºç°è¿‡çš„ç²¾çµä¸­ï¼ŒçŠ¶æ€ä¸º'fnt'çš„æ•°é‡\n",
    "            p1_fnt_count = 0\n",
    "            for pokemon_name, status in p1_pokemon_status_dict.items():\n",
    "                if status == 'fnt':\n",
    "                    p1_fnt_count += 1\n",
    "            \n",
    "            p2_fnt_count = 0\n",
    "            for pokemon_name, status in p2_pokemon_status_dict.items():\n",
    "                if status == 'fnt':\n",
    "                    p2_fnt_count += 1\n",
    "            \n",
    "            # è®¡ç®—fntæ•°é‡æ¯”å€¼ï¼ˆp1_fnt_count / p2_fnt_countï¼‰\n",
    "            # ä½¿ç”¨å¹³æ»‘å¤„ç†é¿å…é™¤ä»¥0ï¼šp1_fnt_count / (p2_fnt_count + 1)\n",
    "            # è¿™æ ·å½“p2_fnt_countä¸º0æ—¶ï¼Œæ¯”å€¼ = p1_fnt_countï¼Œä»èƒ½åæ˜ P1çš„æŸå¤±æƒ…å†µ\n",
    "            features['fnt_count_ratio'] = p1_fnt_count / (p2_fnt_count + 1.0)\n",
    "            \n",
    "            # æ·»åŠ å·®å€¼ç‰¹å¾ä½œä¸ºè¡¥å……ï¼ˆåæ˜ ç»å¯¹ä¼˜åŠ¿ï¼‰\n",
    "            features['fnt_count_diff'] = p1_fnt_count - p2_fnt_count\n",
    "            \n",
    "            # ç¬¬30å›åˆç»„åˆèƒœç‡ç‰¹å¾ â­æ–°å¢\n",
    "            # æå–ç¬¬30å›åˆæ—¶åŒæ–¹å­˜æ´»çš„å®å¯æ¢¦ç»„åˆï¼Œå¹¶åŒ¹é…å†å²èƒœç‡\n",
    "            # turn30_combination_winrate = 1.0  # é»˜è®¤å€¼ï¼ˆä¸­æ€§ï¼Œè¡¨ç¤ºæ— å†å²æ•°æ®ï¼‰\n",
    "            # \n",
    "            # if False:#total_turns >= 30 and turn30_winrates:\n",
    "            #     # æˆªå–å‰30å›åˆæ•°æ®ï¼Œè·å–åŒæ–¹åœ¨ç¬¬30å›åˆæ—¶çš„å­˜æ´»ç²¾çµé›†åˆ\n",
    "            #     first_30_turns = timeline[:30]\n",
    "            #     (\n",
    "            #         p1_turn30_alive_raw,\n",
    "            #         p1_turn30_fnt_raw,\n",
    "            #         p2_turn30_alive_raw,\n",
    "            #     ) = extract_final_pokemon_status(first_30_turns)\n",
    "            #     \n",
    "            #     # ä»p1_teamä¸­æå–æœªæ­»äº¡çš„ç²¾çµåç§°ï¼Œç„¶åä¸p1_alive_pokemon_namesåˆå¹¶\n",
    "            #     # è¿™æ ·æ—¢åŒ…å«æœªå‡ºåœºçš„å­˜æ´»ç²¾çµï¼Œä¹ŸåŒ…å«æ—¶é—´çº¿ä¸­å‡ºç°çš„å­˜æ´»ç²¾çµ\n",
    "            #     p1_team = row.get('p1_team_details', [])\n",
    "            #     p1_team_names = {pokemon.get('name', '') for pokemon in p1_team \n",
    "            #                 if pokemon and pokemon.get('name', '') not in p1_turn30_fnt_raw}\n",
    "            #     p1_turn30_alive_raw = p1_team_names | p1_turn30_alive_raw\n",
    "            # \n",
    "            #     p1_turn30_alive = {name.lower() for name in p1_turn30_alive_raw}\n",
    "            #     p2_turn30_alive = {name.lower() for name in p2_turn30_alive_raw}\n",
    "            # \n",
    "            #     # å‰è¾¹å·²ç»æå–è¿‡äº†ï¼Œä¸è¦é‡å¤\n",
    "            #     # å¦‚æœåŒæ–¹éƒ½æœ‰å­˜æ´»å®å¯æ¢¦ï¼Œå°è¯•åŒ¹é…å†å²èƒœç‡\n",
    "            #     if p1_turn30_alive and p2_turn30_alive:\n",
    "            #         # åˆ›å»ºç»„åˆé”®ï¼šå°†å®å¯æ¢¦é›†åˆæ’åºåè¿æ¥\n",
    "            #         # æ ¼å¼ï¼šp1_pokemon1,p1_pokemon2|p2_pokemon1,p2_pokemon2\n",
    "            #         p1_sorted = ','.join(sorted(p1_turn30_alive))\n",
    "            #         p2_sorted = ','.join(sorted(p2_turn30_alive))\n",
    "            #         combination_key = f\"{p1_sorted}|{p2_sorted}\"\n",
    "            #         \n",
    "            #         # åœ¨èƒœç‡æ•°æ®åº“ä¸­æŸ¥æ‰¾åŒ¹é…çš„ç»„åˆ\n",
    "            #         if combination_key in turn30_winrates:\n",
    "            #             # æ‰¾åˆ°å®Œå…¨åŒ¹é…ï¼Œä½¿ç”¨å†å²èƒœç‡æ¯”å€¼\n",
    "            #             turn30_combination_winrate = turn30_winrates[combination_key].get('ratio', 1.0)\n",
    "            #         # å¦‚æœæ²¡æœ‰å®Œå…¨åŒ¹é…ï¼Œä¿æŒé»˜è®¤å€¼1.0ï¼ˆä¸­æ€§ï¼‰\n",
    "            # \n",
    "            # features['turn30_combination_winrate'] = turn30_combination_winrate\n",
    "\n",
    "            # ç‰¹å¾ï¼šç±»å‹å…‹åˆ¶æ•ˆæœå€æ•°ï¼ˆp1_avg, p2_avgï¼‰â­æ–°å¢\n",
    "            # æå–æˆ˜æ–—è¿‡ç¨‹ä¸­æ¯ä¸ªç©å®¶ä½¿ç”¨çš„æŠ€èƒ½é›†åˆ\n",
    "            battle_data = {'battle_timeline': timeline}\n",
    "            p1_moves, p2_moves = extract_moves(battle_data)\n",
    "            \n",
    "            # è®¡ç®—æ¯ä¸ªé˜Ÿä¼å¯¹å¯¹æ–¹é˜Ÿä¼çš„å¹³å‡ç±»å‹æ•ˆæœå€æ•°\n",
    "            p1_team_avg, p2_team_avg = type_multiplier(p1_moves, p2_moves)\n",
    "            features['p1_avg'] = p1_team_avg  # ç©å®¶1å¯¹ç©å®¶2çš„ç±»å‹æ•ˆæœå€æ•°\n",
    "            features['p2_avg'] = p2_team_avg  # ç©å®¶2å¯¹ç©å®¶1çš„ç±»å‹æ•ˆæœå€æ•°\n",
    "            \n",
    "            # ç‰¹å¾ï¼šå…ˆåˆ¶æŠ€èƒ½ä¼˜å…ˆçº§æ€»å’Œï¼ˆp1_num_priority_moves, p2_num_priority_movesï¼‰â­æ–°å¢\n",
    "            # ç»Ÿè®¡æ‰€æœ‰å…ˆåˆ¶æŠ€èƒ½çš„ä¼˜å…ˆçº§å€¼æ€»å’Œ\n",
    "            features['p1_num_priority_moves'] = count_priority_moves(p1_moves)  # ç©å®¶1å…ˆåˆ¶æŠ€èƒ½ä¼˜å…ˆçº§æ€»å’Œ\n",
    "            features['p2_num_priority_moves'] = count_priority_moves(p2_moves)  # ç©å®¶2å…ˆåˆ¶æŠ€èƒ½ä¼˜å…ˆçº§æ€»å’Œ\n",
    "\n",
    "            return features\n",
    "\n",
    "        # ä¸ºè®­ç»ƒå’Œæµ‹è¯•æ•°æ®æå–ç‰¹å¾\n",
    "        train_battle_features = []\n",
    "        for idx, row in self.train_data.iterrows(): # idx == 238\n",
    "            timeline = row.get('battle_timeline', [])\n",
    "            battle_features = analyze_battle_timeline(row, timeline, pokemon_db, None)  # self.turn30_winrates\n",
    "            train_battle_features.append(battle_features)\n",
    "\n",
    "        test_battle_features = []\n",
    "        for idx, row in self.test_data.iterrows():\n",
    "            timeline = row.get('battle_timeline', [])\n",
    "            battle_features = analyze_battle_timeline(row, timeline, pokemon_db, None)  # self.turn30_winrates\n",
    "            test_battle_features.append(battle_features)\n",
    "\n",
    "        self.train_dynamic_features = pd.DataFrame(train_battle_features)\n",
    "        self.test_dynamic_features = pd.DataFrame(test_battle_features)\n",
    "\n",
    "        print(f\"åŠ¨æ€ç‰¹å¾æå–å®Œæˆ: {self.train_dynamic_features.shape[1]} ä¸ªç‰¹å¾\")\n",
    "        return self.train_dynamic_features, self.test_dynamic_features\n",
    "\n",
    "    def create_interaction_features(self, df):\n",
    "        \"\"\"\n",
    "        åˆ›å»ºç‰¹å¾äº¤äº’é¡¹\n",
    "        \n",
    "        å…±4ä¸ªäº¤äº’ç‰¹å¾ï¼š\n",
    "        - hp_boost_interaction: HPä¼˜åŠ¿ Ã— Boostä¼˜åŠ¿ (è¡€é‡å’Œå±æ€§æå‡ååŒ)\n",
    "        - p1_effective_power: P1å¨åŠ› Ã— P1å‘½ä¸­ç‡ (æœ‰æ•ˆæ”»å‡»åŠ›)\n",
    "        - p2_effective_power: P2å¨åŠ› Ã— P2å‘½ä¸­ç‡ (æœ‰æ•ˆæ”»å‡»åŠ›)\n",
    "        - type_stats_interaction: ç±»å‹ä¼˜åŠ¿ Ã— å±æ€§ä¼˜åŠ¿ (å…‹åˆ¶å’Œå®åŠ›çš„ç»„åˆ)\n",
    "        \"\"\"\n",
    "        df_copy = df.copy()\n",
    "\n",
    "        # å…³é”®ç‰¹å¾ç»„åˆ\n",
    "        # HPä¼˜åŠ¿äº¤äº’ç‰¹å¾ï¼ˆå·²æ³¨é‡Š - ä¾èµ–æ•´ä½“HPç‰¹å¾ï¼‰\n",
    "        # if 'hp_advantage_end' in df_copy.columns and 'boost_advantage' in df_copy.columns:\n",
    "        #     df_copy['hp_boost_interaction'] = df_copy['hp_advantage_end'] * df_copy['boost_advantage']\n",
    "\n",
    "        if 'p1_avg_move_power' in df_copy.columns and 'p1_avg_accuracy' in df_copy.columns:\n",
    "            df_copy['p1_effective_power'] = df_copy['p1_avg_move_power'] * df_copy['p1_avg_accuracy']\n",
    "\n",
    "        if 'p2_avg_move_power' in df_copy.columns and 'p2_avg_accuracy' in df_copy.columns:\n",
    "            df_copy['p2_effective_power'] = df_copy['p2_avg_move_power'] * df_copy['p2_avg_accuracy']\n",
    "\n",
    "        if 'type_adv_mean' in df_copy.columns and 'total_stats_advantage' in df_copy.columns:\n",
    "            df_copy['type_stats_interaction'] = df_copy['type_adv_mean'] * df_copy['total_stats_advantage']\n",
    "\n",
    "        return df_copy\n",
    "\n",
    "    def combine_features(self):\n",
    "        \"\"\"åˆå¹¶æ‰€æœ‰ç‰¹å¾å¹¶åˆ›å»ºäº¤äº’é¡¹\"\"\"\n",
    "        print(\"\\n=== åˆå¹¶ç‰¹å¾å¹¶åˆ›å»ºäº¤äº’é¡¹ ===\")\n",
    "\n",
    "        # åˆå¹¶åŸºç¡€ç‰¹å¾\n",
    "        self.train_combined = pd.concat([\n",
    "            self.train_static_features.reset_index(drop=True),\n",
    "            self.train_dynamic_features.reset_index(drop=True)\n",
    "        ], axis=1)\n",
    "\n",
    "        self.test_combined = pd.concat([\n",
    "            self.test_static_features.reset_index(drop=True),\n",
    "            self.test_dynamic_features.reset_index(drop=True)\n",
    "        ], axis=1)\n",
    "\n",
    "        # åˆ›å»ºäº¤äº’ç‰¹å¾\n",
    "        self.train_combined = self.create_interaction_features(self.train_combined)\n",
    "        self.test_combined = self.create_interaction_features(self.test_combined)\n",
    "\n",
    "        # æ ¹æ®é…ç½®åˆ—è¡¨ç§»é™¤ç‰¹å¾\n",
    "        if self.features_to_remove:\n",
    "            print(f\"\\n=== ç§»é™¤é…ç½®çš„ç‰¹å¾ ({len(self.features_to_remove)}ä¸ª) ===\")\n",
    "            features_to_remove_actual = []\n",
    "            for feature in self.features_to_remove:\n",
    "                if feature in self.train_combined.columns:\n",
    "                    features_to_remove_actual.append(feature)\n",
    "                else:\n",
    "                    print(f\"  è­¦å‘Š: ç‰¹å¾ '{feature}' ä¸å­˜åœ¨ï¼Œè·³è¿‡ç§»é™¤\")\n",
    "            \n",
    "            if features_to_remove_actual:\n",
    "                self.train_combined = self.train_combined.drop(columns=features_to_remove_actual)\n",
    "                self.test_combined = self.test_combined.drop(columns=features_to_remove_actual)\n",
    "                print(f\"  âœ“ å·²ç§»é™¤ {len(features_to_remove_actual)} ä¸ªç‰¹å¾: {features_to_remove_actual}\")\n",
    "            else:\n",
    "                print(\"  âš ï¸ æ²¡æœ‰æ‰¾åˆ°è¦ç§»é™¤çš„ç‰¹å¾\")\n",
    "\n",
    "        # å¤„ç†ç¼ºå¤±å€¼\n",
    "        self.train_combined = self.train_combined.fillna(0)\n",
    "        self.test_combined = self.test_combined.fillna(0)\n",
    "\n",
    "        # ç¡®ä¿ä¸¤ä¸ªæ•°æ®é›†æœ‰ç›¸åŒçš„åˆ—\n",
    "        train_cols = set(self.train_combined.columns)\n",
    "        test_cols = set(self.test_combined.columns)\n",
    "\n",
    "        missing_in_test = train_cols - test_cols\n",
    "        missing_in_train = test_cols - train_cols\n",
    "\n",
    "        for col in missing_in_test:\n",
    "            self.test_combined[col] = 0\n",
    "        for col in missing_in_train:\n",
    "            self.train_combined[col] = 0\n",
    "\n",
    "        # å¯¹é½åˆ—é¡ºåº\n",
    "        self.test_combined = self.test_combined[self.train_combined.columns]\n",
    "\n",
    "        print(f\"ç‰¹å¾åˆå¹¶å®Œæˆ:\")\n",
    "        print(f\"è®­ç»ƒç‰¹å¾å½¢çŠ¶: {self.train_combined.shape}\")\n",
    "        print(f\"æµ‹è¯•ç‰¹å¾å½¢çŠ¶: {self.test_combined.shape}\")\n",
    "\n",
    "        return self.train_combined, self.test_combined\n",
    "\n",
    "    def select_features_rfecv(self, X_train, y_train, estimator=None, cv=5, scoring='accuracy', min_features_to_select=10, n_jobs=-1):\n",
    "        \"\"\"\n",
    "        ä½¿ç”¨RFECVï¼ˆé€’å½’ç‰¹å¾æ¶ˆé™¤ä¸äº¤å‰éªŒè¯ï¼‰è¿›è¡Œç‰¹å¾é€‰æ‹©\n",
    "        \n",
    "        å‚æ•°:\n",
    "        - X_train: è®­ç»ƒç‰¹å¾\n",
    "        - y_train: è®­ç»ƒæ ‡ç­¾\n",
    "        - estimator: ç”¨äºç‰¹å¾é€‰æ‹©çš„ä¼°è®¡å™¨ï¼ˆé»˜è®¤ä½¿ç”¨LogisticRegressionï¼‰\n",
    "        - cv: äº¤å‰éªŒè¯æŠ˜æ•°ï¼ˆé»˜è®¤5æŠ˜ï¼‰\n",
    "        - scoring: è¯„åˆ†æ ‡å‡†ï¼ˆé»˜è®¤'accuracy'ï¼‰\n",
    "        - min_features_to_select: æœ€å°‘ä¿ç•™çš„ç‰¹å¾æ•°ï¼ˆé»˜è®¤10ï¼‰\n",
    "        - n_jobs: å¹¶è¡Œä»»åŠ¡æ•°ï¼ˆé»˜è®¤-1ï¼Œä½¿ç”¨æ‰€æœ‰CPUï¼‰\n",
    "        \n",
    "        è¿”å›:\n",
    "        - X_train_selected: é€‰æ‹©åçš„è®­ç»ƒç‰¹å¾\n",
    "        - selected_features: é€‰ä¸­çš„ç‰¹å¾åç§°åˆ—è¡¨\n",
    "        - optimal_n_features: æœ€ä¼˜ç‰¹å¾æ•°é‡\n",
    "        \"\"\"\n",
    "        print(f\"\\n=== RFECVç‰¹å¾é€‰æ‹© ===\")\n",
    "        print(f\"åˆå§‹ç‰¹å¾æ•°é‡: {X_train.shape[1]}\")\n",
    "        print(f\"äº¤å‰éªŒè¯æŠ˜æ•°: {cv}\")\n",
    "        print(f\"æœ€å°‘ä¿ç•™ç‰¹å¾æ•°: {min_features_to_select}\")\n",
    "        print(\"æ­£åœ¨è®¡ç®—æœ€ä¼˜ç‰¹å¾æ•°é‡ï¼ˆè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰...\")\n",
    "        \n",
    "        # å¦‚æœæ²¡æœ‰æä¾›ä¼°è®¡å™¨ï¼Œä½¿ç”¨XGBoostä½œä¸ºé»˜è®¤ä¼°è®¡å™¨\n",
    "        # æ³¨æ„ï¼šRFECVä¼šå¤šæ¬¡è®­ç»ƒæ¨¡å‹ï¼ˆæ¯ä¸ªç‰¹å¾æ•°é‡éƒ½è¦è®­ç»ƒcvæ¬¡ï¼‰ï¼Œæ‰€ä»¥ä½¿ç”¨è½»é‡çº§å‚æ•°ä»¥åŠ å¿«é€Ÿåº¦\n",
    "        # ç‰¹å¾é€‰æ‹©çš„ç›®æ ‡æ˜¯æ‰¾åˆ°é‡è¦ç‰¹å¾ï¼Œä¸éœ€è¦æ¨¡å‹è¾¾åˆ°æœ€ä½³æ€§èƒ½\n",
    "        if estimator is None:\n",
    "            estimator = xgb.XGBClassifier(\n",
    "                n_estimators=100,  # å‡å°‘æ ‘æ•°é‡ï¼ŒåŠ å¿«ç‰¹å¾é€‰æ‹©é€Ÿåº¦ï¼ˆä»800é™åˆ°100ï¼‰\n",
    "                max_depth=6,  # ç¨å¾®é™ä½æ·±åº¦ï¼ŒåŠ å¿«è®­ç»ƒï¼ˆä»8é™åˆ°6ï¼‰\n",
    "                learning_rate=0.1,  # æé«˜å­¦ä¹ ç‡ï¼Œè¡¥å¿æ ‘æ•°é‡å‡å°‘ï¼ˆä»0.03æé«˜åˆ°0.1ï¼‰\n",
    "                subsample=0.8,  # ç¨å¾®é™ä½é‡‡æ ·ç‡ï¼ŒåŠ å¿«è®­ç»ƒï¼ˆä»0.85é™åˆ°0.8ï¼‰\n",
    "                colsample_bytree=0.8,  # ç¨å¾®é™ä½åˆ—é‡‡æ ·ç‡ï¼ˆä»0.85é™åˆ°0.8ï¼‰\n",
    "                min_child_weight=1,  # ç®€åŒ–å‚æ•°ï¼ˆä»2é™åˆ°1ï¼‰\n",
    "                gamma=0,  # ç®€åŒ–å‚æ•°ï¼ŒåŠ å¿«è®­ç»ƒï¼ˆä»0.05é™åˆ°0ï¼‰\n",
    "                reg_alpha=0.01,  # é™ä½æ­£åˆ™åŒ–ï¼ŒåŠ å¿«è®­ç»ƒï¼ˆä»0.1é™åˆ°0.01ï¼‰\n",
    "                reg_lambda=0.01,  # é™ä½æ­£åˆ™åŒ–ï¼ŒåŠ å¿«è®­ç»ƒï¼ˆä»0.1é™åˆ°0.01ï¼‰\n",
    "                random_state=42,\n",
    "                eval_metric='logloss',\n",
    "                n_jobs=n_jobs\n",
    "            )\n",
    "        \n",
    "        # åˆ›å»ºRFECVå¯¹è±¡\n",
    "        rfecv = RFECV(\n",
    "            estimator=estimator,\n",
    "            step=1,  # æ¯æ¬¡ç§»é™¤1ä¸ªç‰¹å¾\n",
    "            cv=cv,\n",
    "            scoring=scoring,\n",
    "            min_features_to_select=min_features_to_select,\n",
    "            n_jobs=n_jobs\n",
    "        )\n",
    "        \n",
    "        # æ‰§è¡Œç‰¹å¾é€‰æ‹©\n",
    "        rfecv.fit(X_train, y_train)\n",
    "        \n",
    "        # ä¿å­˜ç‰¹å¾é€‰æ‹©å™¨ä¾›åç»­ä½¿ç”¨\n",
    "        self.feature_selector = rfecv\n",
    "        \n",
    "        # è·å–é€‰ä¸­çš„ç‰¹å¾\n",
    "        selected_mask = rfecv.support_\n",
    "        selected_features = X_train.columns[selected_mask].tolist()\n",
    "        optimal_n_features = rfecv.n_features_\n",
    "        \n",
    "        # è½¬æ¢æ•°æ®\n",
    "        X_train_selected = rfecv.transform(X_train)\n",
    "        \n",
    "        # å¦‚æœè¾“å…¥æ˜¯DataFrameï¼Œå°†ç»“æœä¹Ÿè½¬æ¢ä¸ºDataFrameä»¥ä¿æŒä¸€è‡´æ€§\n",
    "        if isinstance(X_train, pd.DataFrame):\n",
    "            X_train_selected = pd.DataFrame(\n",
    "                X_train_selected,\n",
    "                columns=selected_features,\n",
    "                index=X_train.index\n",
    "            )\n",
    "        \n",
    "        # è·å–è¢«ç§»é™¤çš„ç‰¹å¾\n",
    "        all_features = X_train.columns.tolist()\n",
    "        removed_features = [feat for feat in all_features if feat not in selected_features]\n",
    "        \n",
    "        print(f\"âœ“ RFECVç‰¹å¾é€‰æ‹©å®Œæˆ\")\n",
    "        print(f\"  æœ€ä¼˜ç‰¹å¾æ•°é‡: {optimal_n_features}\")\n",
    "        print(f\"  é€‰ä¸­çš„ç‰¹å¾æ•°é‡: {len(selected_features)}\")\n",
    "        print(f\"  ç‰¹å¾å‡å°‘: {X_train.shape[1] - optimal_n_features} ä¸ª ({(1 - optimal_n_features/X_train.shape[1])*100:.1f}%)\")\n",
    "        \n",
    "        # æ‰“å°è¢«ç§»é™¤çš„ç‰¹å¾\n",
    "        if removed_features:\n",
    "            print(f\"\\nè¢«ç§»é™¤çš„ç‰¹å¾ ({len(removed_features)} ä¸ª):\")\n",
    "            # æŒ‰ç‰¹å¾åç§°æ’åºä»¥ä¾¿æŸ¥çœ‹\n",
    "            removed_features_sorted = sorted(removed_features)\n",
    "            # æ¯è¡Œæ˜¾ç¤º5ä¸ªç‰¹å¾ï¼Œä¾¿äºé˜…è¯»\n",
    "            for i in range(0, len(removed_features_sorted), 5):\n",
    "                features_line = removed_features_sorted[i:i+5]\n",
    "                print(f\"  {', '.join(features_line)}\")\n",
    "        else:\n",
    "            print(f\"\\næ²¡æœ‰ç‰¹å¾è¢«ç§»é™¤\")\n",
    "        \n",
    "        # æ˜¾ç¤ºäº¤å‰éªŒè¯å¾—åˆ†éšç‰¹å¾æ•°é‡çš„å˜åŒ–\n",
    "        print(f\"\\näº¤å‰éªŒè¯å¾—åˆ†éšç‰¹å¾æ•°é‡çš„å˜åŒ–:\")\n",
    "        print(f\"  æœ€é«˜å¾—åˆ†: {rfecv.cv_results_['mean_test_score'].max():.4f}\")\n",
    "        print(f\"  æœ€ä¼˜ç‰¹å¾æ•°æ—¶çš„å¾—åˆ†: {rfecv.cv_results_['mean_test_score'][rfecv.n_features_ - min_features_to_select]:.4f}\")\n",
    "        \n",
    "        return X_train_selected, selected_features, optimal_n_features\n",
    "\n",
    "    def save_misclassified_samples(self, y_true_indices, y_pred, y_true, model_name='best_model'):\n",
    "        \"\"\"\n",
    "        ä¿å­˜é¢„æµ‹é”™è¯¯çš„æ ·æœ¬åˆ°JSONæ–‡ä»¶\n",
    "        \n",
    "        åŠŸèƒ½ï¼š\n",
    "        - è¯†åˆ«éªŒè¯é›†ä¸­é¢„æµ‹é”™è¯¯çš„æ ·æœ¬\n",
    "        - ä¿å­˜å®Œæ•´çš„æˆ˜æ–—è®°å½•ï¼ˆåŒ…å«æ—¶é—´çº¿ã€é˜Ÿä¼ä¿¡æ¯ç­‰ï¼‰\n",
    "        - æ·»åŠ é¢„æµ‹ä¿¡æ¯æ ‡ç­¾ï¼ˆpredicted, actual, model, indexï¼‰\n",
    "        - ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯ï¼ˆå‡†ç¡®ç‡ã€å‡é˜³æ€§ã€å‡é˜´æ€§ç­‰ï¼‰\n",
    "        \n",
    "        è¾“å‡ºæ–‡ä»¶ï¼š\n",
    "        - misclassified_samples_{model_name}.json: é”™è¯¯æ ·æœ¬è¯¦æƒ…\n",
    "        - misclassified_stats_{model_name}.json: ç»Ÿè®¡ä¿¡æ¯\n",
    "        \"\"\"\n",
    "        print(f\"\\n=== ä¿å­˜{model_name}çš„é¢„æµ‹é”™è¯¯æ ·æœ¬ ===\")\n",
    "        \n",
    "        # æ‰¾å‡ºé¢„æµ‹é”™è¯¯çš„ç´¢å¼•ä½ç½®\n",
    "        misclassified_mask = y_pred != y_true.values\n",
    "        misclassified_indices = y_true_indices[misclassified_mask]\n",
    "        \n",
    "        if len(misclassified_indices) == 0:\n",
    "            print(\"æ²¡æœ‰é¢„æµ‹é”™è¯¯çš„æ ·æœ¬ï¼\")\n",
    "            return None, None\n",
    "        \n",
    "        print(f\"å‘ç° {len(misclassified_indices)} ä¸ªé¢„æµ‹é”™è¯¯çš„æ ·æœ¬\")\n",
    "        \n",
    "        # è·å–é”™è¯¯é¢„æµ‹çš„å€¼\n",
    "        y_pred_wrong = y_pred[misclassified_mask]\n",
    "        y_true_wrong = y_true.values[misclassified_mask]\n",
    "        \n",
    "        # ä»åŸå§‹è®­ç»ƒæ•°æ®ä¸­æå–é”™è¯¯æ ·æœ¬\n",
    "        misclassified_samples = []\n",
    "        for i, idx in enumerate(misclassified_indices):\n",
    "            sample = self.train_data.iloc[idx].to_dict()\n",
    "            \n",
    "            # æ·»åŠ é¢„æµ‹ä¿¡æ¯\n",
    "            sample['prediction_info'] = {\n",
    "                'predicted': int(y_pred_wrong[i]),\n",
    "                'actual': int(y_true_wrong[i]),\n",
    "                'model': model_name,\n",
    "                'original_index': int(idx)\n",
    "            }\n",
    "            \n",
    "            misclassified_samples.append(sample)\n",
    "        \n",
    "        # ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        output_file = f'misclassified/misclassified_samples_{model_name}_{timestamp}.json'\n",
    "        \n",
    "        # ä¿å­˜åˆ°JSONæ–‡ä»¶\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(misclassified_samples, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"é¢„æµ‹é”™è¯¯æ ·æœ¬å·²ä¿å­˜åˆ°: {output_file}\")\n",
    "        \n",
    "        # ä¿å­˜ç®€å•ç»Ÿè®¡ä¿¡æ¯\n",
    "        stats = {\n",
    "            'total_samples': len(y_true),\n",
    "            'misclassified_count': len(misclassified_indices),\n",
    "            'accuracy': 1 - (len(misclassified_indices) / len(y_true)),\n",
    "            'error_rate': len(misclassified_indices) / len(y_true),\n",
    "            'false_positive': int(((y_pred == 1) & (y_true == 0)).sum()),\n",
    "            'false_negative': int(((y_pred == 0) & (y_true == 1)).sum()),\n",
    "            'timestamp': timestamp,\n",
    "            'model_name': model_name\n",
    "        }\n",
    "        \n",
    "        stats_file = f'misclassified/misclassified_stats_{model_name}_{timestamp}.json'\n",
    "        with open(stats_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(stats, f, indent=2)\n",
    "        \n",
    "        print(f\"ç»Ÿè®¡ä¿¡æ¯å·²ä¿å­˜åˆ°: {stats_file}\")\n",
    "        print(f\"å‡†ç¡®ç‡: {stats['accuracy']:.4f}\")\n",
    "        print(f\"é”™è¯¯ç‡: {stats['error_rate']:.4f}\")\n",
    "        print(f\"å‡é˜³æ€§(é¢„æµ‹èµ¢ä½†å®é™…è¾“): {stats['false_positive']}\")\n",
    "        print(f\"å‡é˜´æ€§(é¢„æµ‹è¾“ä½†å®é™…èµ¢): {stats['false_negative']}\")\n",
    "        \n",
    "        return misclassified_samples, stats\n",
    "\n",
    "    # ========================================================================\n",
    "    # Optunaè¶…å‚æ•°ä¼˜åŒ–ç›¸å…³æ–¹æ³•\n",
    "    # ========================================================================\n",
    "\n",
    "    def optimize_xgboost_hyperparams(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        ä½¿ç”¨Optuna + MedianPrunerä¼˜åŒ–XGBoostè¶…å‚æ•°\n",
    "\n",
    "        å‚æ•°:\n",
    "        - X_train: è®­ç»ƒç‰¹å¾\n",
    "        - y_train: è®­ç»ƒæ ‡ç­¾\n",
    "\n",
    "        è¿”å›:\n",
    "        - best_params: æœ€ä¼˜è¶…å‚æ•°å­—å…¸\n",
    "        \"\"\"\n",
    "        print(f\"\\n=== XGBoostè¶…å‚æ•°ä¼˜åŒ– ===\")\n",
    "        print(f\"è¯•éªŒæ¬¡æ•°: {self.optuna_n_trials}\")\n",
    "        print(f\"äº¤å‰éªŒè¯æŠ˜æ•°: {self.optuna_cv_folds}\")\n",
    "        print(f\"è¶…æ—¶æ—¶é—´: {self.optuna_timeout}ç§’\")\n",
    "\n",
    "        # å®šä¹‰ç›®æ ‡å‡½æ•°ï¼šOptunaä¼šå¤šæ¬¡è°ƒç”¨æ­¤å‡½æ•°ï¼Œæ¯æ¬¡ä¼ å…¥ä¸åŒçš„trialå¯¹è±¡\n",
    "        def objective(trial):\n",
    "            \"\"\"\n",
    "            Optunaç›®æ ‡å‡½æ•°ï¼šè¯„ä¼°ä¸€ç»„è¶…å‚æ•°çš„æ€§èƒ½\n",
    "            \n",
    "            å‚æ•°:\n",
    "            - trial: Optunaçš„Trialå¯¹è±¡ï¼Œç”¨äºå»ºè®®è¶…å‚æ•°å€¼å’ŒæŠ¥å‘Šä¸­é—´ç»“æœ\n",
    "            \n",
    "            è¿”å›:\n",
    "            - äº¤å‰éªŒè¯çš„å¹³å‡å‡†ç¡®ç‡ï¼ˆOptunaä¼šæœ€å¤§åŒ–æ­¤å€¼ï¼‰\n",
    "            \"\"\"\n",
    "            # ========================================================================\n",
    "            # XGBoostè¶…å‚æ•°æœç´¢ç©ºé—´å®šä¹‰\n",
    "            # ========================================================================\n",
    "            # ä½¿ç”¨trial.suggest_*æ–¹æ³•å®šä¹‰æ¯ä¸ªè¶…å‚æ•°çš„æœç´¢èŒƒå›´\n",
    "            # Optunaä¼šæ ¹æ®å†å²è¯•éªŒç»“æœæ™ºèƒ½é€‰æ‹©ä¸‹ä¸€ä¸ªè¦å°è¯•çš„å‚æ•°ç»„åˆ\n",
    "            params = {\n",
    "                # æ ‘çš„æ•°é‡ï¼š200-1000ï¼Œæ­¥é•¿100ï¼ˆå³200, 300, 400, ..., 1000ï¼‰\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 200, 1000, step=100),\n",
    "                \n",
    "                # æ ‘çš„æœ€å¤§æ·±åº¦ï¼š4-12ï¼ˆæ§åˆ¶æ¨¡å‹å¤æ‚åº¦ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆï¼‰\n",
    "                'max_depth': trial.suggest_int('max_depth', 4, 12),\n",
    "                \n",
    "                # å­¦ä¹ ç‡ï¼š0.01-0.3ï¼Œå¯¹æ•°å°ºåº¦ï¼ˆlog=Trueè¡¨ç¤ºåœ¨å¯¹æ•°ç©ºé—´å‡åŒ€é‡‡æ ·ï¼‰\n",
    "                # è¾ƒå°çš„å­¦ä¹ ç‡é€šå¸¸éœ€è¦æ›´å¤šæ ‘ï¼Œä½†å¯èƒ½è·å¾—æ›´å¥½çš„æ³›åŒ–æ€§èƒ½\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "                \n",
    "                # è¡Œé‡‡æ ·æ¯”ä¾‹ï¼š0.6-1.0ï¼ˆæ¯æ£µæ ‘ä½¿ç”¨çš„è®­ç»ƒæ ·æœ¬æ¯”ä¾‹ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆï¼‰\n",
    "                'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "                \n",
    "                # åˆ—é‡‡æ ·æ¯”ä¾‹ï¼š0.6-1.0ï¼ˆæ¯æ£µæ ‘ä½¿ç”¨çš„ç‰¹å¾æ¯”ä¾‹ï¼Œå¢åŠ éšæœºæ€§ï¼‰\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "                \n",
    "                # å¶å­èŠ‚ç‚¹æœ€å°æ ·æœ¬æƒé‡å’Œï¼š1-10ï¼ˆæ§åˆ¶å¶å­èŠ‚ç‚¹åˆ†è£‚ï¼Œå€¼è¶Šå¤§è¶Šä¿å®ˆï¼‰\n",
    "                'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "                \n",
    "                # æœ€å°æŸå¤±å‡å°‘é‡ï¼š0-0.5ï¼ˆåˆ†è£‚æ‰€éœ€çš„æœ€å°å¢ç›Šï¼Œå€¼è¶Šå¤§è¶Šä¿å®ˆï¼‰\n",
    "                'gamma': trial.suggest_float('gamma', 0, 0.5),\n",
    "                \n",
    "                # L1æ­£åˆ™åŒ–ç³»æ•°ï¼š0.001-1.0ï¼Œå¯¹æ•°å°ºåº¦ï¼ˆæ§åˆ¶ç‰¹å¾é€‰æ‹©ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆï¼‰\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 0.001, 1.0, log=True),\n",
    "                \n",
    "                # L2æ­£åˆ™åŒ–ç³»æ•°ï¼š0.001-1.0ï¼Œå¯¹æ•°å°ºåº¦ï¼ˆæ§åˆ¶æƒé‡å¤§å°ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆï¼‰\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 0.001, 1.0, log=True),\n",
    "                \n",
    "                # å›ºå®šå‚æ•°ï¼ˆä¸å‚ä¸ä¼˜åŒ–ï¼‰\n",
    "                'random_state': 42,  # éšæœºç§å­ï¼Œä¿è¯å¯å¤ç°æ€§\n",
    "                'eval_metric': 'logloss',  # è¯„ä¼°æŒ‡æ ‡\n",
    "                'n_jobs': -1  # ä½¿ç”¨æ‰€æœ‰CPUæ ¸å¿ƒ\n",
    "            }\n",
    "\n",
    "            # ä½¿ç”¨å»ºè®®çš„è¶…å‚æ•°åˆ›å»ºXGBoostæ¨¡å‹\n",
    "            model = xgb.XGBClassifier(**params)\n",
    "\n",
    "            # ========================================================================\n",
    "            # äº¤å‰éªŒè¯è¯„ä¼°è¶…å‚æ•°æ€§èƒ½\n",
    "            # ========================================================================\n",
    "            # ä½¿ç”¨åˆ†å±‚KæŠ˜äº¤å‰éªŒè¯ï¼Œä¿è¯æ¯æŠ˜ä¸­å„ç±»åˆ«æ¯”ä¾‹ä¸€è‡´\n",
    "            cv = StratifiedKFold(n_splits=self.optuna_cv_folds, shuffle=True, random_state=42)\n",
    "            scores = []  # å­˜å‚¨æ¯æŠ˜çš„å‡†ç¡®ç‡\n",
    "\n",
    "            # éå†æ¯ä¸ªäº¤å‰éªŒè¯æŠ˜\n",
    "            for fold_idx, (train_idx, val_idx) in enumerate(cv.split(X_train, y_train)):\n",
    "                # å¤„ç†DataFrameå’Œnumpyæ•°ç»„ä¸¤ç§æ•°æ®æ ¼å¼\n",
    "                X_fold_train = X_train.iloc[train_idx] if hasattr(X_train, 'iloc') else X_train[train_idx]\n",
    "                y_fold_train = y_train.iloc[train_idx] if hasattr(y_train, 'iloc') else y_train[train_idx]\n",
    "                X_fold_val = X_train.iloc[val_idx] if hasattr(X_train, 'iloc') else X_train[val_idx]\n",
    "                y_fold_val = y_train.iloc[val_idx] if hasattr(y_train, 'iloc') else y_train[val_idx]\n",
    "\n",
    "                # åœ¨å½“å‰æŠ˜çš„è®­ç»ƒé›†ä¸Šè®­ç»ƒæ¨¡å‹\n",
    "                model.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "                # åœ¨éªŒè¯é›†ä¸Šé¢„æµ‹å¹¶è®¡ç®—å‡†ç¡®ç‡\n",
    "                y_pred = model.predict(X_fold_val)\n",
    "                fold_accuracy = accuracy_score(y_fold_val, y_pred)\n",
    "                scores.append(fold_accuracy)\n",
    "\n",
    "                # ========================================================================\n",
    "                # Pruningï¼ˆå‰ªæï¼‰æœºåˆ¶ï¼šæå‰ç»ˆæ­¢è¡¨ç°å·®çš„è¯•éªŒ\n",
    "                # ========================================================================\n",
    "                # æŠ¥å‘Šå½“å‰foldçš„ä¸­é—´ç»“æœï¼ˆå‡†ç¡®ç‡ï¼‰å’Œæ­¥æ•°ï¼ˆfoldç´¢å¼•ï¼‰\n",
    "                # MedianPrunerä¼šæ ¹æ®å·²å®Œæˆçš„è¯•éªŒçš„ä¸­ä½æ•°æ€§èƒ½å†³å®šæ˜¯å¦å‰ªæ\n",
    "                trial.report(fold_accuracy, fold_idx)\n",
    "\n",
    "                # æ£€æŸ¥æ˜¯å¦åº”è¯¥å‰ªæï¼šå¦‚æœå½“å‰è¯•éªŒè¡¨ç°æ˜æ˜¾ä½äºä¸­ä½æ•°ï¼Œæå‰ç»ˆæ­¢\n",
    "                # è¿™æ ·å¯ä»¥èŠ‚çœè®¡ç®—èµ„æºï¼Œå°†æ—¶é—´æŠ•å…¥åˆ°æ›´æœ‰å¸Œæœ›çš„å‚æ•°ç»„åˆä¸Š\n",
    "                if trial.should_prune():\n",
    "                    raise optuna.TrialPruned()  # æŠ›å‡ºå¼‚å¸¸ï¼Œç»ˆæ­¢å½“å‰è¯•éªŒ\n",
    "\n",
    "            # è¿”å›æ‰€æœ‰æŠ˜çš„å¹³å‡å‡†ç¡®ç‡ï¼ˆOptunaä¼šæœ€å¤§åŒ–æ­¤å€¼ï¼‰\n",
    "            return np.mean(scores)\n",
    "\n",
    "        # ========================================================================\n",
    "        # åˆ›å»ºMedianPrunerï¼ˆä¸­ä½æ•°å‰ªæå™¨ï¼‰\n",
    "        # ========================================================================\n",
    "        # MedianPrunerä¼šæå‰ç»ˆæ­¢è¡¨ç°ä½äºä¸­ä½æ•°çš„è¯•éªŒï¼ŒèŠ‚çœè®¡ç®—èµ„æº\n",
    "        # n_startup_trials: å‰Nä¸ªè¯•éªŒä¸è¿›è¡Œå‰ªæï¼ˆé¢„çƒ­æœŸï¼‰ï¼Œè®©Pruneræœ‰è¶³å¤Ÿæ•°æ®å»ºç«‹åŸºå‡†\n",
    "        # n_warmup_steps: æ¯ä¸ªè¯•éªŒçš„å‰Næ­¥ä¸å‰ªæï¼Œç»™æ¨¡å‹è¶³å¤Ÿçš„è®­ç»ƒæ—¶é—´\n",
    "        pruner = MedianPruner(\n",
    "            n_startup_trials=self.optuna_pruner_warmup,  # å‰5ä¸ªè¯•éªŒä¸å‰ªæ\n",
    "            n_warmup_steps=self.optuna_pruner_interval  # æ¯ä¸ªè¯•éªŒå‰1æ­¥ä¸å‰ªæ\n",
    "        )\n",
    "\n",
    "        # ========================================================================\n",
    "        # åˆ›å»ºOptuna Studyå¹¶å¼€å§‹ä¼˜åŒ–\n",
    "        # ========================================================================\n",
    "        # è®¾ç½®æ—¥å¿—çº§åˆ«ä¸ºWARNINGï¼Œå‡å°‘è¾“å‡ºä¿¡æ¯ï¼ˆåªæ˜¾ç¤ºè­¦å‘Šå’Œé”™è¯¯ï¼‰\n",
    "        optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "        \n",
    "        # åˆ›å»ºStudyå¯¹è±¡ï¼šç®¡ç†æ•´ä¸ªè¶…å‚æ•°ä¼˜åŒ–è¿‡ç¨‹\n",
    "        study = optuna.create_study(\n",
    "            direction='maximize',  # æœ€å¤§åŒ–ç›®æ ‡å‡½æ•°ï¼ˆå‡†ç¡®ç‡ï¼‰\n",
    "            pruner=pruner,  # ä½¿ç”¨MedianPrunerè¿›è¡Œæ—©æœŸå‰ªæ\n",
    "            study_name='xgboost_optimization'  # Studyåç§°ï¼Œç”¨äºæ ‡è¯†å’Œä¿å­˜\n",
    "        )\n",
    "\n",
    "        # å¼€å§‹ä¼˜åŒ–ï¼šOptunaä¼šæ™ºèƒ½åœ°é€‰æ‹©è¶…å‚æ•°ç»„åˆè¿›è¡Œè¯•éªŒ\n",
    "        # ä½¿ç”¨TPEï¼ˆTree-structured Parzen Estimatorï¼‰ç®—æ³•è¿›è¡Œè´å¶æ–¯ä¼˜åŒ–\n",
    "        study.optimize(\n",
    "            objective,  # ç›®æ ‡å‡½æ•°\n",
    "            n_trials=self.optuna_n_trials,  # æœ€å¤§è¯•éªŒæ¬¡æ•°ï¼ˆ50æ¬¡ï¼‰\n",
    "            timeout=self.optuna_timeout,  # è¶…æ—¶æ—¶é—´ï¼ˆ3600ç§’=1å°æ—¶ï¼‰\n",
    "            show_progress_bar=True  # æ˜¾ç¤ºè¿›åº¦æ¡\n",
    "        )\n",
    "\n",
    "        # ========================================================================\n",
    "        # ä¿å­˜ä¼˜åŒ–ç»“æœ\n",
    "        # ========================================================================\n",
    "        # ä¿å­˜Studyå¯¹è±¡å’Œæœ€ä¼˜å‚æ•°ï¼Œä¾›åç»­ä½¿ç”¨å’Œä¿å­˜åˆ°æ–‡ä»¶\n",
    "        self.optuna_studies['XGBoost'] = study\n",
    "        self.optuna_best_params['XGBoost'] = study.best_params\n",
    "\n",
    "        # ========================================================================\n",
    "        # æ‰“å°ä¼˜åŒ–ç»“æœæ‘˜è¦\n",
    "        # ========================================================================\n",
    "        print(f\"\\nâœ“ XGBoostä¼˜åŒ–å®Œæˆ\")\n",
    "        print(f\"  æœ€ä¼˜å‡†ç¡®ç‡: {study.best_value:.4f}\")  # æ‰€æœ‰è¯•éªŒä¸­çš„æœ€é«˜å‡†ç¡®ç‡\n",
    "        print(f\"  æœ€ä¼˜å‚æ•°:\")  # è¾¾åˆ°æœ€ä¼˜å‡†ç¡®ç‡çš„è¶…å‚æ•°ç»„åˆ\n",
    "        for key, value in study.best_params.items():\n",
    "            print(f\"    {key}: {value}\")\n",
    "        print(f\"  å®Œæˆè¯•éªŒ: {len(study.trials)}\")  # æˆåŠŸå®Œæˆçš„è¯•éªŒæ•°\n",
    "        # ç»Ÿè®¡è¢«å‰ªæçš„è¯•éªŒæ•°ï¼ˆæå‰ç»ˆæ­¢çš„è¯•éªŒï¼‰\n",
    "        print(f\"  å‰ªæè¯•éªŒ: {len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED])}\")\n",
    "\n",
    "        return study.best_params\n",
    "\n",
    "    def optimize_lightgbm_hyperparams(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        ä½¿ç”¨Optuna + MedianPrunerä¼˜åŒ–LightGBMè¶…å‚æ•°\n",
    "\n",
    "        å‚æ•°:\n",
    "        - X_train: è®­ç»ƒç‰¹å¾\n",
    "        - y_train: è®­ç»ƒæ ‡ç­¾\n",
    "\n",
    "        è¿”å›:\n",
    "        - best_params: æœ€ä¼˜è¶…å‚æ•°å­—å…¸\n",
    "        \"\"\"\n",
    "        print(f\"\\n=== LightGBMè¶…å‚æ•°ä¼˜åŒ– ===\")\n",
    "        print(f\"è¯•éªŒæ¬¡æ•°: {self.optuna_n_trials}\")\n",
    "        print(f\"äº¤å‰éªŒè¯æŠ˜æ•°: {self.optuna_cv_folds}\")\n",
    "        print(f\"è¶…æ—¶æ—¶é—´: {self.optuna_timeout}ç§’\")\n",
    "\n",
    "        # å®šä¹‰ç›®æ ‡å‡½æ•°ï¼šOptunaä¼šå¤šæ¬¡è°ƒç”¨æ­¤å‡½æ•°ï¼Œæ¯æ¬¡ä¼ å…¥ä¸åŒçš„trialå¯¹è±¡\n",
    "        def objective(trial):\n",
    "            \"\"\"\n",
    "            Optunaç›®æ ‡å‡½æ•°ï¼šè¯„ä¼°ä¸€ç»„è¶…å‚æ•°çš„æ€§èƒ½\n",
    "            \n",
    "            å‚æ•°:\n",
    "            - trial: Optunaçš„Trialå¯¹è±¡ï¼Œç”¨äºå»ºè®®è¶…å‚æ•°å€¼å’ŒæŠ¥å‘Šä¸­é—´ç»“æœ\n",
    "            \n",
    "            è¿”å›:\n",
    "            - äº¤å‰éªŒè¯çš„å¹³å‡å‡†ç¡®ç‡ï¼ˆOptunaä¼šæœ€å¤§åŒ–æ­¤å€¼ï¼‰\n",
    "            \"\"\"\n",
    "            # ========================================================================\n",
    "            # LightGBMè¶…å‚æ•°æœç´¢ç©ºé—´å®šä¹‰\n",
    "            # ========================================================================\n",
    "            # LightGBMç‰¹æœ‰çš„å‚æ•°ï¼šnum_leavesï¼ˆå¶å­èŠ‚ç‚¹æ•°ï¼‰å’Œmin_child_samplesï¼ˆå¶å­èŠ‚ç‚¹æœ€å°æ ·æœ¬æ•°ï¼‰\n",
    "            params = {\n",
    "                # æ ‘çš„æ•°é‡ï¼š200-1000ï¼Œæ­¥é•¿100\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 200, 1000, step=100),\n",
    "                \n",
    "                # æ ‘çš„æœ€å¤§æ·±åº¦ï¼š4-12\n",
    "                'max_depth': trial.suggest_int('max_depth', 4, 12),\n",
    "                \n",
    "                # å­¦ä¹ ç‡ï¼š0.01-0.3ï¼Œå¯¹æ•°å°ºåº¦\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "                \n",
    "                # å¶å­èŠ‚ç‚¹æ•°ï¼š20-100ï¼ˆLightGBMç‰¹æœ‰ï¼Œæ§åˆ¶æ¨¡å‹å¤æ‚åº¦ï¼‰\n",
    "                # æ³¨æ„ï¼šnum_leavesåº”å°äº2^max_depthï¼Œå¦åˆ™å¯èƒ½è¿‡æ‹Ÿåˆ\n",
    "                'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
    "                \n",
    "                # è¡Œé‡‡æ ·æ¯”ä¾‹ï¼š0.6-1.0\n",
    "                'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "                \n",
    "                # åˆ—é‡‡æ ·æ¯”ä¾‹ï¼š0.6-1.0\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "                \n",
    "                # å¶å­èŠ‚ç‚¹æœ€å°æ ·æœ¬æ•°ï¼š5-50ï¼ˆLightGBMç‰¹æœ‰ï¼Œæ§åˆ¶å¶å­èŠ‚ç‚¹åˆ†è£‚ï¼‰\n",
    "                'min_child_samples': trial.suggest_int('min_child_samples', 5, 50),\n",
    "                \n",
    "                # L1æ­£åˆ™åŒ–ç³»æ•°ï¼š0.001-1.0ï¼Œå¯¹æ•°å°ºåº¦\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 0.001, 1.0, log=True),\n",
    "                \n",
    "                # L2æ­£åˆ™åŒ–ç³»æ•°ï¼š0.001-1.0ï¼Œå¯¹æ•°å°ºåº¦\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 0.001, 1.0, log=True),\n",
    "                \n",
    "                # å›ºå®šå‚æ•°\n",
    "                'random_state': 42,\n",
    "                'verbose': -1,  # ä¸è¾“å‡ºè®­ç»ƒæ—¥å¿—\n",
    "                'n_jobs': -1  # ä½¿ç”¨æ‰€æœ‰CPUæ ¸å¿ƒ\n",
    "            }\n",
    "\n",
    "            # åˆ›å»ºæ¨¡å‹\n",
    "            model = lgb.LGBMClassifier(**params)\n",
    "\n",
    "            # äº¤å‰éªŒè¯\n",
    "            cv = StratifiedKFold(n_splits=self.optuna_cv_folds, shuffle=True, random_state=42)\n",
    "            scores = []\n",
    "\n",
    "            for fold_idx, (train_idx, val_idx) in enumerate(cv.split(X_train, y_train)):\n",
    "                X_fold_train = X_train.iloc[train_idx] if hasattr(X_train, 'iloc') else X_train[train_idx]\n",
    "                y_fold_train = y_train.iloc[train_idx] if hasattr(y_train, 'iloc') else y_train[train_idx]\n",
    "                X_fold_val = X_train.iloc[val_idx] if hasattr(X_train, 'iloc') else X_train[val_idx]\n",
    "                y_fold_val = y_train.iloc[val_idx] if hasattr(y_train, 'iloc') else y_train[val_idx]\n",
    "\n",
    "                # è®­ç»ƒæ¨¡å‹\n",
    "                model.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "                # é¢„æµ‹å¹¶è®¡ç®—å‡†ç¡®ç‡\n",
    "                y_pred = model.predict(X_fold_val)\n",
    "                fold_accuracy = accuracy_score(y_fold_val, y_pred)\n",
    "                scores.append(fold_accuracy)\n",
    "\n",
    "                # Pruning: æ¯ä¸ªfoldç»“æŸåæŠ¥å‘Šä¸­é—´ç»“æœ\n",
    "                trial.report(fold_accuracy, fold_idx)\n",
    "\n",
    "                # å¦‚æœtrialè¢«å‰ªæï¼Œæå‰ç»ˆæ­¢\n",
    "                if trial.should_prune():\n",
    "                    raise optuna.TrialPruned()\n",
    "\n",
    "            # è¿”å›å¹³å‡å‡†ç¡®ç‡\n",
    "            return np.mean(scores)\n",
    "\n",
    "        # åˆ›å»ºMedianPruner\n",
    "        pruner = MedianPruner(\n",
    "            n_startup_trials=self.optuna_pruner_warmup,\n",
    "            n_warmup_steps=self.optuna_pruner_interval\n",
    "        )\n",
    "\n",
    "        # åˆ›å»ºstudyå¹¶ä¼˜åŒ–\n",
    "        optuna.logging.set_verbosity(optuna.logging.WARNING)  # å‡å°‘æ—¥å¿—è¾“å‡º\n",
    "        study = optuna.create_study(\n",
    "            direction='maximize',\n",
    "            pruner=pruner,\n",
    "            study_name='lightgbm_optimization'\n",
    "        )\n",
    "\n",
    "        study.optimize(\n",
    "            objective,\n",
    "            n_trials=self.optuna_n_trials,\n",
    "            timeout=self.optuna_timeout,\n",
    "            show_progress_bar=True\n",
    "        )\n",
    "\n",
    "        # ä¿å­˜studyå’Œæœ€ä¼˜å‚æ•°\n",
    "        self.optuna_studies['LightGBM'] = study\n",
    "        self.optuna_best_params['LightGBM'] = study.best_params\n",
    "\n",
    "        # æ‰“å°ç»“æœ\n",
    "        print(f\"\\nâœ“ LightGBMä¼˜åŒ–å®Œæˆ\")\n",
    "        print(f\"  æœ€ä¼˜å‡†ç¡®ç‡: {study.best_value:.4f}\")\n",
    "        print(f\"  æœ€ä¼˜å‚æ•°:\")\n",
    "        for key, value in study.best_params.items():\n",
    "            print(f\"    {key}: {value}\")\n",
    "        print(f\"  å®Œæˆè¯•éªŒ: {len(study.trials)}\")\n",
    "        print(f\"  å‰ªæè¯•éªŒ: {len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED])}\")\n",
    "\n",
    "        return study.best_params\n",
    "\n",
    "    def optimize_catboost_hyperparams(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        ä½¿ç”¨Optuna + MedianPrunerä¼˜åŒ–CatBoostè¶…å‚æ•°\n",
    "\n",
    "        å‚æ•°:\n",
    "        - X_train: è®­ç»ƒç‰¹å¾\n",
    "        - y_train: è®­ç»ƒæ ‡ç­¾\n",
    "\n",
    "        è¿”å›:\n",
    "        - best_params: æœ€ä¼˜è¶…å‚æ•°å­—å…¸\n",
    "        \"\"\"\n",
    "        print(f\"\\n=== CatBoostè¶…å‚æ•°ä¼˜åŒ– ===\")\n",
    "        print(f\"è¯•éªŒæ¬¡æ•°: {self.optuna_n_trials}\")\n",
    "        print(f\"äº¤å‰éªŒè¯æŠ˜æ•°: {self.optuna_cv_folds}\")\n",
    "        print(f\"è¶…æ—¶æ—¶é—´: {self.optuna_timeout}ç§’\")\n",
    "\n",
    "        # å®šä¹‰ç›®æ ‡å‡½æ•°ï¼šOptunaä¼šå¤šæ¬¡è°ƒç”¨æ­¤å‡½æ•°ï¼Œæ¯æ¬¡ä¼ å…¥ä¸åŒçš„trialå¯¹è±¡\n",
    "        def objective(trial):\n",
    "            \"\"\"\n",
    "            Optunaç›®æ ‡å‡½æ•°ï¼šè¯„ä¼°ä¸€ç»„è¶…å‚æ•°çš„æ€§èƒ½\n",
    "            \n",
    "            å‚æ•°:\n",
    "            - trial: Optunaçš„Trialå¯¹è±¡ï¼Œç”¨äºå»ºè®®è¶…å‚æ•°å€¼å’ŒæŠ¥å‘Šä¸­é—´ç»“æœ\n",
    "            \n",
    "            è¿”å›:\n",
    "            - äº¤å‰éªŒè¯çš„å¹³å‡å‡†ç¡®ç‡ï¼ˆOptunaä¼šæœ€å¤§åŒ–æ­¤å€¼ï¼‰\n",
    "            \"\"\"\n",
    "            # ========================================================================\n",
    "            # CatBoostè¶…å‚æ•°æœç´¢ç©ºé—´å®šä¹‰\n",
    "            # ========================================================================\n",
    "            # CatBoostå‚æ•°å‘½åä¸å…¶ä»–åº“ç•¥æœ‰ä¸åŒï¼šiterationsï¼ˆè€Œén_estimatorsï¼‰ã€depthï¼ˆè€Œémax_depthï¼‰\n",
    "            # CatBoostå¯¹ç±»åˆ«ç‰¹å¾æœ‰è‡ªåŠ¨å¤„ç†èƒ½åŠ›ï¼Œé€šå¸¸ä¸éœ€è¦æ‰‹åŠ¨ç¼–ç \n",
    "            params = {\n",
    "                # è¿­ä»£æ¬¡æ•°ï¼š200-1000ï¼Œæ­¥é•¿100ï¼ˆCatBoostä½¿ç”¨iterationsè€Œén_estimatorsï¼‰\n",
    "                'iterations': trial.suggest_int('iterations', 200, 1000, step=100),\n",
    "                \n",
    "                # æ ‘çš„æœ€å¤§æ·±åº¦ï¼š4-10ï¼ˆCatBoostä½¿ç”¨depthè€Œémax_depthï¼‰\n",
    "                'depth': trial.suggest_int('depth', 4, 10),\n",
    "                \n",
    "                # å­¦ä¹ ç‡ï¼š0.01-0.3ï¼Œå¯¹æ•°å°ºåº¦\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "                \n",
    "                # L2æ­£åˆ™åŒ–ç³»æ•°ï¼š1-10ï¼ˆCatBoostä½¿ç”¨l2_leaf_regï¼Œæ•´æ•°è€Œéæµ®ç‚¹æ•°ï¼‰\n",
    "                # æ§åˆ¶å¶å­èŠ‚ç‚¹å€¼çš„L2æ­£åˆ™åŒ–ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ\n",
    "                'l2_leaf_reg': trial.suggest_int('l2_leaf_reg', 1, 10),\n",
    "                \n",
    "                # å›ºå®šå‚æ•°\n",
    "                'random_seed': 42,  # éšæœºç§å­ï¼ˆCatBoostä½¿ç”¨random_seedè€Œérandom_stateï¼‰\n",
    "                'verbose': False,  # ä¸è¾“å‡ºè®­ç»ƒæ—¥å¿—\n",
    "                'thread_count': -1  # ä½¿ç”¨æ‰€æœ‰CPUæ ¸å¿ƒï¼ˆCatBoostä½¿ç”¨thread_countè€Œén_jobsï¼‰\n",
    "            }\n",
    "\n",
    "            # åˆ›å»ºæ¨¡å‹\n",
    "            model = CatBoostClassifier(**params)\n",
    "\n",
    "            # äº¤å‰éªŒè¯\n",
    "            cv = StratifiedKFold(n_splits=self.optuna_cv_folds, shuffle=True, random_state=42)\n",
    "            scores = []\n",
    "\n",
    "            for fold_idx, (train_idx, val_idx) in enumerate(cv.split(X_train, y_train)):\n",
    "                X_fold_train = X_train.iloc[train_idx] if hasattr(X_train, 'iloc') else X_train[train_idx]\n",
    "                y_fold_train = y_train.iloc[train_idx] if hasattr(y_train, 'iloc') else y_train[train_idx]\n",
    "                X_fold_val = X_train.iloc[val_idx] if hasattr(X_train, 'iloc') else X_train[val_idx]\n",
    "                y_fold_val = y_train.iloc[val_idx] if hasattr(y_train, 'iloc') else y_train[val_idx]\n",
    "\n",
    "                # è®­ç»ƒæ¨¡å‹\n",
    "                model.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "                # é¢„æµ‹å¹¶è®¡ç®—å‡†ç¡®ç‡\n",
    "                y_pred = model.predict(X_fold_val)\n",
    "                fold_accuracy = accuracy_score(y_fold_val, y_pred)\n",
    "                scores.append(fold_accuracy)\n",
    "\n",
    "                # Pruning: æ¯ä¸ªfoldç»“æŸåæŠ¥å‘Šä¸­é—´ç»“æœ\n",
    "                trial.report(fold_accuracy, fold_idx)\n",
    "\n",
    "                # å¦‚æœtrialè¢«å‰ªæï¼Œæå‰ç»ˆæ­¢\n",
    "                if trial.should_prune():\n",
    "                    raise optuna.TrialPruned()\n",
    "\n",
    "            # è¿”å›å¹³å‡å‡†ç¡®ç‡\n",
    "            return np.mean(scores)\n",
    "\n",
    "        # åˆ›å»ºMedianPruner\n",
    "        pruner = MedianPruner(\n",
    "            n_startup_trials=self.optuna_pruner_warmup,\n",
    "            n_warmup_steps=self.optuna_pruner_interval\n",
    "        )\n",
    "\n",
    "        # åˆ›å»ºstudyå¹¶ä¼˜åŒ–\n",
    "        optuna.logging.set_verbosity(optuna.logging.WARNING)  # å‡å°‘æ—¥å¿—è¾“å‡º\n",
    "        study = optuna.create_study(\n",
    "            direction='maximize',\n",
    "            pruner=pruner,\n",
    "            study_name='catboost_optimization'\n",
    "        )\n",
    "\n",
    "        study.optimize(\n",
    "            objective,\n",
    "            n_trials=self.optuna_n_trials,\n",
    "            timeout=self.optuna_timeout,\n",
    "            show_progress_bar=True\n",
    "        )\n",
    "\n",
    "        # ä¿å­˜studyå’Œæœ€ä¼˜å‚æ•°\n",
    "        self.optuna_studies['CatBoost'] = study\n",
    "        self.optuna_best_params['CatBoost'] = study.best_params\n",
    "\n",
    "        # æ‰“å°ç»“æœ\n",
    "        print(f\"\\nâœ“ CatBoostä¼˜åŒ–å®Œæˆ\")\n",
    "        print(f\"  æœ€ä¼˜å‡†ç¡®ç‡: {study.best_value:.4f}\")\n",
    "        print(f\"  æœ€ä¼˜å‚æ•°:\")\n",
    "        for key, value in study.best_params.items():\n",
    "            print(f\"    {key}: {value}\")\n",
    "        print(f\"  å®Œæˆè¯•éªŒ: {len(study.trials)}\")\n",
    "        print(f\"  å‰ªæè¯•éªŒ: {len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED])}\")\n",
    "\n",
    "        return study.best_params\n",
    "\n",
    "    def save_optuna_results(self, output_dir='optuna_results'):\n",
    "        \"\"\"\n",
    "        ä¿å­˜Optunaä¼˜åŒ–ç»“æœåˆ°æ–‡ä»¶\n",
    "\n",
    "        å‚æ•°:\n",
    "        - output_dir: è¾“å‡ºç›®å½•è·¯å¾„ï¼ˆé»˜è®¤'optuna_results'ï¼‰\n",
    "\n",
    "        åŠŸèƒ½:\n",
    "        - ä¿å­˜æœ€ä¼˜å‚æ•°åˆ°JSONæ–‡ä»¶ï¼ˆåŒ…å«æ¨¡å‹åã€æœ€ä¼˜å€¼ã€æœ€ä¼˜å‚æ•°ã€è¯•éªŒç»Ÿè®¡ç­‰ï¼‰\n",
    "        - ä¿å­˜ä¼˜åŒ–å†å²åˆ°CSVæ–‡ä»¶ï¼ˆåŒ…å«æ‰€æœ‰è¯•éªŒçš„è¯¦ç»†è®°å½•ï¼‰\n",
    "        - æ‰“å°ç»Ÿè®¡ä¿¡æ¯ï¼ˆæ€»è¯•éªŒæ•°ã€å®Œæˆæ•°ã€å‰ªææ•°ã€å¤±è´¥æ•°ç­‰ï¼‰\n",
    "\n",
    "        è¾“å‡ºæ–‡ä»¶:\n",
    "        - {model_name}_best_params_{timestamp}.json: æœ€ä¼˜å‚æ•°JSONæ–‡ä»¶\n",
    "        - {model_name}_optimization_history_{timestamp}.csv: ä¼˜åŒ–å†å²CSVæ–‡ä»¶\n",
    "        \"\"\"\n",
    "        # æ£€æŸ¥æ˜¯å¦æœ‰ä¼˜åŒ–ç»“æœå¯ä¿å­˜\n",
    "        if not self.optuna_studies:\n",
    "            print(\"âš ï¸ æ²¡æœ‰Optunaä¼˜åŒ–ç»“æœå¯ä¿å­˜\")\n",
    "            return\n",
    "\n",
    "        # åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "        # ç”Ÿæˆæ—¶é—´æˆ³ï¼Œç”¨äºæ–‡ä»¶å\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "        print(f\"\\n=== ä¿å­˜Optunaä¼˜åŒ–ç»“æœ ===\")\n",
    "        print(f\"è¾“å‡ºç›®å½•: {output_dir}\")\n",
    "\n",
    "        # éå†æ¯ä¸ªæ¨¡å‹çš„ä¼˜åŒ–ç»“æœ\n",
    "        for model_name, study in self.optuna_studies.items():\n",
    "            # ========================================================================\n",
    "            # ä¿å­˜æœ€ä¼˜å‚æ•°åˆ°JSONæ–‡ä»¶\n",
    "            # ========================================================================\n",
    "            best_params_file = os.path.join(output_dir, f'{model_name}_best_params_{timestamp}.json')\n",
    "            with open(best_params_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump({\n",
    "                    'model': model_name,  # æ¨¡å‹åç§°\n",
    "                    'best_value': study.best_value,  # æœ€ä¼˜ç›®æ ‡å‡½æ•°å€¼ï¼ˆå‡†ç¡®ç‡ï¼‰\n",
    "                    'best_params': study.best_params,  # æœ€ä¼˜è¶…å‚æ•°ç»„åˆ\n",
    "                    'n_trials': len(study.trials),  # æ€»è¯•éªŒæ•°\n",
    "                    'n_pruned': len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]),  # è¢«å‰ªæçš„è¯•éªŒæ•°\n",
    "                    'timestamp': timestamp  # æ—¶é—´æˆ³\n",
    "                }, f, indent=2, ensure_ascii=False)\n",
    "            print(f\"âœ“ {model_name} æœ€ä¼˜å‚æ•°å·²ä¿å­˜: {best_params_file}\")\n",
    "\n",
    "            # ========================================================================\n",
    "            # ä¿å­˜ä¼˜åŒ–å†å²åˆ°CSVæ–‡ä»¶\n",
    "            # ========================================================================\n",
    "            # trials_dataframe()è¿”å›åŒ…å«æ‰€æœ‰è¯•éªŒä¿¡æ¯çš„DataFrame\n",
    "            # åŒ…æ‹¬ï¼šå‚æ•°å€¼ã€ç›®æ ‡å‡½æ•°å€¼ã€è¯•éªŒçŠ¶æ€ã€è€—æ—¶ç­‰\n",
    "            trials_df = study.trials_dataframe()\n",
    "            history_file = os.path.join(output_dir, f'{model_name}_optimization_history_{timestamp}.csv')\n",
    "            trials_df.to_csv(history_file, index=False)\n",
    "            print(f\"âœ“ {model_name} ä¼˜åŒ–å†å²å·²ä¿å­˜: {history_file}\")\n",
    "\n",
    "            # ========================================================================\n",
    "            # æ‰“å°ç»Ÿè®¡ä¿¡æ¯\n",
    "            # ========================================================================\n",
    "            print(f\"\\n{model_name} ä¼˜åŒ–ç»Ÿè®¡:\")\n",
    "            print(f\"  æ€»è¯•éªŒæ•°: {len(study.trials)}\")  # æ‰€æœ‰è¯•éªŒï¼ˆåŒ…æ‹¬å®Œæˆã€å‰ªæã€å¤±è´¥ï¼‰\n",
    "            # æˆåŠŸå®Œæˆçš„è¯•éªŒæ•°\n",
    "            print(f\"  å®Œæˆè¯•éªŒ: {len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])}\")\n",
    "            # è¢«å‰ªæï¼ˆæå‰ç»ˆæ­¢ï¼‰çš„è¯•éªŒæ•°\n",
    "            print(f\"  å‰ªæè¯•éªŒ: {len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED])}\")\n",
    "            # å¤±è´¥çš„è¯•éªŒæ•°ï¼ˆå‡ºç°å¼‚å¸¸ï¼‰\n",
    "            print(f\"  å¤±è´¥è¯•éªŒ: {len([t for t in study.trials if t.state == optuna.trial.TrialState.FAIL])}\")\n",
    "            print(f\"  æœ€ä¼˜å‡†ç¡®ç‡: {study.best_value:.4f}\")  # æ‰€æœ‰è¯•éªŒä¸­çš„æœ€é«˜å‡†ç¡®ç‡\n",
    "            print(f\"  æœ€ä¼˜å‚æ•°: {study.best_params}\")  # è¾¾åˆ°æœ€ä¼˜å‡†ç¡®ç‡çš„å‚æ•°ç»„åˆ\n",
    "\n",
    "        print(f\"\\nâœ“ æ‰€æœ‰Optunaç»“æœå·²ä¿å­˜åˆ° {output_dir}\")\n",
    "\n",
    "    def train_models(self):\n",
    "        \"\"\"\n",
    "        è®­ç»ƒå¤šä¸ªæ¨¡å‹å¹¶ä½¿ç”¨Stackingé›†æˆ\n",
    "\n",
    "        æ¨¡å‹é…ç½®ï¼š\n",
    "        - RandomForest: 800æ£µæ ‘, max_depth=25\n",
    "        - XGBoost: 800æ£µæ ‘, learning_rate=0.03, å¸¦L1/L2æ­£åˆ™åŒ–\n",
    "        - LightGBM: 800æ£µæ ‘, num_leaves=50, å¸¦æ­£åˆ™åŒ–\n",
    "        - CatBoost: 800è¿­ä»£, depth=9\n",
    "        - GradientBoosting: 500æ£µæ ‘, max_depth=8\n",
    "\n",
    "        é›†æˆç­–ç•¥ï¼š\n",
    "        - Stacking: ä½¿ç”¨XGBoost+LightGBM+CatBoost, å…ƒå­¦ä¹ å™¨ä¸ºLogisticRegression\n",
    "        - Voting: ä½¿ç”¨æ‰€æœ‰5ä¸ªåŸºç¡€æ¨¡å‹, soft voting\n",
    "\n",
    "        é”™è¯¯æ ·æœ¬åˆ†æï¼š\n",
    "        - è‡ªåŠ¨ä¿å­˜æœ€ä½³æ¨¡å‹(Stackingæˆ–Voting)çš„é¢„æµ‹é”™è¯¯æ ·æœ¬\n",
    "        - å¯é€‰ï¼šä¿å­˜å„åŸºç¡€æ¨¡å‹çš„é”™è¯¯æ ·æœ¬ç”¨äºå¯¹æ¯”\n",
    "        \"\"\"\n",
    "        print(\"\\n=== æ¨¡å‹è®­ç»ƒ(Stackingé›†æˆ) ===\")\n",
    "\n",
    "        # å‡†å¤‡æ•°æ®\n",
    "        X = self.train_combined\n",
    "        y = self.train_data['player_won']\n",
    "\n",
    "        # ä½¿ç”¨é€‰å®šçš„XGBoostå‚æ•°å¯¹å…¨éƒ¨æœ‰æ ‡ç­¾æ•°æ®è¿›è¡Œ4æŠ˜äº¤å‰éªŒè¯è¯„ä¼°\n",
    "        xgb_cv_params = dict(\n",
    "            n_estimators=800,\n",
    "            max_depth=8,\n",
    "            learning_rate=0.03,\n",
    "            subsample=0.85,\n",
    "            colsample_bytree=0.85,\n",
    "            min_child_weight=2,\n",
    "            gamma=0.05,\n",
    "            reg_alpha=0.1,\n",
    "            reg_lambda=0.1,\n",
    "            random_state=42,\n",
    "            eval_metric='logloss',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        print(\"\\næ‰§è¡ŒXGBoost 4æŠ˜äº¤å‰éªŒè¯è¯„ä¼°ï¼ˆå…¨éƒ¨æœ‰æ ‡ç­¾æ ·æœ¬ï¼‰...\")\n",
    "        xgb_cv_model = xgb.XGBClassifier(**xgb_cv_params)\n",
    "        xgb_cv_splitter = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
    "        xgb_cv_scores = cross_val_score(\n",
    "            xgb_cv_model,\n",
    "            X,\n",
    "            y,\n",
    "            cv=xgb_cv_splitter,\n",
    "            scoring='accuracy',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        print(f\"XGBoost 4æŠ˜äº¤å‰éªŒè¯å‡†ç¡®ç‡: {xgb_cv_scores.mean():.4f} Â± {xgb_cv_scores.std():.4f}\")\n",
    "\n",
    "        # æ•°æ®åˆ†å‰² - ä¿å­˜éªŒè¯é›†ç´¢å¼•ç”¨äºåç»­é”™è¯¯åˆ†æ\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X, y, test_size=self.validation_split, random_state=42, stratify=y\n",
    "        )\n",
    "\n",
    "        # ä¿å­˜éªŒè¯é›†æ•°æ®ä¾›åç»­åˆ†æä½¿ç”¨\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "\n",
    "        # ä¿å­˜éªŒè¯é›†çš„åŸå§‹ç´¢å¼•\n",
    "        val_indices = y_val.index.to_numpy()\n",
    "\n",
    "        # ç‰¹å¾é€‰æ‹©(å¯é€‰,ä¿ç•™é‡è¦ç‰¹å¾)\n",
    "        # é€‰é¡¹1: ä½¿ç”¨äº’ä¿¡æ¯ç‰¹å¾é€‰æ‹©\n",
    "        # X_train_selected, selected_features = self.select_features(X_train, y_train, k=80)\n",
    "        # X_val_selected = self.feature_selector.transform(X_val)\n",
    "\n",
    "        # é€‰é¡¹2: ä½¿ç”¨RFECVç‰¹å¾é€‰æ‹©ï¼ˆæ¨èï¼Œè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜ç‰¹å¾æ•°é‡ï¼‰\n",
    "        use_rfecv = False  # è®¾ç½®ä¸ºTrueå¯ç”¨RFECVç‰¹å¾é€‰æ‹©\n",
    "        if use_rfecv:\n",
    "            X_train_selected, selected_features, optimal_n = self.select_features_rfecv(\n",
    "                X_train, y_train,\n",
    "                estimator=None,  # ä½¿ç”¨é»˜è®¤LogisticRegressionï¼Œä¹Ÿå¯ä»¥ä¼ å…¥å…¶ä»–ä¼°è®¡å™¨å¦‚RandomForestClassifier(n_estimators=100)\n",
    "                cv=4,  # 5æŠ˜äº¤å‰éªŒè¯\n",
    "                scoring='accuracy',  # è¯„åˆ†æ ‡å‡†\n",
    "                min_features_to_select=20,  # æœ€å°‘ä¿ç•™20ä¸ªç‰¹å¾\n",
    "                n_jobs=-1  # ä½¿ç”¨æ‰€æœ‰CPUæ ¸å¿ƒ\n",
    "            )\n",
    "            X_val_selected = self.feature_selector.transform(X_val)\n",
    "            # ä½¿ç”¨é€‰æ‹©åçš„ç‰¹å¾\n",
    "            X_train = X_train_selected\n",
    "            X_val = X_val_selected\n",
    "            print(f\"\\nä½¿ç”¨RFECVé€‰æ‹©åçš„ç‰¹å¾è¿›è¡Œæ¨¡å‹è®­ç»ƒ\")\n",
    "            print(f\"è®­ç»ƒç‰¹å¾å½¢çŠ¶: {X_train.shape}, éªŒè¯ç‰¹å¾å½¢çŠ¶: {X_val.shape}\")\n",
    "\n",
    "        # ========================================================================\n",
    "        # Optunaè¶…å‚æ•°ä¼˜åŒ–æµç¨‹ï¼ˆå¯é€‰ï¼‰\n",
    "        # ========================================================================\n",
    "        # å¦‚æœå¯ç”¨Optunaä¼˜åŒ–ï¼Œä¼šåœ¨è®­ç»ƒæ¨¡å‹ä¹‹å‰å…ˆè¿›è¡Œè¶…å‚æ•°æœç´¢\n",
    "        # ä¼˜åŒ–è¿‡ç¨‹å¯èƒ½è€—æ—¶è¾ƒé•¿ï¼ˆæ¯ä¸ªæ¨¡å‹å¯èƒ½éœ€è¦æ•°å°æ—¶ï¼‰ï¼Œä½†é€šå¸¸èƒ½æå‡æ¨¡å‹æ€§èƒ½\n",
    "        # ========================================================================\n",
    "        xgb_best_params = None  # XGBoostæœ€ä¼˜å‚æ•°ï¼ˆå¦‚æœè¿›è¡Œäº†ä¼˜åŒ–ï¼‰\n",
    "        lgb_best_params = None   # LightGBMæœ€ä¼˜å‚æ•°ï¼ˆå¦‚æœè¿›è¡Œäº†ä¼˜åŒ–ï¼‰\n",
    "        cat_best_params = None  # CatBoostæœ€ä¼˜å‚æ•°ï¼ˆå¦‚æœè¿›è¡Œäº†ä¼˜åŒ–ï¼‰\n",
    "\n",
    "        if self.use_optuna_tuning:\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(\"=== å¼€å§‹Optunaè¶…å‚æ•°ä¼˜åŒ– ===\")\n",
    "            print(f\"{'='*80}\")\n",
    "            print(f\"ä¼˜åŒ–é…ç½®:\")\n",
    "            print(f\"  - æ¯ä¸ªæ¨¡å‹è¯•éªŒæ¬¡æ•°: {self.optuna_n_trials}\")  # é»˜è®¤50æ¬¡\n",
    "            print(f\"  - äº¤å‰éªŒè¯æŠ˜æ•°: {self.optuna_cv_folds}\")  # é»˜è®¤3æŠ˜\n",
    "            print(f\"  - å•ä¸ªæ¨¡å‹è¶…æ—¶: {self.optuna_timeout}ç§’\")  # é»˜è®¤3600ç§’ï¼ˆ1å°æ—¶ï¼‰\n",
    "            print(f\"  - Pruneré¢„çƒ­æ­¥æ•°: {self.optuna_pruner_warmup}\")  # é»˜è®¤å‰5ä¸ªè¯•éªŒä¸å‰ªæ\n",
    "\n",
    "            # ä¼˜åŒ–XGBoostè¶…å‚æ•°\n",
    "            # ä½¿ç”¨TPEç®—æ³•å’ŒMedianPrunerè¿›è¡Œæ™ºèƒ½æœç´¢ï¼Œè¿”å›æœ€ä¼˜å‚æ•°ç»„åˆ\n",
    "            xgb_best_params = self.optimize_xgboost_hyperparams(X_train, y_train)\n",
    "\n",
    "            # ä¼˜åŒ–LightGBMè¶…å‚æ•°\n",
    "            # æœç´¢ç©ºé—´åŒ…æ‹¬num_leavesã€min_child_samplesç­‰LightGBMç‰¹æœ‰å‚æ•°\n",
    "            lgb_best_params = self.optimize_lightgbm_hyperparams(X_train, y_train)\n",
    "\n",
    "            # ä¼˜åŒ–CatBoostè¶…å‚æ•°\n",
    "            # æœç´¢ç©ºé—´åŒ…æ‹¬iterationsã€depthã€l2_leaf_regç­‰CatBoostå‚æ•°\n",
    "            cat_best_params = self.optimize_catboost_hyperparams(X_train, y_train)\n",
    "\n",
    "            # ä¿å­˜Optunaä¼˜åŒ–ç»“æœåˆ°æ–‡ä»¶\n",
    "            # åŒ…æ‹¬æœ€ä¼˜å‚æ•°JSONæ–‡ä»¶å’Œä¼˜åŒ–å†å²CSVæ–‡ä»¶\n",
    "            self.save_optuna_results(output_dir='optuna_results')\n",
    "\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(\"=== Optunaè¶…å‚æ•°ä¼˜åŒ–å®Œæˆ ===\")\n",
    "            print(f\"{'='*80}\")\n",
    "        else:\n",
    "            print(\"\\nâš ï¸ Optunaè¶…å‚æ•°ä¼˜åŒ–å·²ç¦ç”¨ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°\")\n",
    "\n",
    "        # ========================================================================\n",
    "        # å‡†å¤‡æœ€ç»ˆè®­ç»ƒæ•°æ®\n",
    "        # ========================================================================\n",
    "        X_train_final = X_train.copy()\n",
    "        y_train_final = y_train.copy()\n",
    "\n",
    "        # ========================================================================\n",
    "        # æ­£å¼æ¨¡å‹è®­ç»ƒï¼ˆä½¿ç”¨æœ€ç»ˆç¡®å®šçš„è®­ç»ƒæ•°æ®ï¼‰\n",
    "        # ========================================================================\n",
    "        print(f\"\\n=== æ­£å¼æ¨¡å‹è®­ç»ƒ ===\")\n",
    "        print(f\"è®­ç»ƒæ•°æ®å¤§å°: {len(X_train_final)} æ ·æœ¬\")\n",
    "\n",
    "        # ========================================================================\n",
    "        # å®šä¹‰åŸºç¡€æ¨¡å‹å‚æ•°ï¼ˆæ ¹æ®æ˜¯å¦ä½¿ç”¨Optunaä¼˜åŒ–é€‰æ‹©å‚æ•°ï¼‰\n",
    "        # ========================================================================\n",
    "        # å¦‚æœå¯ç”¨äº†Optunaä¼˜åŒ–ä¸”ä¼˜åŒ–æˆåŠŸï¼Œä½¿ç”¨ä¼˜åŒ–åçš„æœ€ä¼˜å‚æ•°\n",
    "        # å¦åˆ™ä½¿ç”¨ç»éªŒè°ƒä¼˜çš„é»˜è®¤å‚æ•°\n",
    "        # ========================================================================\n",
    "        \n",
    "        # XGBoostå‚æ•°é€‰æ‹©\n",
    "        if self.use_optuna_tuning and xgb_best_params:\n",
    "            # ä½¿ç”¨Optunaä¼˜åŒ–çš„XGBoostå‚æ•°\n",
    "            # åˆå¹¶ä¼˜åŒ–å‚æ•°å’Œå›ºå®šå‚æ•°ï¼ˆç¡®ä¿random_stateç­‰å›ºå®šå‚æ•°ä¸è¢«è¦†ç›–ï¼‰\n",
    "            print(\"\\nâœ“ ä½¿ç”¨Optunaä¼˜åŒ–çš„XGBoostå‚æ•°\")\n",
    "            xgb_params = {\n",
    "                **xgb_best_params,  # å±•å¼€ä¼˜åŒ–åçš„å‚æ•°\n",
    "                'random_state': 42,  # å›ºå®šéšæœºç§å­\n",
    "                'eval_metric': 'logloss',  # å›ºå®šè¯„ä¼°æŒ‡æ ‡\n",
    "                'n_jobs': -1  # ä½¿ç”¨æ‰€æœ‰CPUæ ¸å¿ƒ\n",
    "            }\n",
    "        else:\n",
    "            # ä½¿ç”¨é»˜è®¤XGBoostå‚æ•°ï¼ˆç»éªŒè°ƒä¼˜çš„å‚æ•°ï¼‰\n",
    "            xgb_params = xgb_cv_params\n",
    "\n",
    "        # LightGBMå‚æ•°é€‰æ‹©\n",
    "        if self.use_optuna_tuning and lgb_best_params:\n",
    "            # ä½¿ç”¨Optunaä¼˜åŒ–çš„LightGBMå‚æ•°\n",
    "            print(\"âœ“ ä½¿ç”¨Optunaä¼˜åŒ–çš„LightGBMå‚æ•°\")\n",
    "            lgb_params = {\n",
    "                **lgb_best_params,  # å±•å¼€ä¼˜åŒ–åçš„å‚æ•°\n",
    "                'random_state': 42,  # å›ºå®šéšæœºç§å­\n",
    "                'verbose': -1,  # ä¸è¾“å‡ºè®­ç»ƒæ—¥å¿—\n",
    "                'n_jobs': -1  # ä½¿ç”¨æ‰€æœ‰CPUæ ¸å¿ƒ\n",
    "            }\n",
    "        else:\n",
    "            # ä½¿ç”¨é»˜è®¤LightGBMå‚æ•°ï¼ˆç»éªŒè°ƒä¼˜çš„å‚æ•°ï¼‰\n",
    "            lgb_params = {\n",
    "                'n_estimators': 800,  # æ ‘çš„æ•°é‡\n",
    "                'max_depth': 10,  # æ ‘çš„æœ€å¤§æ·±åº¦\n",
    "                'learning_rate': 0.03,  # å­¦ä¹ ç‡\n",
    "                'subsample': 0.85,  # è¡Œé‡‡æ ·æ¯”ä¾‹\n",
    "                'colsample_bytree': 0.85,  # åˆ—é‡‡æ ·æ¯”ä¾‹\n",
    "                'min_child_samples': 15,  # å¶å­èŠ‚ç‚¹æœ€å°æ ·æœ¬æ•°\n",
    "                'reg_alpha': 0.1,  # L1æ­£åˆ™åŒ–ç³»æ•°\n",
    "                'reg_lambda': 0.1,  # L2æ­£åˆ™åŒ–ç³»æ•°\n",
    "                'num_leaves': 50,  # å¶å­èŠ‚ç‚¹æ•°\n",
    "                'random_state': 42,\n",
    "                'verbose': -1,\n",
    "                'n_jobs': -1\n",
    "            }\n",
    "\n",
    "        # CatBoostå‚æ•°é€‰æ‹©\n",
    "        if self.use_optuna_tuning and cat_best_params:\n",
    "            # ä½¿ç”¨Optunaä¼˜åŒ–çš„CatBoostå‚æ•°\n",
    "            print(\"âœ“ ä½¿ç”¨Optunaä¼˜åŒ–çš„CatBoostå‚æ•°\")\n",
    "            cat_params = {\n",
    "                **cat_best_params,  # å±•å¼€ä¼˜åŒ–åçš„å‚æ•°\n",
    "                'random_seed': 42,  # å›ºå®šéšæœºç§å­ï¼ˆCatBoostä½¿ç”¨random_seedï¼‰\n",
    "                'verbose': False,  # ä¸è¾“å‡ºè®­ç»ƒæ—¥å¿—\n",
    "                'thread_count': -1  # ä½¿ç”¨æ‰€æœ‰CPUæ ¸å¿ƒï¼ˆCatBoostä½¿ç”¨thread_countï¼‰\n",
    "            }\n",
    "        else:\n",
    "            # ä½¿ç”¨é»˜è®¤CatBoostå‚æ•°ï¼ˆç»éªŒè°ƒä¼˜çš„å‚æ•°ï¼‰\n",
    "            cat_params = {\n",
    "                'iterations': 800,  # è¿­ä»£æ¬¡æ•°ï¼ˆCatBoostä½¿ç”¨iterationsï¼‰\n",
    "                'depth': 9,  # æ ‘çš„æœ€å¤§æ·±åº¦ï¼ˆCatBoostä½¿ç”¨depthï¼‰\n",
    "                'learning_rate': 0.03,  # å­¦ä¹ ç‡\n",
    "                'l2_leaf_reg': 2,  # L2æ­£åˆ™åŒ–ç³»æ•°\n",
    "                'random_seed': 42,\n",
    "                'verbose': False,\n",
    "                'thread_count': -1\n",
    "            }\n",
    "\n",
    "        base_models = {\n",
    "            'XGBoost': xgb.XGBClassifier(**xgb_params),\n",
    "            'LightGBM': lgb.LGBMClassifier(**lgb_params),\n",
    "            'CatBoost': CatBoostClassifier(**cat_params)\n",
    "        }\n",
    "\n",
    "        # è®­ç»ƒåŸºç¡€æ¨¡å‹ï¼ˆä½¿ç”¨æœ€ç»ˆçš„è®­ç»ƒæ•°æ®ï¼‰\n",
    "        for name, model in base_models.items():\n",
    "            print(f\"è®­ç»ƒ {name}...\")\n",
    "            model.fit(X_train_final, y_train_final)\n",
    "\n",
    "            y_pred = model.predict(X_val)\n",
    "            accuracy = accuracy_score(y_val, y_pred)\n",
    "\n",
    "            print(f\"{name} éªŒè¯å‡†ç¡®ç‡: {accuracy:.4f}\")\n",
    "\n",
    "            self.models[name] = model\n",
    "\n",
    "            if hasattr(model, 'feature_importances_'):\n",
    "                self.feature_importance[name] = model.feature_importances_\n",
    "\n",
    "        # Stackingé›†æˆæ¨¡å‹ - ä½¿ç”¨è¾ƒå°‘çš„åŸºç¡€æ¨¡å‹å‡å°‘å†…å­˜å ç”¨\n",
    "        print(\"\\nè®­ç»ƒStackingé›†æˆæ¨¡å‹...\")\n",
    "\n",
    "        # é€‰æ‹©è¡¨ç°æœ€å¥½çš„3ä¸ªæ¨¡å‹è¿›è¡ŒStacking\n",
    "        stacking_estimators = [\n",
    "            ('XGBoost', base_models['XGBoost']),\n",
    "            ('LightGBM', base_models['LightGBM']),\n",
    "            ('CatBoost', base_models['CatBoost'])\n",
    "        ]\n",
    "\n",
    "        # æ–¹æ¡ˆ2: ä½¿ç”¨'prefit'é¿å…äº¤å‰éªŒè¯ï¼ˆæœ€å¿«ï¼Œä½†å¯èƒ½ç•¥å¾®é™ä½æ€§èƒ½ï¼‰\n",
    "        # æ³¨æ„ï¼šprefitéœ€è¦åŸºç¡€æ¨¡å‹å·²ç»è®­ç»ƒå¥½ï¼Œè¿™é‡Œæˆ‘ä»¬å·²ç»è®­ç»ƒè¿‡äº†\n",
    "        stacking_model = StackingClassifier(\n",
    "            estimators=stacking_estimators,\n",
    "            final_estimator=LogisticRegression(C=1.0, max_iter=500, random_state=42),  # å‡å°‘è¿­ä»£æ¬¡æ•°\n",
    "            cv=2, # cv=4, # cv='prefit',  # ä½¿ç”¨prefité¿å…äº¤å‰éªŒè¯ï¼Œé€Ÿåº¦æå‡3-5å€ï¼ # è¡¨ç¤ºåœ¨è®­ç»ƒStackingç»ˆç»“å™¨æ—¶ä½¿ç”¨3æŠ˜äº¤å‰éªŒè¯ï¼ˆå†…éƒ¨é‡è®­ç»ƒ3æ¬¡å–å¹³å‡ï¼‰ StackingClassifier åœ¨ cv=3 æ—¶ä¼šæŠŠè®­ç»ƒé›†å†æŒ‰ 3 æŠ˜åˆ’åˆ†ï¼Œç”¨å‰ä¸¤æŠ˜ç”ŸæˆåŸºç¡€æ¨¡å‹çš„é¢„æµ‹ã€ç¬¬ä¸‰æŠ˜è®­ç»ƒç»ˆç»“å™¨ï¼›ç„¶åè½®æ¢ 3 æ¬¡ï¼Œæ¯æ¬¡æ¢ä¸€æŠ˜åš\"ç»ˆç»“å™¨è®­ç»ƒé›†\"ï¼Œæœ€åæŠŠä¸‰æ¬¡è®­ç»ƒå¾—åˆ°çš„ç»ˆç»“å™¨æƒé‡å¹³å‡å†ç”¨äºæœ€ç»ˆæ¨¡å‹ã€‚ å…ˆç”¨é‚£ 2 æŠ˜æŠŠæ‰€æœ‰åŸºç¡€æ¨¡å‹ï¼ˆXGBoostã€LightGBMã€CatBoost ç­‰ï¼‰é‡æ–°è®­ç»ƒå¥½ï¼Œç„¶åè®©å®ƒä»¬å»é¢„æµ‹åˆšåˆšè¢«ç•™å‡ºæ¥çš„é‚£ 1 æŠ˜ï¼Œå¾—åˆ°è¿™ä¸€æŠ˜åœ¨å„ä¸ªåŸºç¡€æ¨¡å‹ä¸‹çš„é¢„æµ‹ç»“æœï¼ˆè¿™äº›é¢„æµ‹å€¼å°±åƒæ–°çš„ç‰¹å¾ï¼‰ã€‚ä½¿ç”¨è¿™ä»½æŠ˜ä¸Šçš„åŸºç¡€é¢„æµ‹ç»“æœ + å®é™…æ ‡ç­¾ï¼Œå»è®­ç»ƒç»ˆç»“å™¨ï¼ˆè¿™é‡Œæ˜¯ LogisticRegressionï¼‰ã€‚\n",
    "            n_jobs=1  # ä¿æŒå•çº¿ç¨‹\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            stacking_model.fit(X_train_final, y_train_final)\n",
    "            y_pred_stacking = stacking_model.predict(X_val)\n",
    "            stacking_accuracy = accuracy_score(y_val, y_pred_stacking)\n",
    "            print(f\"Stackingé›†æˆæ¨¡å‹éªŒè¯å‡†ç¡®ç‡: {stacking_accuracy:.4f}\")\n",
    "            self.models['Stacking'] = stacking_model\n",
    "        except Exception as e:\n",
    "            print(f\"Stackingè®­ç»ƒå¤±è´¥: {e}\")\n",
    "            print(\"è·³è¿‡Stackingæ¨¡å‹,ä½¿ç”¨Votingä½œä¸ºä¸»è¦é›†æˆæ–¹æ³•\")\n",
    "\n",
    "        # # Votingé›†æˆ(soft voting)\n",
    "        # print(\"\\nè®­ç»ƒVotingé›†æˆæ¨¡å‹...\")\n",
    "        # voting_estimators = list(base_models.items())\n",
    "        # voting_model = VotingClassifier(\n",
    "        #     estimators=voting_estimators,\n",
    "        #     voting='soft',\n",
    "        #     n_jobs=-1\n",
    "        # )\n",
    "        # voting_model.fit(X_train_final, y_train_final)\n",
    "        # y_pred_voting = voting_model.predict(X_val)\n",
    "        # voting_accuracy = accuracy_score(y_val, y_pred_voting)\n",
    "        # print(f\"Votingé›†æˆæ¨¡å‹éªŒè¯å‡†ç¡®ç‡: {voting_accuracy:.4f}\")\n",
    "\n",
    "        # self.models['Voting'] = voting_model\n",
    "\n",
    "        # ä¿å­˜æœ€ä½³æ¨¡å‹çš„é¢„æµ‹é”™è¯¯æ ·æœ¬\n",
    "        if 'Stacking' in self.models:\n",
    "            self.best_model_name = 'Stacking'\n",
    "            self.best_model = self.models['Stacking']\n",
    "            best_predictions = self.models['Stacking'].predict(X_val)\n",
    "        else:\n",
    "            self.best_model_name = 'Voting'\n",
    "            self.best_model = self.models['Voting']\n",
    "            best_predictions = y_pred_voting\n",
    "\n",
    "        # ä¿å­˜é”™è¯¯æ ·æœ¬åˆ°JSON\n",
    "        # self.save_misclassified_samples(val_indices, best_predictions, y_val, self.best_model_name)\n",
    "\n",
    "        # # ä¹Ÿå¯ä»¥ä¿å­˜å„ä¸ªåŸºç¡€æ¨¡å‹çš„é”™è¯¯æ ·æœ¬ç”¨äºå¯¹æ¯”åˆ†æ\n",
    "        # print(\"\\n=== ä¿å­˜å„åŸºç¡€æ¨¡å‹çš„é”™è¯¯æ ·æœ¬ ===\")\n",
    "        # for name, model in base_models.items():\n",
    "        #     y_pred_base = model.predict(X_val)\n",
    "        #     self.save_misclassified_samples(val_indices, y_pred_base, y_val, name)\n",
    "\n",
    "        return self.models\n",
    "\n",
    "    def make_predictions(self):\n",
    "        \"\"\"ç”Ÿæˆé¢„æµ‹ç»“æœ\"\"\"\n",
    "        print(\"\\n=== ç”Ÿæˆé¢„æµ‹ ===\")\n",
    "\n",
    "        # å¦‚æœä½¿ç”¨äº†ç‰¹å¾é€‰æ‹©ï¼Œéœ€è¦å¯¹æµ‹è¯•æ•°æ®ä¹Ÿè¿›è¡Œè½¬æ¢\n",
    "        test_features = self.test_combined\n",
    "        if hasattr(self, 'feature_selector') and self.feature_selector is not None:\n",
    "            print(\"åº”ç”¨ç‰¹å¾é€‰æ‹©åˆ°æµ‹è¯•æ•°æ®...\")\n",
    "            test_features_array = self.feature_selector.transform(self.test_combined)\n",
    "            # å¦‚æœåŸå§‹æ•°æ®æ˜¯DataFrameï¼Œå°†ç»“æœä¹Ÿè½¬æ¢ä¸ºDataFrame\n",
    "            if isinstance(self.test_combined, pd.DataFrame):\n",
    "                selected_features = self.test_combined.columns[self.feature_selector.support_].tolist()\n",
    "                test_features = pd.DataFrame(\n",
    "                    test_features_array,\n",
    "                    columns=selected_features,\n",
    "                    index=self.test_combined.index\n",
    "                )\n",
    "            else:\n",
    "                test_features = test_features_array\n",
    "            print(f\"æµ‹è¯•ç‰¹å¾å½¢çŠ¶: {test_features.shape}\")\n",
    "\n",
    "        predictions = {}\n",
    "\n",
    "        for name, model in self.models.items():\n",
    "            pred = model.predict(test_features)\n",
    "            predictions[name] = pred\n",
    "            print(f\"{name} é¢„æµ‹å®Œæˆ\")\n",
    "\n",
    "        # ä¼˜å…ˆé€‰æ‹©Stacking,å¦‚æœæ²¡æœ‰åˆ™ç”¨Voting\n",
    "        if 'Stacking' in predictions:\n",
    "            best_predictions = predictions['Stacking']\n",
    "            print(\"ä½¿ç”¨Stackingæ¨¡å‹ç”Ÿæˆæœ€ç»ˆé¢„æµ‹\")\n",
    "        else:\n",
    "            best_predictions = predictions['Voting']\n",
    "            print(\"ä½¿ç”¨Votingæ¨¡å‹ç”Ÿæˆæœ€ç»ˆé¢„æµ‹\")\n",
    "\n",
    "        # åˆ›å»ºæäº¤æ–‡ä»¶\n",
    "        submission = pd.DataFrame({\n",
    "            'battle_id': self.test_data['battle_id'],\n",
    "            'player_won': best_predictions.astype(int)\n",
    "        })\n",
    "\n",
    "        submission.to_csv('submission_enhanced_v4.csv', index=False)\n",
    "        print(\"æäº¤æ–‡ä»¶å·²ç”Ÿæˆ: submission_enhanced_v4.csv\")\n",
    "\n",
    "        return submission, predictions\n",
    "\n",
    "    def get_sample_features(self, original_index):\n",
    "        \"\"\"è·å–æŒ‡å®šç´¢å¼•æ ·æœ¬çš„æ‰€æœ‰ç‰¹å¾\"\"\"\n",
    "        if self.train_combined is None:\n",
    "            print(\"é”™è¯¯: è¯·å…ˆè¿è¡Œç‰¹å¾æå– (extract_static_features, extract_dynamic_features, combine_features)\")\n",
    "            return None\n",
    "\n",
    "        if original_index >= len(self.train_combined):\n",
    "            print(f\"é”™è¯¯: ç´¢å¼•è¶…å‡ºèŒƒå›´ (æœ€å¤§: {len(self.train_combined)-1})\")\n",
    "            return None\n",
    "\n",
    "        return self.train_combined.iloc[original_index].to_dict()\n",
    "\n",
    "    def explain_single_prediction(self, sample_index, model_name='XGBoost', top_k=20, use_shap=True):\n",
    "        \"\"\"\n",
    "        è§£é‡Šå•ä¸ªæ ·æœ¬çš„é¢„æµ‹ç»“æœ\n",
    "        \n",
    "        åŠŸèƒ½ï¼š\n",
    "        1. æ˜¾ç¤ºè¯¥æ ·æœ¬çš„æ‰€æœ‰ç‰¹å¾å€¼\n",
    "        2. æ˜¾ç¤ºé¢„æµ‹ç»“æœå’Œæ¦‚ç‡\n",
    "        3. æ˜¾ç¤ºå¯¹è¯¥é¢„æµ‹è´¡çŒ®æœ€å¤§çš„ç‰¹å¾ï¼ˆä½¿ç”¨SHAPæˆ–ç‰¹å¾é‡è¦æ€§ï¼‰\n",
    "        \n",
    "        å‚æ•°ï¼š\n",
    "        - sample_index: æ ·æœ¬ç´¢å¼•ï¼ˆåœ¨train_combinedä¸­çš„ç´¢å¼•ï¼‰\n",
    "        - model_name: ä½¿ç”¨çš„æ¨¡å‹åç§°ï¼ˆé»˜è®¤'XGBoost'ï¼‰\n",
    "        - top_k: æ˜¾ç¤ºå‰Kä¸ªæœ€é‡è¦çš„ç‰¹å¾ï¼ˆé»˜è®¤20ï¼‰\n",
    "        - use_shap: æ˜¯å¦ä½¿ç”¨SHAPå€¼ï¼ˆå¦‚æœå¯ç”¨ï¼Œé»˜è®¤Trueï¼‰\n",
    "        \n",
    "        è¿”å›ï¼š\n",
    "        - åŒ…å«é¢„æµ‹è§£é‡Šçš„å­—å…¸\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"è§£é‡Šæ ·æœ¬ #{sample_index} çš„é¢„æµ‹ç»“æœ\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # æ£€æŸ¥æ¨¡å‹å’Œæ•°æ®\n",
    "        if self.train_combined is None:\n",
    "            print(\"é”™è¯¯: è¯·å…ˆè¿è¡Œç‰¹å¾æå–\")\n",
    "            return None\n",
    "        \n",
    "        if model_name not in self.models:\n",
    "            print(f\"é”™è¯¯: æ¨¡å‹ '{model_name}' ä¸å­˜åœ¨\")\n",
    "            print(f\"å¯ç”¨æ¨¡å‹: {list(self.models.keys())}\")\n",
    "            return None\n",
    "        \n",
    "        model = self.models[model_name]\n",
    "        \n",
    "        # è·å–æ ·æœ¬ç‰¹å¾\n",
    "        if sample_index >= len(self.train_combined):\n",
    "            print(f\"é”™è¯¯: ç´¢å¼•è¶…å‡ºèŒƒå›´ (æœ€å¤§: {len(self.train_combined)-1})\")\n",
    "            return None\n",
    "        \n",
    "        sample_features = self.train_combined.iloc[sample_index:sample_index+1]\n",
    "        feature_names = self.train_combined.columns.tolist()\n",
    "        \n",
    "        # è·å–é¢„æµ‹ç»“æœ\n",
    "        prediction = model.predict(sample_features)[0]\n",
    "        prediction_proba = model.predict_proba(sample_features)[0]\n",
    "        \n",
    "        print(f\"\\nğŸ“Š é¢„æµ‹ç»“æœ:\")\n",
    "        print(f\"   é¢„æµ‹ç±»åˆ«: {prediction} ({'P1è·èƒœ' if prediction == 1 else 'P2è·èƒœ'})\")\n",
    "        print(f\"   é¢„æµ‹æ¦‚ç‡: P1è·èƒœ={prediction_proba[1]:.4f}, P2è·èƒœ={prediction_proba[0]:.4f}\")\n",
    "        print(f\"   ç½®ä¿¡åº¦: {max(prediction_proba):.4f}\")\n",
    "        \n",
    "        # å°è¯•ä½¿ç”¨SHAPå€¼è§£é‡Š\n",
    "        if use_shap:\n",
    "            try:\n",
    "                import shap\n",
    "                print(f\"\\nğŸ” ä½¿ç”¨SHAPå€¼è§£é‡Šé¢„æµ‹ï¼ˆæ˜¾ç¤ºå‰{top_k}ä¸ªç‰¹å¾ï¼‰...\")\n",
    "                \n",
    "                # åˆ›å»ºSHAPè§£é‡Šå™¨\n",
    "                explainer = shap.TreeExplainer(model)\n",
    "                \n",
    "                # ============================================\n",
    "                # èƒŒæ™¯æ•°æ®ï¼ˆBackground Dataï¼‰è¯´æ˜\n",
    "                # ============================================\n",
    "                # SHAPå€¼è®¡ç®—çš„æ˜¯\"ç›¸å¯¹äºæŸä¸ªåŸºå‡†çš„è´¡çŒ®\"\n",
    "                # \n",
    "                # ã€èƒŒæ™¯æ•°æ®çš„ä½œç”¨ã€‘\n",
    "                # 1. ä½œä¸ºåŸºå‡†å‚è€ƒç‚¹ï¼šSHAPå€¼è¡¡é‡çš„æ˜¯\"ç›¸å¯¹äºèƒŒæ™¯æ•°æ®çš„å¹³å‡æƒ…å†µï¼Œè¯¥ç‰¹å¾å€¼å¦‚ä½•å½±å“é¢„æµ‹\"\n",
    "                # 2. æé«˜è®¡ç®—æ•ˆç‡ï¼šä½¿ç”¨å°‘é‡ä»£è¡¨æ€§æ ·æœ¬ï¼ˆå¦‚100ä¸ªï¼‰ä½œä¸ºèƒŒæ™¯ï¼Œè€Œä¸æ˜¯æ•´ä¸ªæ•°æ®é›†\n",
    "                # 3. æ›´ç¨³å®šçš„è§£é‡Šï¼šä½¿ç”¨å¤šä¸ªæ ·æœ¬çš„å¹³å‡å€¼ä½œä¸ºåŸºå‡†ï¼Œæ¯”å•ä¸ªæ ·æœ¬æ›´ç¨³å®š\n",
    "                #\n",
    "                # ã€ç¤ºä¾‹ç†è§£ã€‘\n",
    "                # å‡è®¾è¦è§£é‡Šæ ·æœ¬Açš„é¢„æµ‹ï¼š\n",
    "                # - èƒŒæ™¯æ•°æ®ï¼š100ä¸ªéªŒè¯é›†æ ·æœ¬çš„å¹³å‡ç‰¹å¾å€¼\n",
    "                # - SHAPå€¼è®¡ç®—ï¼šæ ·æœ¬Açš„ç‰¹å¾å€¼ vs èƒŒæ™¯æ•°æ®çš„å¹³å‡ç‰¹å¾å€¼\n",
    "                # - ç»“æœï¼šæ¯ä¸ªç‰¹å¾å¯¹é¢„æµ‹çš„è´¡çŒ® = è¯¥ç‰¹å¾åœ¨æ ·æœ¬Aä¸­çš„å€¼ç›¸å¯¹äºèƒŒæ™¯å¹³å‡å€¼çš„å·®å¼‚å¸¦æ¥çš„å½±å“\n",
    "                #\n",
    "                # ã€ä¸ºä»€ä¹ˆä½¿ç”¨éªŒè¯é›†ä½œä¸ºèƒŒæ™¯ã€‘\n",
    "                # - éªŒè¯é›†ä»£è¡¨æ¨¡å‹çš„\"å…¸å‹è¾“å…¥åˆ†å¸ƒ\"\n",
    "                # - æ¯”è®­ç»ƒé›†æ›´æ¥è¿‘çœŸå®é¢„æµ‹åœºæ™¯\n",
    "                # - é¿å…ä½¿ç”¨æµ‹è¯•æ•°æ®ï¼ˆå¯èƒ½æ³„éœ²ä¿¡æ¯ï¼‰\n",
    "                #\n",
    "                # ã€è®¡ç®—æ–¹å¼å¯¹æ¯”ã€‘\n",
    "                # - æœ‰èƒŒæ™¯æ•°æ®ï¼šSHAPå€¼ = f(æ ·æœ¬ç‰¹å¾) - f(èƒŒæ™¯å¹³å‡ç‰¹å¾)  [æ›´å‡†ç¡®ï¼Œéœ€è¦èƒŒæ™¯]\n",
    "                # - æ— èƒŒæ™¯æ•°æ®ï¼šSHAPå€¼ = f(æ ·æœ¬ç‰¹å¾) - f(æ¨¡å‹æœŸæœ›å€¼)   [å¿«é€Ÿï¼Œä½†å¯èƒ½ä¸å¤Ÿå‡†ç¡®]\n",
    "                # ============================================\n",
    "                \n",
    "                if self.X_val is not None and len(self.X_val) > 100:\n",
    "                    # ä½¿ç”¨éªŒè¯é›†çš„æ ·æœ¬ä½œä¸ºèƒŒæ™¯æ•°æ®ï¼ˆå–å‰100ä¸ªä»£è¡¨æ€§æ ·æœ¬ï¼‰\n",
    "                    # è¿™100ä¸ªæ ·æœ¬çš„å¹³å‡ç‰¹å¾å€¼å°†ä½œä¸ºSHAPå€¼è®¡ç®—çš„åŸºå‡†å‚è€ƒç‚¹\n",
    "                    background_data = self.X_val.iloc[:100]\n",
    "                    shap_values = explainer.shap_values(sample_features, background_data)\n",
    "                else:\n",
    "                    # å¦‚æœæ²¡æœ‰éªŒè¯é›†æˆ–éªŒè¯é›†å¤ªå°ï¼Œä¸ä½¿ç”¨èƒŒæ™¯æ•°æ®\n",
    "                    # SHAPå°†ä½¿ç”¨æ¨¡å‹å†…éƒ¨çš„æœŸæœ›å€¼ä½œä¸ºåŸºå‡†ï¼ˆè®¡ç®—æ›´å¿«ï¼Œä½†è§£é‡Šå¯èƒ½ä¸å¦‚æœ‰èƒŒæ™¯æ•°æ®å‡†ç¡®ï¼‰\n",
    "                    shap_values = explainer.shap_values(sample_features)\n",
    "                \n",
    "                # å¤„ç†SHAPå€¼çš„æ ¼å¼ï¼ˆå¯èƒ½æ˜¯åˆ—è¡¨æˆ–æ•°ç»„ï¼‰\n",
    "                if isinstance(shap_values, list):\n",
    "                    shap_values = shap_values[1] if len(shap_values) > 1 else shap_values[0]\n",
    "                \n",
    "                # è·å–è¯¥æ ·æœ¬çš„SHAPå€¼\n",
    "                if len(shap_values.shape) > 1:\n",
    "                    sample_shap = shap_values[0]\n",
    "                else:\n",
    "                    sample_shap = shap_values\n",
    "                \n",
    "                # åˆ›å»ºç‰¹å¾è´¡çŒ®DataFrame\n",
    "                feature_contributions = pd.DataFrame({\n",
    "                    'feature': feature_names,\n",
    "                    'shap_value': sample_shap,\n",
    "                    'feature_value': sample_features.iloc[0].values,\n",
    "                    'abs_shap': np.abs(sample_shap)\n",
    "                })\n",
    "                \n",
    "                # æŒ‰ç»å¯¹SHAPå€¼æ’åº\n",
    "                feature_contributions = feature_contributions.sort_values('abs_shap', ascending=False)\n",
    "                \n",
    "                print(f\"\\nğŸ“ˆ å¯¹è¯¥é¢„æµ‹è´¡çŒ®æœ€å¤§çš„å‰{top_k}ä¸ªç‰¹å¾:\")\n",
    "                print(\"-\" * 80)\n",
    "                print(f\"{'æ’å':<6} {'ç‰¹å¾å':<40} {'ç‰¹å¾å€¼':<15} {'SHAPå€¼':<12} {'è´¡çŒ®æ–¹å‘':<10}\")\n",
    "                print(\"-\" * 80)\n",
    "                \n",
    "                for i, (idx, row) in enumerate(feature_contributions.head(top_k).iterrows(), 1):\n",
    "                    direction = \"â†‘ æ”¯æŒP1\" if row['shap_value'] > 0 else \"â†“ æ”¯æŒP2\"\n",
    "                    print(f\"{i:<6} {row['feature']:<40} {row['feature_value']:<15.4f} {row['shap_value']:<12.6f} {direction:<10}\")\n",
    "                \n",
    "                # è®¡ç®—æ€»è´¡çŒ®\n",
    "                positive_contrib = feature_contributions[feature_contributions['shap_value'] > 0]['shap_value'].sum()\n",
    "                negative_contrib = feature_contributions[feature_contributions['shap_value'] < 0]['shap_value'].sum()\n",
    "                \n",
    "                print(f\"\\nğŸ’¡ è´¡çŒ®æ€»ç»“:\")\n",
    "                print(f\"   æ”¯æŒP1è·èƒœçš„æ€»è´¡çŒ®: {positive_contrib:.4f}\")\n",
    "                print(f\"   æ”¯æŒP2è·èƒœçš„æ€»è´¡çŒ®: {abs(negative_contrib):.4f}\")\n",
    "                print(f\"   å‡€è´¡çŒ®: {positive_contrib + negative_contrib:.4f}\")\n",
    "                \n",
    "                return {\n",
    "                    'sample_index': sample_index,\n",
    "                    'prediction': int(prediction),\n",
    "                    'prediction_proba': prediction_proba,\n",
    "                    'feature_contributions': feature_contributions,\n",
    "                    'method': 'SHAP'\n",
    "                }\n",
    "                \n",
    "            except ImportError:\n",
    "                print(\"âš ï¸ SHAPåº“æœªå®‰è£…ï¼Œä½¿ç”¨ç‰¹å¾é‡è¦æ€§æ–¹æ³•...\")\n",
    "                use_shap = False\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ SHAPè®¡ç®—å¤±è´¥: {e}\")\n",
    "                print(\"ä½¿ç”¨ç‰¹å¾é‡è¦æ€§æ–¹æ³•...\")\n",
    "                use_shap = False\n",
    "        \n",
    "        # # å¤‡é€‰æ–¹æ¡ˆï¼šä½¿ç”¨ç‰¹å¾é‡è¦æ€§\n",
    "        # if not use_shap:\n",
    "        #     print(f\"\\nğŸ” ä½¿ç”¨ç‰¹å¾é‡è¦æ€§è§£é‡Šé¢„æµ‹ï¼ˆæ˜¾ç¤ºå‰{top_k}ä¸ªç‰¹å¾ï¼‰...\")\n",
    "            \n",
    "        #     # è·å–ç‰¹å¾é‡è¦æ€§\n",
    "        #     if hasattr(model, 'feature_importances_'):\n",
    "        #         importances = model.feature_importances_\n",
    "        #     else:\n",
    "        #         print(\"é”™è¯¯: æ¨¡å‹æ²¡æœ‰feature_importances_å±æ€§\")\n",
    "        #         return None\n",
    "            \n",
    "        #     # è·å–æ ·æœ¬çš„ç‰¹å¾å€¼\n",
    "        #     sample_values = sample_features.iloc[0].values\n",
    "            \n",
    "        #     # åˆ›å»ºç‰¹å¾è´¡çŒ®DataFrame\n",
    "        #     feature_contributions = pd.DataFrame({\n",
    "        #         'feature': feature_names,\n",
    "        #         'importance': importances,\n",
    "        #         'feature_value': sample_values,\n",
    "        #         'weighted_contribution': importances * np.abs(sample_values)\n",
    "        #     })\n",
    "            \n",
    "        #     # æŒ‰åŠ æƒè´¡çŒ®æ’åº\n",
    "        #     feature_contributions = feature_contributions.sort_values('weighted_contribution', ascending=False)\n",
    "            \n",
    "        #     print(f\"\\nğŸ“ˆ å¯¹è¯¥é¢„æµ‹è´¡çŒ®æœ€å¤§çš„å‰{top_k}ä¸ªç‰¹å¾:\")\n",
    "        #     print(\"-\" * 80)\n",
    "        #     print(f\"{'æ’å':<6} {'ç‰¹å¾å':<40} {'ç‰¹å¾å€¼':<15} {'é‡è¦æ€§':<12} {'åŠ æƒè´¡çŒ®':<12}\")\n",
    "        #     print(\"-\" * 80)\n",
    "            \n",
    "        #     for i, (idx, row) in enumerate(feature_contributions.head(top_k).iterrows(), 1):\n",
    "        #         print(f\"{i:<6} {row['feature']:<40} {row['feature_value']:<15.4f} {row['importance']:<12.6f} {row['weighted_contribution']:<12.6f}\")\n",
    "            \n",
    "        #     return {\n",
    "        #         'sample_index': sample_index,\n",
    "        #         'prediction': int(prediction),\n",
    "        #         'prediction_proba': prediction_proba,\n",
    "        #         'feature_contributions': feature_contributions,\n",
    "        #         'method': 'Feature Importance'\n",
    "        #     }\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def analyze_results(self):\n",
    "        \"\"\"åˆ†æç»“æœ\"\"\"\n",
    "        print(\"\\n=== ç»“æœåˆ†æ ===\")\n",
    "\n",
    "        # ç‰¹å¾é‡è¦æ€§åˆ†æ\n",
    "        if self.feature_importance:\n",
    "            print(\"\\nç‰¹å¾é‡è¦æ€§åˆ†æ:\")\n",
    "            for model_name, importance in self.feature_importance.items():\n",
    "                print(f\"\\n{model_name} å‰15ä¸ªé‡è¦ç‰¹å¾:\")\n",
    "                feature_names = self.train_combined.columns\n",
    "                importance_df = pd.DataFrame({\n",
    "                    'feature': feature_names,\n",
    "                    'importance': importance\n",
    "                }).sort_values('importance', ascending=False)\n",
    "                print(importance_df.head(15))\n",
    "\n",
    "        return self.feature_importance\n",
    "\n",
    "def main():\n",
    "    \"\"\"ä¸»å‡½æ•°\"\"\"\n",
    "    # åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ\n",
    "    log_file_path = setup_logging(log_dir='print_log')\n",
    "    print(f\"æ—¥å¿—ç³»ç»Ÿå·²å¯åŠ¨ï¼Œè¾“å‡ºå°†ä¿å­˜åˆ°: {log_file_path}\")\n",
    "    \n",
    "    try:\n",
    "        print(\"Pokemon Battles Prediction 2025 - Enhanced Version\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        # åˆ›å»ºé¢„æµ‹å™¨å®ä¾‹\n",
    "        predictor = PokemonBattlePredictorEnhanced()\n",
    "        # åŠ è½½æ•°æ®\n",
    "        if os.path.exists('input/train.jsonl') and os.path.exists('input/test.jsonl'):\n",
    "            train_data, test_data = predictor.load_data('input/train.jsonl', 'input/test.jsonl')\n",
    "        else:\n",
    "            train_data, test_data = predictor.load_data('../input/fds-pokemon-battles-prediction-2025/train.jsonl', '../input/fds-pokemon-battles-prediction-2025/test.jsonl')\n",
    "\n",
    "        # ç‰¹å¾å·¥ç¨‹\n",
    "        predictor.extract_static_features()\n",
    "        predictor.extract_dynamic_features()\n",
    "        predictor.combine_features()\n",
    "\n",
    "        # æ¨¡å‹è®­ç»ƒ\n",
    "        predictor.train_models()\n",
    "\n",
    "        # ç”Ÿæˆé¢„æµ‹\n",
    "        submission, predictions = predictor.make_predictions()\n",
    "\n",
    "        # ç»“æœåˆ†æ\n",
    "        predictor.analyze_results()\n",
    "        \n",
    "        # ç‰¹å¾ç§»é™¤å½±å“æµ‹è¯•\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"å¼€å§‹ç‰¹å¾ç§»é™¤å½±å“æµ‹è¯•...\")\n",
    "        print(\"=\"*60)\n",
    "        # removal_results = predictor.test_feature_removal_impact(top_n=20, n_repeats=2)\n",
    "        \n",
    "\n",
    "        # ç¤ºä¾‹ï¼šè§£é‡Šå•ä¸ªæ ·æœ¬çš„é¢„æµ‹ï¼ˆç´¢å¼•6678ï¼‰\n",
    "        # print(\"\\n\" + \"=\"*60)\n",
    "        # print(\"è§£é‡Šæ ·æœ¬ #6678 çš„é¢„æµ‹ç»“æœ...\")\n",
    "        # print(\"=\"*60)\n",
    "        explanation = predictor.explain_single_prediction(\n",
    "            sample_index= 3907,#7433, # 238  6678, # 8440, #6678    11è¿™ä¸ªç¡®å®æ˜¯ç‰¹ä¾‹     7433å­˜æ´»ä½†æ˜¯è¡€é‡ä½\n",
    "            model_name='XGBoost',\n",
    "            top_k=40,\n",
    "            use_shap=True  # å¦‚æœå®‰è£…äº†SHAPåº“ï¼Œä¼šä½¿ç”¨SHAPå€¼ï¼›å¦åˆ™ä½¿ç”¨ç‰¹å¾é‡è¦æ€§\n",
    "        )\n",
    "\n",
    "        print(\"\\nä»»åŠ¡å®Œæˆ!\")\n",
    "        print(\"è¯·æ£€æŸ¥ submission_enhanced_v4.csv æ–‡ä»¶\")\n",
    "        print(\"ç‰¹å¾åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ\")\n",
    "        print(\"\\nğŸ’¡ æç¤º: è¦è§£é‡Šå•ä¸ªæ ·æœ¬çš„é¢„æµ‹ï¼Œå¯ä»¥ä½¿ç”¨:\")\n",
    "        print(\"   predictor.explain_single_prediction(sample_index=6678, model_name='XGBoost', top_k=20)\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"é”™è¯¯: æ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶ - {e}\")\n",
    "        print(\"è¯·ç¡®ä¿ train.jsonl å’Œ test.jsonl æ–‡ä»¶å­˜åœ¨äº input/ ç›®å½•\")\n",
    "    except Exception as e:\n",
    "        print(f\"å‘ç”Ÿé”™è¯¯: {e}\")\n",
    "        import traceback\n",
    "        print(traceback.format_exc())\n",
    "    finally:\n",
    "        # å…³é—­æ—¥å¿—æ–‡ä»¶\n",
    "        close_logging()\n",
    "        print(f\"\\næ—¥å¿—æ–‡ä»¶å·²ä¿å­˜: {log_file_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13033998,
     "sourceId": 107555,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 170.479441,
   "end_time": "2025-11-14T22:43:05.886290",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-14T22:40:15.406849",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
